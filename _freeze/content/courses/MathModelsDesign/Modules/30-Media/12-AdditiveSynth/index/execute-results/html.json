{
  "hash": "95e879c3d56309eb3d1c63e2bf1f2ccc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: <iconify-icon icon=\"mdi:reiterate\" width=\"1.2em\" height=\"1.2em\"></iconify-icon> <iconify-icon icon=\"gravity-ui:function\" width=\"1.2em\" height=\"1.2em\"></iconify-icon> Additive Sound Synthesis\nsubtitle: \"\"\nsubject: \"\"\nabstract: \"\"\ndate: 23/Jan/2025\ndate-modified: \"2025-02-07\"\norder: 12\ncategories:\n  - Component Addition\n  - Time-varying Parameters\nbibliography: \n  - grateful-refs.bib\n  - references.bib\ncitation: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n## Introduction\n\nSo we understand the Fourier Transform: we can express any waveform as a\nsum of sinusoids that are appropriately weighted and are at discrete\nmultiples of a chosen \"fundamental frequency\".\n\nHow do we use these ideas to synthesize sound?\n\n## {{< iconify icons8 idea >}} Inspiration\n\nTO BE ADDED (sic!)\n\n## What is Additive Synthesis?\n\nFirst we need to get used to the idea of an\n[**oscillator**](https://p5js.org/reference/p5.sound/p5.Oscillator/).\n\nAn *oscillator* is a source: it generates waveforms that we perceive as\nsound. Let us play with a few oscillator types here:\n\n<https://musiclab.chromeexperiments.com/Oscillators/>\n\nEach of these waveforms, by the Fourier series, is the **sum of an (\ninfinite) number** of **sine wave** outputs.\n\nIn Fourier series, we normally use just *sine wave oscillators*, and use\nmany of them to add up to obtain the wave form we need. Now let us hear\nfrom Mr Shiffman again:\n\n{{< video https://youtu.be/Bk8rLzzSink?list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW >}}\n\n## The Math of Waveform Addition\n\nIn general, we can write a sum of sine/cos waves as:\n\n$$\nf(\\theta) = \\frac{1}{a_0} + \\sum_{k=0}^{\\infty} a_k*sin(k\\theta) + b_k*cos(k\\theta)\n$$ {#eq-additive-synthesis}\n\n$f$ is the desired time-waveform, the\n$\\theta = 2\\pi\\times fundamental~frequency \\times t$, and the $a_k$ and\n$b_k$ are weights for the individual components that are to be designed.\n\nHow does this look like? Mr. Shiffman again:\n\n{{< video https://youtu.be/okfZRl4Xw-c >}}\n\n\nNow let us see how we can design something using the Additive Method. \n\n## Design Principles for Additive Synthesis\n\nHow do we do this with intent? We will follow the development in\n[Farnell](https://mitpress.mit.edu/9780262014410/designing-sound/) and\nRisset and Mathews, [@risset1969a] and\n[Moorer](https://ccrma.stanford.edu/STANM/stanms/stanm5/stanm5.pdf).\n\n1. The idea is to take an original sound, analyze that using the Fourier Series, and then use those coefficients to synthesize the sound with code.\n1. The coefficients, or parameters, need to be manipulated and transformed with time, in order for the synthesized sound to have a \"live\" feel. \n1. The number of such parameters and their control over time could pose a formidable data management challenge. This leads to the idea of *data reduction* in order to have a manageable number of these, and generate the sound in its essentials. \n1. One essential part of this is to use **envelopes** around the amplitudes of several sine waves, what is called the [ADSR]() method. This could also lead to several oscillators being turned on or off based on need. \n1. So one needs to break down the sound into \"principal components\" that are harmonically related ( as with the Fourier series) and then fill in [**inharmonic tones**]() using additional oscillators. \n\n## What is ADSR?\n\n*ADSR* stands for \"Attack Decay Sustain Release\". These related to the way a note of music varies over time in a typical piece of music. \n\n{{< video https://www.youtube.com/watch?v=wUSva_BnedA&pp=ygURQURTUiBjb2RpbmcgdHJhaW4%3D >}}\n\n\n## Additive Synthesis with Code\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke; \"}\n### Using p5.js\n\n### Using R\n:::\n\n## {{< iconify mingcute thought-line >}} Wait, But Why?\n\nTo be Written Up.\n\n## {{< iconify ooui references-ltr >}} References\n\n1.  James Moorer. (Nov 1976) *The Synthesis of Complex Audio Spectra by\n    Means of Discrete Summation Formulae*. Journal of the Audio Society.\n    [PDF](../../../../../materials/pdfs/Moorer-Sine-Summation.pdf)\n2.  Jean-Claude Risset, Max V. Matthews. (Feb 1969). *Analysis of\n    Musical Instrument Tones*. Physics Today.\n    <https://sci-hub.se/https://doi.org/10.1063/1.3035399>\n3.  p5.Sound\n    Tutorial.<https://pdm.lsupathways.org/6_resources/7_soundandmusic/p5.sound/>\n4.  Sound in p5.js Playlist.\n    <https://www.youtube.com/playlist?list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW>\n5.  *Sounds with Tone.js*. <https://pdm.lsupathways.org/3_audio/>\n6.  Mister Bomb. *p5.Sound project tutorials*\n    <https://www.youtube.com/playlist?list=PLIsdHp2z9wFl7A1wWb2VmQUUojEGsKELE>\n7.  *R package `gm`: the grammar of Music*.\n    <https://cran.r-project.org/web/packages/gm/vignettes/gm.html>\n8.  Phil Burk,Larry Polansky, Douglas Repetto, Mary Roberts Dan\n    Rockmore. *Music and Computers: A Theoretical and Historical\n    Approach* <https://musicandcomputersbook.com>\n\n::: {#refs style=\"font-size: 60%;\"}\n###### {{< iconify lucide package-check >}} R Package Citations\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nPackage      Version   Citation    \n-----------  --------  ------------\nambient      1.0.2     @ambient    \ngm           2.0.0     @gm         \nmosaicCalc   0.6.4     @mosaicCalc \nplot3D       1.4.1     @plot3D     \n\n\n:::\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}