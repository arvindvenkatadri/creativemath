{
  "hash": "d649ef879aa6bbaa592203fb52d28450",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: \"2024-12-07\"\ntitle: \"Gradient Descent\"\norder: 180\nsummary: \ntags:\n- Neural Nets\n- Perceptrons\n- Gradient Descent\n\n---\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n## {{< iconify icons8 idea >}} Inspiration\n\n### What is a Neural Network?\n\n1. Frank Rosenblatt's Perceptron\n\n2. Deep Learning Networks\n  - Input Layers\n  - Output Layers\n  - Hidden Layers\n  - Activation\n  \n3. Adaptation and Training\n  - Backpropagation\n  - Error Functions and Surfaces\n  \n4. Working\n  - \"Repeated Weighted Averaging with Thresholding\"\n  - How does that end up \"learning\"? Is there an intuitive explanation?\n\n\n## Neural Nets in Code\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n\n### Using p5.js\n\n\n### Using R\nUsing `torch`.\n\n:::\n\n\n## References\n\n1. Mathoverflow. *Intuitive Crutches for Higher Dimensional Thinking. <https://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking>\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}