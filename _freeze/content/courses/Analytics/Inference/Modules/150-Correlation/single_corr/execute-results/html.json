{
  "hash": "2fe18826215b07ee1bd916748b6ab738",
  "result": {
    "markdown": "---\ntitle: \"Inference for Correlation\"\nauthor: \"Arvind V.\"\ndate: 25/Nov/2022\ndate-modified: \"2023-11-10\"\norder: 140\nkeywords: Statistics ; Tests; p-value; Feynman Technique\nabstract: \"Statistical Significance Tests for Correlations between two Variables\"\nbibliography: \n  - grateful-refs.bib\ncitation: true\n#suppress-bibliography: true\n---\n\n\n## {{< iconify noto-v1 package >}} Setting up R packages\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/setup_b610e60ad88d96156f8c13db5e31b762'}\n\n````{.cell-code}\n```{{r}}\n#| label: setup\n#| fig-align: center\n#| fig-dpi: 300\n\nknitr::opts_chunk$set(fig.align = \"center\", fig.width = 7, fig.height = 5)\noptions(scipen = 8, digits = 3)\n# CRAN Packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(mosaicData)\n\nlibrary(openintro) # datasets and methods\nlibrary(resampledata3) # datasets\nlibrary(statsExpressions) # datasets and methods\nlibrary(ggstatsplot) # special stats plots\nlibrary(ggExtra)\n\n# Non-CRAN Packages\n# remotes::install_github(\"easystats/easystats\")\nlibrary(easystats)\n\nggplot2::theme_set(theme_classic())\n```\n````\n:::\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Extra Pedagogical Packages_124214927ddb8a5ce56c2536152a6b66'}\n\n:::\n\n\n\n\n\n## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction\n\nLet us recap a few basic definitions:\n\nWe have already encountered the `variance` of a variable:\n\n$$\n\\begin{align*}\nvar_x &= \\frac{\\sum_{i=1}^{n}(x_i - \\mu_x)^2}{(n-1)}\\\\\nwhere ~ \\mu_x &= mean(x)\\\\\nn &= sample\\ size\n\\end{align*}\n$$\nThe *standard deviation* is:\n$$\n\n\\sigma_x &= \\sqrt{var_x}\\\\\n\n$$\n\nThe **covariance** of two variables is defined as \n$$\n\\begin{align*}\ncov(x,y) &= \\frac{\\sum_{i = 1}^{n}(x_i - \\mu_x)*(y_i - \\mu_y)}{n-1}\\\\\n&= \\frac{\\sum{x_i *y_i}}{n-1} - \\frac{\\sum{x_i *\\mu_y}}{n-1} - \\frac{\\sum{y_i *\\mu_x}}{n-1} + \\frac{\\sum{\\mu_x *\\mu_y}}{n-1}\\\\\n&= \\frac{\\sum{x_i *y_i}}{n-1} - \\frac{\\sum{\\mu_x *\\mu_y}}{n-1}\\\\\n\n\\end{align*}\n$$\nHence covariance is *the expectation of the product minus the product of the expectations* of the two variables. \n\n::: callout-tip\n### Covariance uses z-scores!\nNote that in both cases we are dealing with **z-scores**: variable minus its mean, $x_i - \\mu_x$, which we have seen when dealing with the CLT and the Gaussian Distribution. \n:::\n\nSo, finally, the coefficient of **correlation* between two variables is defined as:\n\n$$\n\\begin{align*}\ncorrelation ~ r &= \\frac{cov(x,y)}{\\sigma_x * \\sigma_y}\n\\\\\n&= \\frac{cov(x,y)}{\\sqrt{var_x} * \\sqrt{var_y}}\n\\end{align*}\n$$\nThus correlation coefficient is the *covariance scaled by the geometric mean of the variances*. Correlations define how one variables varies with another. One of the basic Questions we would have of our data is: Does some variable have a significant correlation score with another in some way? Does $y$ vary with $x$? A **Correlation Test** is designed to answer exactly this question.  The block diagram depicts the statistical procedures available to test for the significance of correlation scores between two variables. \n\n\n\n```{mermaid}\nflowchart TD\n    A[Inference for Correlation] -->|Check Assumptions| B[Normality: Shapiro-Wilk Test shapiro.test\\n Variances: Fisher F-test var.test]\n    B --> C{OK?}\n    C -->|Yes, both\\n Parametric| D[t.test]\n    D <-->F[Linear Model\\n Method] \n    C -->|Yes, but not variance\\n Parametric| W[t.test with\\n Welch Correction]\n    W<-->F\n    C -->|No\\n Non-Parametric| E[wilcox.test]\n    E <--> G[Linear Model\\n with\\n Ranked Data]\n    C -->|No\\n Non-Parametric| P[Bootstrap\\n or\\n Permutation]\n    P <--> Q[Linear Model\\n with Ranked Data\\n and Permutation]\n```\n\n \n## {{< iconify pajamas issue-type-test-case >}} Case Study #1: A Simple Data set with Two Quant Variables\n\n\nLet us now see how a Correlation Test can be re-formulated as a Linear\nModel + Hypothesis Test.\n\n\n## The Linear Model\n\nThe premise here is that **many common statistical tests are special\ncases of the linear model**. A **linear model** estimates the\nrelationship between dependent variable or \"response\" variable ($y$) and\nan explanatory variable or \"predictor\" ($x$). It is assumed that the\nrelationship is **linear**. $\\beta_0$ is the *intercept* and $\\beta_1$\nis the slope of the linear fit, that **predicts** the value of y based\nthe value of x.\n\n$$\ny = \\beta_0 + \\beta_1 *x\n$$\n\n\n\n### Some Toy Data\n\nMost examples in this exposition are based on three \"imaginary\" samples,\n$x, y1, y2$. Each is normally distributed and made up of 50\nobservations. The means and the sds are, respectively:\n\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/data_genr_001382d8e2f06777f2d3938a0c170be5'}\n\n````{.cell-code}\n```{{r data_genr}}\nrnorm_fixed  <- function(N, mu = 0, sd = 1) {\n  scale(rnorm(N))* sd + mu\n}\nparams <- tibble(mu = c(0, 0.3, 0.5), sd = c(1,2,1.5))\nparams \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mu\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sd\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.0\",\"2\":\"1.0\"},{\"1\":\"0.3\",\"2\":\"2.0\"},{\"1\":\"0.5\",\"2\":\"1.5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/toy_data_9a603f6e06ccb34431825c6f6b591eda'}\n\n````{.cell-code}\n```{{r toy_data}}\nset.seed(40) # for replication\n\n# Data as vectors ( for t.tests etc)\nx <- rnorm_fixed(50, mu = 0.0, sd = 1) #explanatory\ny1 <- rnorm_fixed(50, mu = 0.3, sd = 2) # dependent #1\ny2 <- rnorm_fixed(50, mu = 0.5, sd = 1.5) # dependent #2\n\n# Make a tibble with all variables\nmydata_wide <- tibble(x = x, y1 = y1, y2 = y2)\n\n# Long form data\nmydata_long <- \n  mydata_wide %>%\n  pivot_longer(., cols = c(x,y1,y2), \n               names_to = \"group\", \n               values_to = \"value\")\n\n# Long form data with only dependent variables\nmydata_long_y <- \n  mydata_wide %>% \n  select(-x) %>% \n  pivot_longer(., cols = c(y1,y2), \n               names_to = \"group\", \n               values_to = \"value\")\n```\n````\n:::\n\n\nLet us look at our toy data in three ways:\n\n1.  All three variables:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-4_aaf73d59b329e99d5f77264c815deec8'}\n\n````{.cell-code}\n```{{r}}\nmydata_wide \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]},{\"label\":[\"y1\"],\"name\":[2],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]},{\"label\":[\"y2\"],\"name\":[3],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.4268\",\"2\":\"1.9849\",\"3\":\"0.1030\"},{\"1\":\"0.4441\",\"2\":\"1.2713\",\"3\":\"-0.2809\"},{\"1\":\"-0.8279\",\"2\":\"-0.9443\",\"3\":\"0.6239\"},{\"1\":\"-0.7993\",\"2\":\"0.1033\",\"3\":\"5.4268\"},{\"1\":\"-0.3231\",\"2\":\"2.1904\",\"3\":\"0.1681\"},{\"1\":\"-1.2446\",\"2\":\"0.1919\",\"3\":\"-0.5494\"},{\"1\":\"-1.3551\",\"2\":\"4.8119\",\"3\":\"0.3092\"},{\"1\":\"1.6156\",\"2\":\"1.5517\",\"3\":\"-0.9904\"},{\"1\":\"-0.2919\",\"2\":\"3.3574\",\"3\":\"-0.1720\"},{\"1\":\"-1.2494\",\"2\":\"1.9249\",\"3\":\"-0.1583\"},{\"1\":\"-0.0866\",\"2\":\"-2.8805\",\"3\":\"0.8539\"},{\"1\":\"-1.1707\",\"2\":\"1.7505\",\"3\":\"3.3391\"},{\"1\":\"0.7376\",\"2\":\"-1.0843\",\"3\":\"-1.8839\"},{\"1\":\"-0.4832\",\"2\":\"0.9603\",\"3\":\"2.4843\"},{\"1\":\"0.4033\",\"2\":\"-1.5402\",\"3\":\"-0.0487\"},{\"1\":\"0.9164\",\"2\":\"-1.2436\",\"3\":\"-0.6152\"},{\"1\":\"0.4167\",\"2\":\"0.0319\",\"3\":\"-0.2868\"},{\"1\":\"0.3314\",\"2\":\"-1.3092\",\"3\":\"-0.1235\"},{\"1\":\"1.5768\",\"2\":\"-0.9966\",\"3\":\"0.2994\"},{\"1\":\"-0.9929\",\"2\":\"1.4215\",\"3\":\"-1.0676\"},{\"1\":\"1.2246\",\"2\":\"-0.9037\",\"3\":\"0.1212\"},{\"1\":\"-0.5790\",\"2\":\"2.9455\",\"3\":\"-0.4009\"},{\"1\":\"1.4903\",\"2\":\"2.5738\",\"3\":\"-1.5555\"},{\"1\":\"-1.0653\",\"2\":\"-1.2180\",\"3\":\"-0.5190\"},{\"1\":\"-1.3914\",\"2\":\"-2.1014\",\"3\":\"-0.2486\"},{\"1\":\"0.6655\",\"2\":\"0.9056\",\"3\":\"1.3567\"},{\"1\":\"-1.5322\",\"2\":\"0.5315\",\"3\":\"0.1453\"},{\"1\":\"0.2901\",\"2\":\"0.9008\",\"3\":\"0.8356\"},{\"1\":\"0.6924\",\"2\":\"0.1269\",\"3\":\"2.2918\"},{\"1\":\"-1.7605\",\"2\":\"2.6500\",\"3\":\"2.7367\"},{\"1\":\"0.7208\",\"2\":\"0.1344\",\"3\":\"0.2757\"},{\"1\":\"-1.2240\",\"2\":\"-2.7807\",\"3\":\"3.1455\"},{\"1\":\"-0.7531\",\"2\":\"1.9620\",\"3\":\"0.5994\"},{\"1\":\"1.3280\",\"2\":\"-4.2554\",\"3\":\"1.0446\"},{\"1\":\"-0.2417\",\"2\":\"0.5152\",\"3\":\"-0.6882\"},{\"1\":\"0.5529\",\"2\":\"0.3296\",\"3\":\"1.1520\"},{\"1\":\"-1.3898\",\"2\":\"0.1823\",\"3\":\"-1.8669\"},{\"1\":\"0.2063\",\"2\":\"0.7603\",\"3\":\"4.2723\"},{\"1\":\"-0.3192\",\"2\":\"3.5506\",\"3\":\"0.4508\"},{\"1\":\"0.7848\",\"2\":\"-0.5656\",\"3\":\"-1.7095\"},{\"1\":\"1.2396\",\"2\":\"-2.8808\",\"3\":\"0.8469\"},{\"1\":\"0.2746\",\"2\":\"3.0416\",\"3\":\"-0.0390\"},{\"1\":\"1.8976\",\"2\":\"-1.2941\",\"3\":\"1.1196\"},{\"1\":\"-0.1926\",\"2\":\"-3.4240\",\"3\":\"1.0516\"},{\"1\":\"-1.4137\",\"2\":\"-1.7534\",\"3\":\"1.4959\"},{\"1\":\"0.3512\",\"2\":\"1.8246\",\"3\":\"1.8645\"},{\"1\":\"1.4512\",\"2\":\"-2.3711\",\"3\":\"1.3301\"},{\"1\":\"1.1703\",\"2\":\"2.3434\",\"3\":\"-0.1423\"},{\"1\":\"-0.8390\",\"2\":\"1.8663\",\"3\":\"-0.3977\"},{\"1\":\"0.3171\",\"2\":\"-0.1498\",\"3\":\"-0.9995\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n2.  Variables stacked and labelled (Note: `group` is now a Qual variable\n    !!)\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-5_225adf24aeb450766002c6e6359bf073'}\n\n````{.cell-code}\n```{{r}}\nmydata_long \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"group\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"value\"],\"name\":[2],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"x\",\"2\":\"0.4268\"},{\"1\":\"y1\",\"2\":\"1.9849\"},{\"1\":\"y2\",\"2\":\"0.1030\"},{\"1\":\"x\",\"2\":\"0.4441\"},{\"1\":\"y1\",\"2\":\"1.2713\"},{\"1\":\"y2\",\"2\":\"-0.2809\"},{\"1\":\"x\",\"2\":\"-0.8279\"},{\"1\":\"y1\",\"2\":\"-0.9443\"},{\"1\":\"y2\",\"2\":\"0.6239\"},{\"1\":\"x\",\"2\":\"-0.7993\"},{\"1\":\"y1\",\"2\":\"0.1033\"},{\"1\":\"y2\",\"2\":\"5.4268\"},{\"1\":\"x\",\"2\":\"-0.3231\"},{\"1\":\"y1\",\"2\":\"2.1904\"},{\"1\":\"y2\",\"2\":\"0.1681\"},{\"1\":\"x\",\"2\":\"-1.2446\"},{\"1\":\"y1\",\"2\":\"0.1919\"},{\"1\":\"y2\",\"2\":\"-0.5494\"},{\"1\":\"x\",\"2\":\"-1.3551\"},{\"1\":\"y1\",\"2\":\"4.8119\"},{\"1\":\"y2\",\"2\":\"0.3092\"},{\"1\":\"x\",\"2\":\"1.6156\"},{\"1\":\"y1\",\"2\":\"1.5517\"},{\"1\":\"y2\",\"2\":\"-0.9904\"},{\"1\":\"x\",\"2\":\"-0.2919\"},{\"1\":\"y1\",\"2\":\"3.3574\"},{\"1\":\"y2\",\"2\":\"-0.1720\"},{\"1\":\"x\",\"2\":\"-1.2494\"},{\"1\":\"y1\",\"2\":\"1.9249\"},{\"1\":\"y2\",\"2\":\"-0.1583\"},{\"1\":\"x\",\"2\":\"-0.0866\"},{\"1\":\"y1\",\"2\":\"-2.8805\"},{\"1\":\"y2\",\"2\":\"0.8539\"},{\"1\":\"x\",\"2\":\"-1.1707\"},{\"1\":\"y1\",\"2\":\"1.7505\"},{\"1\":\"y2\",\"2\":\"3.3391\"},{\"1\":\"x\",\"2\":\"0.7376\"},{\"1\":\"y1\",\"2\":\"-1.0843\"},{\"1\":\"y2\",\"2\":\"-1.8839\"},{\"1\":\"x\",\"2\":\"-0.4832\"},{\"1\":\"y1\",\"2\":\"0.9603\"},{\"1\":\"y2\",\"2\":\"2.4843\"},{\"1\":\"x\",\"2\":\"0.4033\"},{\"1\":\"y1\",\"2\":\"-1.5402\"},{\"1\":\"y2\",\"2\":\"-0.0487\"},{\"1\":\"x\",\"2\":\"0.9164\"},{\"1\":\"y1\",\"2\":\"-1.2436\"},{\"1\":\"y2\",\"2\":\"-0.6152\"},{\"1\":\"x\",\"2\":\"0.4167\"},{\"1\":\"y1\",\"2\":\"0.0319\"},{\"1\":\"y2\",\"2\":\"-0.2868\"},{\"1\":\"x\",\"2\":\"0.3314\"},{\"1\":\"y1\",\"2\":\"-1.3092\"},{\"1\":\"y2\",\"2\":\"-0.1235\"},{\"1\":\"x\",\"2\":\"1.5768\"},{\"1\":\"y1\",\"2\":\"-0.9966\"},{\"1\":\"y2\",\"2\":\"0.2994\"},{\"1\":\"x\",\"2\":\"-0.9929\"},{\"1\":\"y1\",\"2\":\"1.4215\"},{\"1\":\"y2\",\"2\":\"-1.0676\"},{\"1\":\"x\",\"2\":\"1.2246\"},{\"1\":\"y1\",\"2\":\"-0.9037\"},{\"1\":\"y2\",\"2\":\"0.1212\"},{\"1\":\"x\",\"2\":\"-0.5790\"},{\"1\":\"y1\",\"2\":\"2.9455\"},{\"1\":\"y2\",\"2\":\"-0.4009\"},{\"1\":\"x\",\"2\":\"1.4903\"},{\"1\":\"y1\",\"2\":\"2.5738\"},{\"1\":\"y2\",\"2\":\"-1.5555\"},{\"1\":\"x\",\"2\":\"-1.0653\"},{\"1\":\"y1\",\"2\":\"-1.2180\"},{\"1\":\"y2\",\"2\":\"-0.5190\"},{\"1\":\"x\",\"2\":\"-1.3914\"},{\"1\":\"y1\",\"2\":\"-2.1014\"},{\"1\":\"y2\",\"2\":\"-0.2486\"},{\"1\":\"x\",\"2\":\"0.6655\"},{\"1\":\"y1\",\"2\":\"0.9056\"},{\"1\":\"y2\",\"2\":\"1.3567\"},{\"1\":\"x\",\"2\":\"-1.5322\"},{\"1\":\"y1\",\"2\":\"0.5315\"},{\"1\":\"y2\",\"2\":\"0.1453\"},{\"1\":\"x\",\"2\":\"0.2901\"},{\"1\":\"y1\",\"2\":\"0.9008\"},{\"1\":\"y2\",\"2\":\"0.8356\"},{\"1\":\"x\",\"2\":\"0.6924\"},{\"1\":\"y1\",\"2\":\"0.1269\"},{\"1\":\"y2\",\"2\":\"2.2918\"},{\"1\":\"x\",\"2\":\"-1.7605\"},{\"1\":\"y1\",\"2\":\"2.6500\"},{\"1\":\"y2\",\"2\":\"2.7367\"},{\"1\":\"x\",\"2\":\"0.7208\"},{\"1\":\"y1\",\"2\":\"0.1344\"},{\"1\":\"y2\",\"2\":\"0.2757\"},{\"1\":\"x\",\"2\":\"-1.2240\"},{\"1\":\"y1\",\"2\":\"-2.7807\"},{\"1\":\"y2\",\"2\":\"3.1455\"},{\"1\":\"x\",\"2\":\"-0.7531\"},{\"1\":\"y1\",\"2\":\"1.9620\"},{\"1\":\"y2\",\"2\":\"0.5994\"},{\"1\":\"x\",\"2\":\"1.3280\"},{\"1\":\"y1\",\"2\":\"-4.2554\"},{\"1\":\"y2\",\"2\":\"1.0446\"},{\"1\":\"x\",\"2\":\"-0.2417\"},{\"1\":\"y1\",\"2\":\"0.5152\"},{\"1\":\"y2\",\"2\":\"-0.6882\"},{\"1\":\"x\",\"2\":\"0.5529\"},{\"1\":\"y1\",\"2\":\"0.3296\"},{\"1\":\"y2\",\"2\":\"1.1520\"},{\"1\":\"x\",\"2\":\"-1.3898\"},{\"1\":\"y1\",\"2\":\"0.1823\"},{\"1\":\"y2\",\"2\":\"-1.8669\"},{\"1\":\"x\",\"2\":\"0.2063\"},{\"1\":\"y1\",\"2\":\"0.7603\"},{\"1\":\"y2\",\"2\":\"4.2723\"},{\"1\":\"x\",\"2\":\"-0.3192\"},{\"1\":\"y1\",\"2\":\"3.5506\"},{\"1\":\"y2\",\"2\":\"0.4508\"},{\"1\":\"x\",\"2\":\"0.7848\"},{\"1\":\"y1\",\"2\":\"-0.5656\"},{\"1\":\"y2\",\"2\":\"-1.7095\"},{\"1\":\"x\",\"2\":\"1.2396\"},{\"1\":\"y1\",\"2\":\"-2.8808\"},{\"1\":\"y2\",\"2\":\"0.8469\"},{\"1\":\"x\",\"2\":\"0.2746\"},{\"1\":\"y1\",\"2\":\"3.0416\"},{\"1\":\"y2\",\"2\":\"-0.0390\"},{\"1\":\"x\",\"2\":\"1.8976\"},{\"1\":\"y1\",\"2\":\"-1.2941\"},{\"1\":\"y2\",\"2\":\"1.1196\"},{\"1\":\"x\",\"2\":\"-0.1926\"},{\"1\":\"y1\",\"2\":\"-3.4240\"},{\"1\":\"y2\",\"2\":\"1.0516\"},{\"1\":\"x\",\"2\":\"-1.4137\"},{\"1\":\"y1\",\"2\":\"-1.7534\"},{\"1\":\"y2\",\"2\":\"1.4959\"},{\"1\":\"x\",\"2\":\"0.3512\"},{\"1\":\"y1\",\"2\":\"1.8246\"},{\"1\":\"y2\",\"2\":\"1.8645\"},{\"1\":\"x\",\"2\":\"1.4512\"},{\"1\":\"y1\",\"2\":\"-2.3711\"},{\"1\":\"y2\",\"2\":\"1.3301\"},{\"1\":\"x\",\"2\":\"1.1703\"},{\"1\":\"y1\",\"2\":\"2.3434\"},{\"1\":\"y2\",\"2\":\"-0.1423\"},{\"1\":\"x\",\"2\":\"-0.8390\"},{\"1\":\"y1\",\"2\":\"1.8663\"},{\"1\":\"y2\",\"2\":\"-0.3977\"},{\"1\":\"x\",\"2\":\"0.3171\"},{\"1\":\"y1\",\"2\":\"-0.1498\"},{\"1\":\"y2\",\"2\":\"-0.9995\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n3.  Same as 2, but only for the dependent `y` variables:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-6_f1c7f0eda63005eb60a1ee963721799c'}\n\n````{.cell-code}\n```{{r}}\nmydata_long_y \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"group\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"value\"],\"name\":[2],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"y1\",\"2\":\"1.9849\"},{\"1\":\"y2\",\"2\":\"0.1030\"},{\"1\":\"y1\",\"2\":\"1.2713\"},{\"1\":\"y2\",\"2\":\"-0.2809\"},{\"1\":\"y1\",\"2\":\"-0.9443\"},{\"1\":\"y2\",\"2\":\"0.6239\"},{\"1\":\"y1\",\"2\":\"0.1033\"},{\"1\":\"y2\",\"2\":\"5.4268\"},{\"1\":\"y1\",\"2\":\"2.1904\"},{\"1\":\"y2\",\"2\":\"0.1681\"},{\"1\":\"y1\",\"2\":\"0.1919\"},{\"1\":\"y2\",\"2\":\"-0.5494\"},{\"1\":\"y1\",\"2\":\"4.8119\"},{\"1\":\"y2\",\"2\":\"0.3092\"},{\"1\":\"y1\",\"2\":\"1.5517\"},{\"1\":\"y2\",\"2\":\"-0.9904\"},{\"1\":\"y1\",\"2\":\"3.3574\"},{\"1\":\"y2\",\"2\":\"-0.1720\"},{\"1\":\"y1\",\"2\":\"1.9249\"},{\"1\":\"y2\",\"2\":\"-0.1583\"},{\"1\":\"y1\",\"2\":\"-2.8805\"},{\"1\":\"y2\",\"2\":\"0.8539\"},{\"1\":\"y1\",\"2\":\"1.7505\"},{\"1\":\"y2\",\"2\":\"3.3391\"},{\"1\":\"y1\",\"2\":\"-1.0843\"},{\"1\":\"y2\",\"2\":\"-1.8839\"},{\"1\":\"y1\",\"2\":\"0.9603\"},{\"1\":\"y2\",\"2\":\"2.4843\"},{\"1\":\"y1\",\"2\":\"-1.5402\"},{\"1\":\"y2\",\"2\":\"-0.0487\"},{\"1\":\"y1\",\"2\":\"-1.2436\"},{\"1\":\"y2\",\"2\":\"-0.6152\"},{\"1\":\"y1\",\"2\":\"0.0319\"},{\"1\":\"y2\",\"2\":\"-0.2868\"},{\"1\":\"y1\",\"2\":\"-1.3092\"},{\"1\":\"y2\",\"2\":\"-0.1235\"},{\"1\":\"y1\",\"2\":\"-0.9966\"},{\"1\":\"y2\",\"2\":\"0.2994\"},{\"1\":\"y1\",\"2\":\"1.4215\"},{\"1\":\"y2\",\"2\":\"-1.0676\"},{\"1\":\"y1\",\"2\":\"-0.9037\"},{\"1\":\"y2\",\"2\":\"0.1212\"},{\"1\":\"y1\",\"2\":\"2.9455\"},{\"1\":\"y2\",\"2\":\"-0.4009\"},{\"1\":\"y1\",\"2\":\"2.5738\"},{\"1\":\"y2\",\"2\":\"-1.5555\"},{\"1\":\"y1\",\"2\":\"-1.2180\"},{\"1\":\"y2\",\"2\":\"-0.5190\"},{\"1\":\"y1\",\"2\":\"-2.1014\"},{\"1\":\"y2\",\"2\":\"-0.2486\"},{\"1\":\"y1\",\"2\":\"0.9056\"},{\"1\":\"y2\",\"2\":\"1.3567\"},{\"1\":\"y1\",\"2\":\"0.5315\"},{\"1\":\"y2\",\"2\":\"0.1453\"},{\"1\":\"y1\",\"2\":\"0.9008\"},{\"1\":\"y2\",\"2\":\"0.8356\"},{\"1\":\"y1\",\"2\":\"0.1269\"},{\"1\":\"y2\",\"2\":\"2.2918\"},{\"1\":\"y1\",\"2\":\"2.6500\"},{\"1\":\"y2\",\"2\":\"2.7367\"},{\"1\":\"y1\",\"2\":\"0.1344\"},{\"1\":\"y2\",\"2\":\"0.2757\"},{\"1\":\"y1\",\"2\":\"-2.7807\"},{\"1\":\"y2\",\"2\":\"3.1455\"},{\"1\":\"y1\",\"2\":\"1.9620\"},{\"1\":\"y2\",\"2\":\"0.5994\"},{\"1\":\"y1\",\"2\":\"-4.2554\"},{\"1\":\"y2\",\"2\":\"1.0446\"},{\"1\":\"y1\",\"2\":\"0.5152\"},{\"1\":\"y2\",\"2\":\"-0.6882\"},{\"1\":\"y1\",\"2\":\"0.3296\"},{\"1\":\"y2\",\"2\":\"1.1520\"},{\"1\":\"y1\",\"2\":\"0.1823\"},{\"1\":\"y2\",\"2\":\"-1.8669\"},{\"1\":\"y1\",\"2\":\"0.7603\"},{\"1\":\"y2\",\"2\":\"4.2723\"},{\"1\":\"y1\",\"2\":\"3.5506\"},{\"1\":\"y2\",\"2\":\"0.4508\"},{\"1\":\"y1\",\"2\":\"-0.5656\"},{\"1\":\"y2\",\"2\":\"-1.7095\"},{\"1\":\"y1\",\"2\":\"-2.8808\"},{\"1\":\"y2\",\"2\":\"0.8469\"},{\"1\":\"y1\",\"2\":\"3.0416\"},{\"1\":\"y2\",\"2\":\"-0.0390\"},{\"1\":\"y1\",\"2\":\"-1.2941\"},{\"1\":\"y2\",\"2\":\"1.1196\"},{\"1\":\"y1\",\"2\":\"-3.4240\"},{\"1\":\"y2\",\"2\":\"1.0516\"},{\"1\":\"y1\",\"2\":\"-1.7534\"},{\"1\":\"y2\",\"2\":\"1.4959\"},{\"1\":\"y1\",\"2\":\"1.8246\"},{\"1\":\"y2\",\"2\":\"1.8645\"},{\"1\":\"y1\",\"2\":\"-2.3711\"},{\"1\":\"y2\",\"2\":\"1.3301\"},{\"1\":\"y1\",\"2\":\"2.3434\"},{\"1\":\"y2\",\"2\":\"-0.1423\"},{\"1\":\"y1\",\"2\":\"1.8663\"},{\"1\":\"y2\",\"2\":\"-0.3977\"},{\"1\":\"y1\",\"2\":\"-0.1498\"},{\"1\":\"y2\",\"2\":\"-0.9995\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n# Tests for Correlation\n\nCorrelation **r** is a measure of *strength* and *direction* of *linear\nassociation* between two variables. **r** is between $[-1,+1]$, with $0$\nimplying no association/correlation.\n\nFrom this definition, the *linear model* lends itself in a\nstraightforward way as a model to interpret *correlation*. Intuitively,\nthe slope of the linear model could be related to the correlation\nbetween y and x.\n\nNow we look at the numbers.\n\n## Pearson Correlation\n\n### Model\n\nThe model for Pearson Correlation tests is exactly the Linear Model:\n\n$$\n\\begin{aligned}\ny = \\beta_0 + \\beta_1 \\times x\\\\\n\\\\\nH_0: Null\\ Hypothesis\\ => \\beta_1 = 0\\\\\\\nH_a: Alternate\\ Hypothesis\\ => \\beta_1 \\ne 0\\\\\n\\end{aligned}\n$$\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Pearson_Correlation_60013176a31c028dc1826dc417812539'}\n\n````{.cell-code}\n```{{r Pearson_Correlation}}\n# Pearson (built-in test)\ncor <- cor.test(y1,x,method = \"pearson\") %>% \n  broom::tidy() %>% mutate(term = \"Pearson Correlation r\") %>% select(term, estimate, p.value) \ncor \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Pearson Correlation r\",\"2\":\"-0.232\",\"3\":\"0.105\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nUsing the *linear model* method we get:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-7_27a61504d4fdba579c745438c0e02f75'}\n\n````{.cell-code}\n```{{r}}\n# Linear Model\nlin <- lm(y1 ~ 1 + x, data = mydata_wide) %>% \n  broom::tidy() %>% mutate(term = c(\"beta_0\", \"beta_1\")) %>% select(term, estimate, p.value)\nlin \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"beta_0\",\"2\":\"0.300\",\"3\":\"0.286\"},{\"1\":\"beta_1\",\"2\":\"-0.464\",\"3\":\"0.105\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWhy are $r$ and $\\beta_1$ different, though the `p-value` is\nsuspiciously the same!?\n\nDid we miss a factor of $\\frac{-0.463}{-0.231} = 2$ somewhere...??\n\nLet us **scale** the variables to within `{-1, +1}` : (subtract the mean\nand divide by sd) and re-do the Linear Model with **scaled** versions\n$x$ and $y$:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-8_9d429e81adaa852233f888764716e82d'}\n\n````{.cell-code}\n```{{r}}\n# Scaled linear model\nlin_scl <- lm(scale(y1) ~ 1 + scale(x), data = mydata_wide) %>% \n  broom::tidy() %>% mutate(term = c(\"beta_0\", \"beta_1\")) %>% select(term, estimate, p.value) %>% select(term, estimate, p.value)\nlin_scl \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"beta_0\",\"2\":\"-9.06e-17\",\"3\":\"1.000\"},{\"1\":\"beta_1\",\"2\":\"-2.32e-01\",\"3\":\"0.105\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nSo we conclude:\n\n1.  **When both x and y have the same standard deviation, the slope from\n    the linear model and the Pearson correlation are the same**. Here,\n    since x has twice the `sd` of y, the ratio of **slope** =\n    -0.464 to **r** = -0.232 is 0.5.\n\n2.  There is this relationship between the **slope in the linear model**\n    and **Pearson correlation**:\n\n$$\nSlope\\ \\beta_1 = \\frac{sd_y}{sd_x} * r\n$$\n\nThe slope is usually much more interpretable and informative than the\ncorrelation coefficient.\n\n2.  Hence a linear model using `scale()` for both variables will show\n    slope = **r**.\n\nSlope_Scaled: -0.232 = Correlation: -0.232\n\n3.  Finally, the *p-value* for Pearson Correlation and that for the\n    *slope* in the linear model is the same ($0.1053$). Which means we\n    cannot reject the NULL hypothesis of \"no relationship\".\n\n### Example\n\nTBD\n\n## Spearman Correlation\n\n### Model\n\nIn some cases the **LINE** assumptions may not hold.\n\nNonlinear relationships, non-normally distributed data ( with large\n**outliers** ) and working with *ordinal* rather than continuous data:\nthese situations necessitate the use of Spearman's *ranked* correlation\nscores. (**Ranked**, not **sign-ranked**.).\n\nSee the example below: We choose to look at the `gpa_study_hours`\ndataset. It has two numeric columns `gpa` and `study_hours`:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/gpa_study_hours_8c647824724b7294999d96be541c3dfe'}\n\n````{.cell-code}\n```{{r gpa_study_hours}}\nglimpse(gpa_study_hours)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 193\nColumns: 2\n$ gpa         <dbl> 4.00, 3.80, 3.93, 3.40, 3.20, 3.52, 3.68, 3.40, 3.70, 3.75…\n$ study_hours <dbl> 10, 25, 45, 10, 4, 10, 24, 40, 10, 10, 30, 7, 15, 60, 10, …\n```\n:::\n:::\n\n\nWe can plot this:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Pearson_example_3_98867f98b2b2913ec9c659d4de784dd3'}\n\n````{.cell-code}\n```{{r Pearson_example_3}}\nggplot(gpa_study_hours, aes(x = study_hours, y = gpa)) + geom_point() + geom_smooth() + theme_minimal()\n# ggstatsplot::ggscatterstats(data = gpa_study_hours, \n#                             x = study_hours, \n#                             y = gpa,\n#                             marginal = TRUE,\n#                             title = \"GPA vs Study Hours\")\n```\n````\n\n::: {.cell-output-display}\n![](single_corr_files/figure-html/Pearson_example_3-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nHmm...not normally distributed, and there is a sort of increasing\nrelationship, however is it linear? And there is some evidence of\nheteroscedasticity, so the LINE assumptions are clearly in violation.\nPearson correlation would not be the best idea here.\n\nLet us quickly try it anyway, using a Linear Model for the **scaled**\n`gpa` and `study_hours` variables, from where we get:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Pearson_example_1_c1edaa35762b8e5c6ad045507e91f724'}\n\n````{.cell-code}\n```{{r Pearson_example_1}}\n# Pearson Correlation as Linear Model\nmodel_gpa <-\n  lm(scale(gpa) ~ 1 + scale(study_hours), data = gpa_study_hours)\n\nmodel_gpa %>%\n  broom::tidy() %>% \n  mutate(term = c(\"beta_0\", \"beta_1\")) %>% \n  cbind(confint(model_gpa) %>%                                              as_tibble()) %>%  \n  select(term, estimate, p.value, `2.5 %`, `97.5 %`)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"2.5 %\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"97.5 %\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"beta_0\",\"2\":\"3.05e-16\",\"3\":\"1.0000\",\"4\":\"-0.14109\",\"5\":\"0.141\"},{\"1\":\"beta_1\",\"2\":\"1.33e-01\",\"3\":\"0.0652\",\"4\":\"-0.00844\",\"5\":\"0.274\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe correlation estimate is $0.133$; the `p-value` is $0.065$ (and the\n`confidence interval` includes $0$).\n\nHence we fail to reject the NULL hypothesis that `study_hours` and `gpa`\nhave no relationship. But can this be right?\n\nShould we use another test, that does not **need** the LINE assumptions?\n\n## \"Signed Rank\" Values\n\nMost statistical tests use the **actual values** of the data variables.\nHowever, in some *non-parametric* statistical tests, the data are used\nin **rank-transformed** sense/order. (In some cases the **signed-rank**\nof the data values is used instead of the data itself.)\n\n**Signed Rank** is calculated as follows:\n\n1.  Take the absolute value of each observation in a sample\n\n2.  Place the <u>*ranks*</u> in order of (absolute magnitude). The\n    smallest number has *rank = 1* and so on. This gives is **ranked\n    data**.\n\n3.  Give each of the ranks the sign of the original observation ( + or\n    -). This gives us **signed** ranked data.\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/signed_rank_function_24ecec110091e47f277242e0b8f6120c'}\n\n````{.cell-code}\n```{{r signed_rank_function}}\nsigned_rank <- function(x) {sign(x) * rank(abs(x))}\n```\n````\n:::\n\n\n## Plotting Original and Signed Rank Data\n\nLet us see how this might work by comparing data and its signed-rank\nversion...A quick set of plots:\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/data_plots_a1065895615db553a1f551b957f1e142'}\n\n````{.cell-code}\n```{{r data_plots}}\np1 <- ggplot(mydata_long,aes(x = group, y = value)) +\n  geom_jitter(width = 0.02, height = 0,aes(colour = group), size = 4) +\n  geom_segment(data = mydata_wide, aes(y = 0, yend = 0, \n                                       x = .75, \n                                       xend = 1.25 )) + \n  geom_text(aes(x = 1, y = 0.5, label = \"0\")) +\n  geom_segment(data = mydata_wide, aes(y = 0.3, yend = 0.3, \n                                       x = 1.75 , \n                                       xend = 2.25 )) + \n  geom_text(aes(x = 2, y = 0.6, label = \"0.3\")) +\n  geom_segment(data = mydata_wide, aes(y = 0.5, yend = 0.5, \n                                       x = 2.75, \n                                       xend = 3.25 )) + \n  geom_text(aes(x = 3, y = 0.8, label = \"0.5\")) +\n  labs(title = \"Original Data\", subtitle = \"Black Lines show Means\") +\n  ylab(\"Response Variable\")\n\np2 <- mydata_long %>% \n  group_by(group) %>% \n  mutate( s_value = signed_rank(value)) %>% \n  ggplot(., aes(x = group, y = s_value)) + \n  geom_jitter(width = 0.02, height = 0,aes(colour = group), size = 4) + \n  stat_summary(fun = \"mean\", geom = \"point\", colour = \"red\", \n               size = 8) + \n  labs(title = \"Signed Rank of Data\", subtitle = \"Red Points are means of Ranks!\") +\n  ylab(\"Signed Rank of Response Variable\")\n\npatchwork::wrap_plots(p1,p2, nrow = 1, guides = \"collect\")\n```\n````\n\n::: {.cell-output-display}\n![](single_corr_files/figure-html/data_plots-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nSo the means of the **ranks** three separate variables seem to be in the\nsame order as the means of the data variables themselves.\n\nHow about associations between data? Do ranks reflect well what the data\nmight?\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Spearman_Plot_91cf5cb1816a6a2a890076a48c908c10'}\n\n````{.cell-code}\n```{{r Spearman_Plot}}\n# Plot the data\np1 <- ggplot(mydata_wide, aes(x, y1)) + \n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  ggtitle(\" Pearson Correlation\\n and Linear Models\")\n\n# Plot ranked data\np2 <- mydata_wide %>% \n  mutate(x_rank = rank(x),\n         y_rank = rank(y1)) %>%\n  ggplot(.,aes(x_rank, y_rank)) + \n  geom_point(shape = 15, size = 2) +\n  geom_smooth(method = \"lm\") + \n  ggtitle(\" Spearman Ranked Correlation\\n and Linear Models\")\n\npatchwork::wrap_plots(p1,p2, nrow = 1, guides = \"collect\")\n```\n````\n\n::: {.cell-output-display}\n![](single_corr_files/figure-html/Spearman_Plot-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nThe slopes are almost identical, $0.25$ for both original data and\nranked data for $y1\\sim x$. So maybe *ranked* and even *sign_ranked*\ndata could work, and if it can work despite LINE assumptions not being\nsatisfied, that would be nice!\n\n## How does Sign-Rank data work?\n\nTBD: need to add some explanation here.\n\nSpearman correlation = Pearson correlation using the rank of the data\nobservations. Let's check how this holds for a our x and y1 data:\n\nSo the Linear Model for the Ranked Data would be:\n\n$$\n\\begin{aligned}\ny = \\beta_0 + \\beta_1 \\times rank(x)\\\\\n\\\\\nH_0: Null\\ Hypothesis\\ => \\beta_1 = 0\\\\\\\nH_a: Alternate\\ Hypothesis\\ => \\beta_1 \\ne 0\\\\\n\\end{aligned}\n$$\n\n### Code\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Spearman_Correlation_c01804348911d99ae13e2e097897291c'}\n\n````{.cell-code}\n```{{r Spearman_Correlation}}\n# Spearman\ncor1 <- cor.test(x,y1, method = \"spearman\") %>% \n  broom::tidy() %>% mutate(term = \"Spearman Correlation \") %>% select(term, estimate, p.value)\ncor1\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Spearman Correlation\",\"2\":\"-0.227\",\"3\":\"0.113\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-9_2905894fcfbbad97c351d5f3af29f9dd'}\n\n````{.cell-code}\n```{{r}}\n# Pearson using ranks\ncor2 <- cor.test(rank(y1), rank(x), method = \"pearson\") %>% \nbroom::tidy() %>% select(estimate, p.value)\ncor2\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"estimate\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.227\",\"2\":\"0.114\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-10_530cee292d21173b9450e221d9188f43'}\n\n````{.cell-code}\n```{{r}}\n# Linear Models using rank\ncor3 <- lm(rank(y1) ~ 1 + rank(x),data = mydata_wide) %>% \n  broom::tidy() %>% select(estimate, p.value)\ncor3\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"estimate\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"31.278\",\"2\":\"0.000000000911\"},{\"1\":\"-0.227\",\"2\":\"0.113545171148\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNotes:\n\n1.  When ranks are used, the slope of the linear model ($\\beta_1$) has\n    the same value as the Spearman correlation coefficient ( $\\rho$ ).\n\n2.  Note that the slope from the linear model now has an intuitive\n    interpretation: **the number of ranks y changes for each change in\n    rank of x**. ( Ranks are \"independent\" of `sd` )\n\n### Example\n\nWe examine the `cars93` data, where the numeric variables of interest\nare `weight` and `price`.\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Spearman_example_1_2426055cce377616e0c34f864dcb9b62'}\n\n````{.cell-code}\n```{{r Spearman_example_1}}\ncars93 %>% \n  ggplot(aes(weight, price)) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE, lty = 2) + \n  labs(title = \"Car Weight and Car Price have a nonlinear relationship\")\n```\n````\n\n::: {.cell-output-display}\n![](single_corr_files/figure-html/Spearman_example_1-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nLet us try a Spearman Correlation score for these variables, since the\ndata are not linearly related and the variance of `price` also is not\nconstant over `weight`\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/Spearman_example_2_a11136684478f16281e2cadd06500ec2'}\n\n````{.cell-code}\n```{{r Spearman_example_2}}\ncor.test(cars93$price, cars93$weight, method = \"spearman\") %>% broom::tidy()\n\n# Using linear Model\nlm(rank(price) ~ rank(weight), data = cars93) %>% summary()\n\n# Stats Plot\nggstatsplot::ggscatterstats(data = cars93, x = weight, \n                            y = price,\n                            type = \"nonparametric\",\n                            title = \"Cars93: Weight vs Price\",\n                            subtitle = \"Spearman Correlation\")\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"estimate\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"alternative\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"0.883\",\"2\":\"3074\",\"3\":\"1.07e-18\",\"4\":\"Spearman's rank correlation rho\",\"5\":\"two.sided\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = rank(price) ~ rank(weight), data = cars93)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.068  -3.014   0.782   3.693  20.410 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    3.2207     2.0589    1.56     0.12    \nrank(weight)   0.8829     0.0651   13.55   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.46 on 52 degrees of freedom\nMultiple R-squared:  0.779,\tAdjusted R-squared:  0.775 \nF-statistic:  184 on 1 and 52 DF,  p-value: <2e-16\n```\n:::\n\n::: {.cell-output-display}\n![](single_corr_files/figure-html/Spearman_example_2-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nWe see that using ranks of the `price` variable, we obtain a Spearman's\n$\\rho = 0.882$ with a `p-value` that is very small. Hence we are able to\nreject the NULL hypothesis and state that there is a relationship\nbetween these two variables. The **linear** relationship is evaluated as\na correlation of `0.882`.\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-11_03d059e98739e1ab40d8939b21c850ff'}\n\n````{.cell-code}\n```{{r}}\n# Other ways using other packages\nmosaic::cor_test(gpa ~ study_hours, data = gpa_study_hours) %>% broom:: tidy() %>% select(estimate, p.value, conf.low, conf.high)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"estimate\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.133\",\"2\":\"0.0652\",\"3\":\"-0.00838\",\"4\":\"0.269\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-12_72b01eadb85adf2726131e85e26e2567'}\n\n````{.cell-code}\n```{{r}}\nstatsExpressions::corr_test(data = gpa_study_hours, \n                            x = study_hours, \n                            y = gpa)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"parameter1\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"parameter2\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"effectsize\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.level\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df.error\"],\"name\":[9],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[11],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n.obs\"],\"name\":[12],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"conf.method\"],\"name\":[13],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"expression\"],\"name\":[14],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"study_hours\",\"2\":\"gpa\",\"3\":\"Pearson correlation\",\"4\":\"0.133\",\"5\":\"0.95\",\"6\":\"-0.00838\",\"7\":\"0.269\",\"8\":\"1.85\",\"9\":\"191\",\"10\":\"0.0652\",\"11\":\"Pearson correlation\",\"12\":\"193\",\"13\":\"normal\",\"14\":\"<language>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## {{< iconify ooui references-rtl >}} References\n\n::: {#refs style=\"font-size: 60%;\"}\n\\\n*Common statistical tests are linear models (or: how to teach\n    stats)* by [Jonas Kristoffer Lindeløv](https://lindeloev.github.io/tests-as-linear/)\\\n    [CheatSheet](https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf)\\\n    *Common statistical tests are linear models: a work through* by [Steve Doogue](https://steverxd.github.io/Stat_tests/)\\\n    [Jeffrey Walker \"Elements of Statistical Modeling for Experimental Biology\"](https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/)\\\n    Diez, David M & Barr, Christopher D & Çetinkaya-Rundel, Mine: [OpenIntro Statistics](https://www.openintro.org/book/os/)\\\n    Modern Statistics with R: From wrangling and exploring data to inference and predictive modelling by [Måns\n    Thulin](http://www.modernstatisticswithr.com/)\\\n    [Jeffrey Walker \"A\n    linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables\"](https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/intro-linear-models.html#a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables)\n    \n    \n\n\n\n::: {.cell layout-align=\"center\" hash='single_corr_cache/html/unnamed-chunk-13_fbfda54ea526dac25058520405231a88'}\n::: {.cell-output-display}\nPackage            Version   Citation          \n-----------------  --------  ------------------\neasystats          0.7.0     @easystats        \nggExtra            0.10.1    @ggExtra          \nggstatsplot        0.12.1    @ggstatsplot      \nopenintro          2.4.0     @openintro        \nresampledata3      1.0       @resampledata3    \nstatsExpressions   1.5.2     @statsExpressions\n:::\n:::\n\n\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}