{
  "hash": "becf0c4220fa42bf2f7d28f3e691cd4a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"\\U0001F0CF Inference Test for Two Proportions\"\nauthor: \"Arvind V.\"\ndate: 10/Nov/2022\nabstract: \"Inference Test for Two Proportions\"\nlastmod: \"2024-09-14\"\norder: 190\nimage: preview.jpg\nimage-alt: From The Internet Archive\ncategories:\n- Permutation\n- Monte Carlo Simulation\n- Random Number Generation\n- Distributions\n- Generating Parallel Worlds\nbibliography: \n  - grateful-refs.bib\ncitation: true\n#suppress-bibliography: true\n---\n\n\n\n\n## {{< iconify noto-v1 package >}} Setting up R packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(ggmosaic) # plotting mosaic plots for Categorical Data\n\n### Dataset from Chihara and Hesterberg's book (Second Edition)\nlibrary(resampledata)\nlibrary(vcd)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction\n\nMany experiments gather qualitative data across different segments of a population, for example, opinion about a topic among people who belog to different income groups, or who live in different parts of a city. This should remind us of the [Likert Plots](../../../Descriptive/Modules/45-SurveyData/index.qmd) that we plotted earlier. In this case the two variables, dependent and independent, are both Qualitative, and we can calculate [counts and proportions](../../../Descriptive/Modules/40-CatData/index.qmd). \n\nHow does one Qual variable affect the other? How do counts/proportions of the `dependent variable` vary with the `levels` of the `independent` variable? This is our task for this module. \n\nHere is a quick example of the kind of data we might look at here, taken from the [British Medical Journal](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests):\n\n![Breast Feeding](../../../../../materials/images/table-83.webp){#fig-breast-feeding}\n\nClearly, we can see differences in counts/proportions of women who breast-fed their babies for three months or more, *based on* whether they were \"printers wives\" or \"farmers' wives\"! Is there a doctor in the [House](https://www.imdb.com/title/tt0412142/)?\n\n\n### {{< iconify flat-color-icons workflow >}} The CLT for Two Proportions\nWe first need to establish some model assumptions prior to making our analysis. As before, we wish to see if the CLT applies here, and if so, in what form. \nThe difference between two proportions can be modeled using a normal distribution when:\n\n- Independence (extended): The data are independent within and between the two groups. Generally this is satisfied if the data come from two independent random samples or if the data come from a randomized experiment.\n- **Success-failure condition**: The success-failure condition holds for both groups, where we check successes and failures in each group separately. That is, we should have at least 10 successes and 10 failures in each of the two groups.\n\nWhen these conditions are satisfied, the standard error of $\\hat{p_1}-\\hat{p_2}$ is well-approximated by:\n\n$$\nSE(\\hat{p_1}-\\hat{p_2}) = \\sqrt{\\frac{\\hat{p_1}*(1-\\hat{p_1})}{n_1}} + \\sqrt{\\frac{\\hat{p_2}*(1-\\hat{p_2})}{n_2}}\n$$\n\nwhere $\\hat{p_1}$ and $\\hat{p_2}$ represent the sample proportions, and $n_1$ and $n_2$ represent the sample sizes.\n\nWe can represent the Confidence Intervals as:\n\n$$\n\\begin{eqnarray}\nCI(p_1 - p_2) &=& (\\hat{p_1} - \\hat{p_2}) \\pm 1.96 * SE(\\hat{p_1}-\\hat{p_2})\\\\\n&=& (\\hat{p_1} - \\hat{p_2}) \\pm 1.96 * \\left(\\sqrt{\\frac{\\hat{p_1}*(1-\\hat{p_1})}{n_1}} + \\sqrt{\\frac{\\hat{p_2}*(1-\\hat{p_2})}{n_2}}\\right)\n\\end{eqnarray}\n$$\n\n## {{< iconify grommet-icons test >}} {{< iconify lucide ratio >}} Inference for Proportions Case Study-1: `GSS2002` dataset\n\nWe saw how we could perform inference for a single proportion. We can extend this idea to *multiple proportions* too.\n\nLet us try a dataset with Qualitative / Categorical data. This is the `General Social Survey GSS dataset` from the [`resampledata`\npackage](https://github.com/rudeboybert/resampledata), and we have\npeople with different levels of `Education` stating their opinion on the\n`Death Penalty`. We want to know if these two Categorical variables have\na correlation, i.e. can the opinions in favour of the `Death Penalty` be\nexplained by the `Education` level?\n\nSince data is Categorical ( both variables ), we need to take `counts`\nin a table, and then implement a `chi-square test`. In the test, we will\npermute the `Education` variable to see if we can see how significant\nits *effect size* is.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(GSS2002, package = \"resampledata\")\nglimpse(GSS2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,765\nColumns: 21\n$ ID            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ Region        <fct> South Central, South Central, South Central, South Centr…\n$ Gender        <fct> Female, Male, Female, Female, Male, Male, Female, Female…\n$ Race          <fct> White, White, White, White, White, White, White, White, …\n$ Education     <fct> HS, Bachelors, HS, Left HS, Left HS, HS, Bachelors, HS, …\n$ Marital       <fct> Divorced, Married, Separated, Divorced, Divorced, Divorc…\n$ Religion      <fct> Inter-nondenominational, Protestant, Protestant, Protest…\n$ Happy         <fct> Pretty happy, Pretty happy, NA, NA, NA, Pretty happy, NA…\n$ Income        <fct> 30000-34999, 75000-89999, 35000-39999, 50000-59999, 4000…\n$ PolParty      <fct> \"Strong Rep\", \"Not Str Rep\", \"Strong Rep\", \"Ind, Near De…\n$ Politics      <fct> Conservative, Conservative, NA, NA, NA, Conservative, NA…\n$ Marijuana     <fct> NA, Not legal, NA, NA, NA, NA, NA, NA, Legal, NA, NA, NA…\n$ DeathPenalty  <fct> Favor, Favor, NA, NA, NA, Favor, NA, NA, Favor, NA, NA, …\n$ OwnGun        <fct> No, Yes, NA, NA, NA, Yes, NA, NA, Yes, NA, NA, NA, NA, N…\n$ GunLaw        <fct> Favor, Oppose, NA, NA, NA, Oppose, NA, NA, Oppose, NA, N…\n$ SpendMilitary <fct> Too little, About right, NA, About right, NA, Too little…\n$ SpendEduc     <fct> Too little, Too little, NA, Too little, NA, Too little, …\n$ SpendEnv      <fct> About right, About right, NA, Too little, NA, Too little…\n$ SpendSci      <fct> About right, About right, NA, Too little, NA, Too little…\n$ Pres00        <fct> Bush, Bush, Bush, NA, NA, Bush, Bush, Bush, Bush, NA, NA…\n$ Postlife      <fct> Yes, Yes, NA, NA, NA, Yes, NA, NA, Yes, NA, NA, NA, NA, …\n```\n\n\n:::\n\n```{.r .cell-code}\ninspect(GSS2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n            name  class levels    n missing\n1         Region factor      7 2765       0\n2         Gender factor      2 2765       0\n3           Race factor      3 2765       0\n4      Education factor      5 2760       5\n5        Marital factor      5 2765       0\n6       Religion factor     13 2746      19\n7          Happy factor      3 1369    1396\n8         Income factor     24 1875     890\n9       PolParty factor      8 2729      36\n10      Politics factor      7 1331    1434\n11     Marijuana factor      2  851    1914\n12  DeathPenalty factor      2 1308    1457\n13        OwnGun factor      3  924    1841\n14        GunLaw factor      2  916    1849\n15 SpendMilitary factor      3 1324    1441\n16     SpendEduc factor      3 1343    1422\n17      SpendEnv factor      3 1322    1443\n18      SpendSci factor      3 1266    1499\n19        Pres00 factor      5 1749    1016\n20      Postlife factor      2 1211    1554\n                                    distribution\n1  North Central (24.7%) ...                    \n2  Female (55.6%), Male (44.4%)                 \n3  White (79.1%), Black (14.8%) ...             \n4  HS (53.8%), Bachelors (16.1%) ...            \n5  Married (45.9%), Never Married (25.6%) ...   \n6  Protestant (53.2%), Catholic (24.5%) ...     \n7  Pretty happy (57.3%) ...                     \n8  40000-49999 (9.1%) ...                       \n9  Ind (19.3%), Not Str Dem (18.9%) ...         \n10 Moderate (39.2%), Conservative (15.8%) ...   \n11 Not legal (64%), Legal (36%)                 \n12 Favor (68.7%), Oppose (31.3%)                \n13 No (65.5%), Yes (33.5%) ...                  \n14 Favor (80.5%), Oppose (19.5%)                \n15 About right (46.5%) ...                      \n16 Too little (73.9%) ...                       \n17 Too little (60%) ...                         \n18 About right (49.7%) ...                      \n19 Bush (50.6%), Gore (44.7%) ...               \n20 Yes (80.5%), No (19.5%)                      \n\nquantitative variables:  \n  name   class min  Q1 median   Q3  max mean       sd    n missing\n1   ID integer   1 692   1383 2074 2765 1383 798.3311 2765       0\n```\n\n\n:::\n\n```{.r .cell-code}\nskimr::skim(GSS2002)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |GSS2002 |\n|Number of rows           |2765    |\n|Number of columns        |21      |\n|_______________________  |        |\n|Column type frequency:   |        |\n|factor                   |20      |\n|numeric                  |1       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                              |\n|:-------------|---------:|-------------:|:-------|--------:|:---------------------------------------|\n|Region        |         0|          1.00|FALSE   |        7|Nor: 684, Sou: 486, Sou: 471, Mid: 435  |\n|Gender        |         0|          1.00|FALSE   |        2|Fem: 1537, Mal: 1228                    |\n|Race          |         0|          1.00|FALSE   |        3|Whi: 2188, Bla: 410, Oth: 167           |\n|Education     |         5|          1.00|FALSE   |        5|HS: 1485, Bac: 443, Lef: 400, Gra: 230  |\n|Marital       |         0|          1.00|FALSE   |        5|Mar: 1269, Nev: 708, Div: 445, Wid: 247 |\n|Religion      |        19|          0.99|FALSE   |       13|Pro: 1460, Cat: 673, Non: 379, Chr: 65  |\n|Happy         |      1396|          0.50|FALSE   |        3|Pre: 784, Ver: 415, Not: 170            |\n|Income        |       890|          0.68|FALSE   |       24|400: 170, 300: 166, 250: 140, 500: 136  |\n|PolParty      |        36|          0.99|FALSE   |        8|Ind: 528, Not: 515, Not: 449, Str: 408  |\n|Politics      |      1434|          0.48|FALSE   |        7|Mod: 522, Con: 210, Sli: 209, Sli: 159  |\n|Marijuana     |      1914|          0.31|FALSE   |        2|Not: 545, Leg: 306                      |\n|DeathPenalty  |      1457|          0.47|FALSE   |        2|Fav: 899, Opp: 409                      |\n|OwnGun        |      1841|          0.33|FALSE   |        3|No: 605, Yes: 310, Ref: 9               |\n|GunLaw        |      1849|          0.33|FALSE   |        2|Fav: 737, Opp: 179                      |\n|SpendMilitary |      1441|          0.48|FALSE   |        3|Abo: 615, Too: 414, Too: 295            |\n|SpendEduc     |      1422|          0.49|FALSE   |        3|Too: 992, Abo: 278, Too: 73             |\n|SpendEnv      |      1443|          0.48|FALSE   |        3|Too: 793, Abo: 439, Too: 90             |\n|SpendSci      |      1499|          0.46|FALSE   |        3|Abo: 629, Too: 461, Too: 176            |\n|Pres00        |      1016|          0.63|FALSE   |        5|Bus: 885, Gor: 781, Nad: 57, Oth: 16    |\n|Postlife      |      1554|          0.44|FALSE   |        2|Yes: 975, No: 236                       |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|     sd| p0| p25|  p50|  p75| p100|hist  |\n|:-------------|---------:|-------------:|----:|------:|--:|---:|----:|----:|----:|:-----|\n|ID            |         0|             1| 1383| 798.33|  1| 692| 1383| 2074| 2765|▇▇▇▇▇ |\n\n\n:::\n:::\n\n\n\n\n\nNote how *all* variables are Categorical !! `Education` has five\n`levels`, and of course `DeathPenalty` has three:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGSS2002 %>% count(Education)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Education\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Left HS\",\"2\":\"400\"},{\"1\":\"HS\",\"2\":\"1485\"},{\"1\":\"Jr Col\",\"2\":\"202\"},{\"1\":\"Bachelors\",\"2\":\"443\"},{\"1\":\"Graduate\",\"2\":\"230\"},{\"1\":\"NA\",\"2\":\"5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nGSS2002 %>% count(DeathPenalty)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"DeathPenalty\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Favor\",\"2\":\"899\"},{\"1\":\"Oppose\",\"2\":\"409\"},{\"1\":\"NA\",\"2\":\"1457\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nLet us drop NA entries in `Education` and `Death Penalty` and set up a\n**Contingency Table**.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss2002 <- GSS2002 %>%\n  dplyr::select(Education, DeathPenalty) %>%\n  tidyr::drop_na(., c(Education, DeathPenalty))\n##\ngss_table <- mosaic::tally(DeathPenalty ~ Education, data = gss2002)\ngss_table %>%\n  addmargins()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Education\nDeathPenalty Left HS   HS Jr Col Bachelors Graduate  Sum\n      Favor      117  511     71       135       64  898\n      Oppose      72  200     16        71       50  409\n      Sum        189  711     87       206      114 1307\n```\n\n\n:::\n:::\n\n\n\n\n### Contingency Table Plots\n\nThe Contingency Table can be plotted, as we have seen, using a `mosaic` plot using several packages. Let us do a quick recap:\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n\n#### Using ggmosaic\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(ggmosaic)\n\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\nggplot(data = gss2002) +\n  geom_mosaic(aes(\n    x = product(DeathPenalty, Education),\n    fill = DeathPenalty\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/mosaic-plot-1.png){width=2100}\n:::\n:::\n\n\n\n\n\n#### Using vcd\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvcd::mosaic(gss_table, gp = shading_hsv)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=2100}\n:::\n:::\n\n\n\n\n#### Using ggformula\n\nNeeds a little more work, to convert the Contingency Table into a tibble:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://stackoverflow.com/questions/19233365/how-to-create-a-marimekko-mosaic-plot-in-ggplot2\n\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\ngss_summary <- gss2002 %>%\n  mutate(\n    Education = factor(\n      Education,\n      levels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\"),\n      labels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\")\n    ),\n    DeathPenalty = as.factor(DeathPenalty)\n  ) %>%\n  group_by(Education, DeathPenalty) %>%\n  summarise(count = n()) %>% # This is good for a chisq test\n\n  # Add two more columns to facilitate mosaic/Marrimekko Plot\n  mutate(\n    edu_count = sum(count),\n    edu_prop = count / sum(count)\n  ) %>%\n  ungroup()\n###\ngf_col(edu_prop ~ Education,\n  data = gss_summary,\n  width = ~edu_count,\n  fill = ~DeathPenalty,\n  stat = \"identity\",\n  position = \"fill\",\n  color = \"black\"\n) %>%\n  gf_text(edu_prop ~ Education,\n    label = ~ scales::percent(edu_prop),\n    position = position_stack(vjust = 0.5)\n  ) %>%\n  gf_facet_grid(~Education,\n    scales = \"free_x\",\n    space = \"free_x\"\n  ) %>%\n  gf_theme(scale_fill_manual(values = c(\"orangered\", \"palegreen3\")))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=2100}\n:::\n:::\n\n\n\n\n\n:::\n\n\n\n## Hypotheses Definition\n\nWhat would our Hypotheses be?\n\n$H_0: \\text{Education does not affect votes for Death Penalty}$\n$H_a: \\text{Education affects votes for Death Penalty}$\n\n## Inference for Two Proportions\n\nWe are now ready to perform our statistical inference. We will use the standard `chi-square test`, and develop and intuition for it. We will then do a permutation test to have an alternative method to complete the same task.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n\n### Code\n\nLet us now perform the base `chisq test`: We need a `table` and then the `chisq` test: We will calculate the `observed-chi-squared` value, and compare it with the `critical value`. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the observed chi-square statistic\nobservedChi2 <- mosaic::chisq(tally(DeathPenalty ~ Education, data = gss2002))\nobservedChi2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nX.squared \n 23.45093 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Actual chi-square test\nmosaic::xchisq.test(tally(DeathPenalty ~ Education, data = gss2002))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  x\nX-squared = 23.451, df = 4, p-value = 0.0001029\n\n  117      511       71      135       64   \n(129.86) (488.51) ( 59.78) (141.54) ( 78.33)\n [1.27]   [1.04]   [2.11]   [0.30]   [2.62] \n<-1.13>  < 1.02>  < 1.45>  <-0.55>  <-1.62> \n         \n   72      200       16       71       50   \n( 59.14) (222.49) ( 27.22) ( 64.46) ( 35.67)\n [2.79]   [2.27]   [4.63]   [0.66]   [5.75] \n< 1.67>  <-1.51>  <-2.15>  < 0.81>  < 2.40> \n         \nkey:\n\tobserved\n\t(expected)\n\t[contribution to X-squared]\n\t<Pearson residual>\n```\n\n\n:::\n\n```{.r .cell-code}\n# Determine the Chi-Square critical value\nX_squared_critical <- qchisq(\n  p = .05,\n  df = (5 - 1) * (2 - 1), # (nrows-1) * (ncols-1)\n  lower.tail = FALSE\n)\nX_squared_critical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.487729\n```\n\n\n:::\n:::\n\n\n\n\nWe see that our observed $X^2 = 23.45$; the critical value `X_squared_critical` is $9.48$, which is much smaller! The `p-value` is $0.0001029$, very low as we would expect, indicating that the NULL Hypothesis should be rejected in favour of the alternate hypothesis, that opinions about the `DeathPenalty` are related to `Education`. \n\nLet us now dig into that cryptic-looking table above!\n\n### Intuitive Explanation\n\nLet us look at the Contingency Table that we have:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Contingency Table</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Left HS </th>\n   <th style=\"text-align:right;\"> HS </th>\n   <th style=\"text-align:right;\"> Jr Col </th>\n   <th style=\"text-align:right;\"> Bachelors </th>\n   <th style=\"text-align:right;\"> Graduate </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Favor </td>\n   <td style=\"text-align:right;\"> 117 </td>\n   <td style=\"text-align:right;\"> 511 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 135 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 898 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Oppose </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 200 </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 409 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 189 </td>\n   <td style=\"text-align:right;\"> 711 </td>\n   <td style=\"text-align:right;\"> 87 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 114 </td>\n   <td style=\"text-align:right;\"> 1307 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nIn the chi-square test, we check whether the two ( or more ) categorical\nvariables are independent. To do this we perform a simple check on the\nContingency Table. We first *re-compute* the totals in each row and\ncolumn, based on what we could **expect** if there was independence\n(NULL Hypothesis). If the two variables were independent, then there\nshould be **no difference** between real and expected scores.\n\nHow do we know what scores to expect if there was no relationship \nbetween the variables?\n\nConsider the entry in location (1,1): 117. The number of **expected**\nentries there is probability of an entry landing in that square times\nthe total number of entries:\n\n\n\n\n```{=tex}\n\\begin{align}\n\n\\text{Expected Value at location[1,1]}\n&= p_{row_1} * p_{col_1} * \\text{Total Scores}\\\\\\\n&= \\frac{\\text{Row-1-Total}}{\\text{Total Scores}} * \\frac{\\text{Col-1-Total}}{\\text{Total Scores}} * \\text{Total Scores}\\\\\\\n&= \\frac{898}{1307} * \\frac{189}{1307} * 1307\\\\\\\n&= 130\n\n\\end{align}\n\n```\n\n\n\n\nProceeding in this way for all the 15 entries in the Contingency Table,\nwe get the \"Expected\" Contingency Table. Here are both tables for\ncomparison:\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Expected Contingency Table</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Left HS </th>\n   <th style=\"text-align:right;\"> HS </th>\n   <th style=\"text-align:right;\"> Jr Col </th>\n   <th style=\"text-align:right;\"> Bachelors </th>\n   <th style=\"text-align:right;\"> Graduate </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Favor </td>\n   <td style=\"text-align:right;\"> 130 </td>\n   <td style=\"text-align:right;\"> 489 </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 142 </td>\n   <td style=\"text-align:right;\"> 78 </td>\n   <td style=\"text-align:right;\"> 898 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Oppose </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 222 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 36 </td>\n   <td style=\"text-align:right;\"> 409 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 189 </td>\n   <td style=\"text-align:right;\"> 711 </td>\n   <td style=\"text-align:right;\"> 87 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 114 </td>\n   <td style=\"text-align:right;\"> 1307 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Actual Contingency Table</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Left HS </th>\n   <th style=\"text-align:right;\"> HS </th>\n   <th style=\"text-align:right;\"> Jr Col </th>\n   <th style=\"text-align:right;\"> Bachelors </th>\n   <th style=\"text-align:right;\"> Graduate </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Favor </td>\n   <td style=\"text-align:right;\"> 117 </td>\n   <td style=\"text-align:right;\"> 511 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 135 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 898 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Oppose </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 200 </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 409 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 189 </td>\n   <td style=\"text-align:right;\"> 711 </td>\n   <td style=\"text-align:right;\"> 87 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 114 </td>\n   <td style=\"text-align:right;\"> 1307 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\nThe $X^2$ statistic is **sum of squared differences** between `Observed` \nand `Expected` scores, scaled by the `Expected Scores`. For location \n\\[1,1\\] this would be: $(117-130)^2/130$. Do try to compute all of these and the $X^2$ statistic by hand !!\n\nAll right, what of all this? How did this $X^2$ distribution come from? The idea is that when you take the square of a normally distributed variable, the resultant variable is *chi-square* distributed, which is a positive one-sided (squared numbers!!) distribution.\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\ndf <- tibble(\n  x = rnorm(500, mean = 0, sd = 2),\n  y = x^2\n)\ndf %>%\n  gf_density(~x) %>%\n  gf_fitdistr(dist = \"dnorm\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=2100}\n:::\n\n```{.r .cell-code}\ndf %>%\n  gf_density(~y) %>%\n  gf_fitdistr()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-2.png){width=2100}\n:::\n:::\n\n\n\n\n\n:::\n\n\n\n## Permutation Test for `Education`\n\nWe will now perform the permutation test for the difference between proportions. We will first get an intuitive idea of the permutation, and then perform it using both `mosaic` and `infer`.\n\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n\n\n### {{< iconify svg-spinners blocks-shuffle-3 >}} Permutation Visually Demonstrated\n\nWe saw from the diagram created by Allen Downey that [there is only one test](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)! We will now use this philosophy to develop a technique that allows us to\nmechanize several *Statistical Models* in that way, with nearly identical code.\nWe will first look visually at a permutation exercise. We will create dummy data that contains the following case study:\n\n> A set of identical resumes was sent to male and female evaluators. The\n> candidates in the resumes were of both genders. We wish to see if\n> there was difference in the way resumes were evaluated, by male and\n> female evaluators. (We use just *one* male and *one* female evaluator\n> here, to keep things simple!)\n\n\n\n\n\n::: {.cell .column-body-outset-right layout-ncol=\"2\"}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"evaluator\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"candidate_selected\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"0\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"0\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"0\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"evaluator\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"selection_ratio\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"count\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"F\",\"2\":\"0.1250000\",\"3\":\"3\",\"4\":\"24\"},{\"1\":\"M\",\"2\":\"0.4583333\",\"3\":\"11\",\"4\":\"24\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell layout=\"[20,80]\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n         M \n-0.3333333 \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/Difference in Proportion-1.png){width=2100}\n:::\n:::\n\n\n\n\nSo, we have a solid disparity in percentage of selection between the two evaluators! Now we pretend that *there is no difference between the selections made by either set of evaluators*. So we can just:\n\n-   Pool up all the evaluations\\\n-   Arbitrarily re-assign a given candidate(selected or rejected) to\n    either of the two sets of evaluators, by permutation.\\\n\nHow would that pooled shuffled set of evaluations look like?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"evaluator\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"selection_ratio\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"count\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"F\",\"2\":\"0.2500000\",\"3\":\"6\",\"4\":\"24\"},{\"1\":\"M\",\"2\":\"0.3333333\",\"3\":\"8\",\"4\":\"24\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell layout=\"[[45,-10,45]]\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-2.png){width=2100}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nAs can be seen, the ratio is different! \n\nWe can now check out our Hypothesis that there is *no* bias. We can shuffle the data many many times, calculating the ratio each time, and plot the *distribution of the differences in selection ratio* and see how that artificially created distribution compares with the originally observed figure from Mother Nature.\n\n\n\n\n::: {.cell layout=\"[[60,-10,30]]\"}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\nnull_dist <- do(4999) * diff(mean(\n  candidate_selected ~ shuffle(evaluator),\n  data = data\n))\n# null_dist %>% names()\nnull_dist %>%\n  gf_histogram(~M,\n    fill = ~ (M <= obs_difference),\n    bins = 25, show.legend = FALSE,\n    xlab = \"Bias Proportion\",\n    ylab = \"How Often?\",\n    title = \"Permutation Test on Difference between Groups\",\n    subtitle = \"\"\n  ) %>%\n  gf_vline(xintercept = ~obs_difference, color = \"red\") %>%\n  gf_label(500 ~ obs_difference,\n    label = \"Observed\\n Bias\",\n    show.legend = FALSE\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nmean(~ M <= obs_difference, data = null_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.00220044\n```\n\n\n:::\n:::\n\n\n\n\nWe see that the artificial data can hardly ever ($p = 0.0022$) mimic what the real world experiment is showing. Hence we had good reason to reject our NULL Hypothesis that there is no bias.\n\n\n\n### Code\nWe should now repeat the test with permutations on `Education`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\nnull_chisq <- do(9999) *\n  chisq.test(tally(DeathPenalty ~ shuffle(Education),\n    data = gss2002\n  ))\n\nhead(null_chisq)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"X.squared\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"alternative\"],\"name\":[5],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"data\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".row\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"12.319854\",\"2\":\"4\",\"3\":\"0.01512469\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"1\",\"_rn_\":\"X-squared...1\"},{\"1\":\"5.208442\",\"2\":\"4\",\"3\":\"0.26657081\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"2\",\"_rn_\":\"X-squared...2\"},{\"1\":\"5.431285\",\"2\":\"4\",\"3\":\"0.24583591\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"3\",\"_rn_\":\"X-squared...3\"},{\"1\":\"8.918993\",\"2\":\"4\",\"3\":\"0.06315646\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"4\",\"_rn_\":\"X-squared...4\"},{\"1\":\"1.251510\",\"2\":\"4\",\"3\":\"0.86954725\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"5\",\"_rn_\":\"X-squared...5\"},{\"1\":\"1.802120\",\"2\":\"4\",\"3\":\"0.77209444\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"6\",\"_rn_\":\"X-squared...6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(~X.squared, data = null_chisq) %>%\n  gf_vline(\n    xintercept = observedChi2,\n    color = \"red\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nprop1(~ X.squared >= observedChi2, data = null_chisq)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nprop_TRUE \n    3e-04 \n```\n\n\n:::\n:::\n\n\n\n\nThe `p-value` is well below our threshold of $0.05$, so we would\nconclude that `Education` has a significant effect on `DeathPenalty`\nopinion!\n\n\n:::\n\n\n## {{< iconify grommet-icons test >}} {{< iconify lucide ratio >}} Inference for Proportions Case Study-2: TBD dataset\nTo be Written Up.\n\n\n## {{< iconify fluent-mdl2 decision-solid >}} Conclusion\n\nIn our basic $X^2$ test, we calculate the test statistic of $X^2$ and\nlook up a *theoretical* null distribution for that statistic, and see\nhow unlikely our observed value is.\n\nWhy would a permutation test be a good idea here? With a permutation test, there are *no assumptions* of the null distribution: this is computed based on real data. We note in passing that, in this case, since the number of `cases` in each cell of the Contingency Table are fairly high ( \\>= 5) the resulting NULL\ndistribution is of the $X^2$ variety.\n\n## {{< iconify mingcute thought-line >}} Wait, But Why?\n\n\n## {{< iconify bi person-up >}} Your Turn\n\n\n## {{< iconify ooui references-rtl >}} References\n\n1. [OpenIntro Modern Statistics: Chapter\n17](https://openintro-ims.netlify.app/inference-one-prop.html)\\\n1. Chapter 8: The Chi-Square Test, from *Statistics at Square One*. The British Medical Journal. <https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests>. Very readable and easy to grasp. Especially if you like watching [Grey's Anatomy](https://www.hotstar.com/in/shows/greys-anatomy/14823) and [House](https://www.imdb.com/title/tt0412142/).\n\n1. Exploring the underlying theory of the chi-square test through\nsimulation - part 1\n<https://www.rdatagen.net/post/a-little-intuition-and-simulation-behind-the-chi-square-test-of-independence/>\\\n1. Exploring the underlying theory of the chi-square test through\nsimulation - part 2\n<https://www.rdatagen.net/post/a-little-intuition-and-simulation-behind-the-chi-square-test-of-independence-part-2/>\\\n\n1. An Online $\\Xi^2$-test calculator. <https://www.statology.org/chi-square-test-of-independence-calculator/>\n\n::: {#refs style=\"font-size: 60%;\"}\n###### {{< iconify lucide package-check >}} R Package Citations\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nPackage        Version   Citation                     \n-------------  --------  -----------------------------\nggmosaic       0.3.3     @ggmosaic                    \nresampledata   0.3.1     @resampledata                \nscales         1.3.0     @scales                      \nvcd            1.4.12    @vcd2006; @vcd2007; @vcd2023 \n\n\n:::\n:::\n\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}