{
  "hash": "d383833b97a1de8dc03f8e7362c91b20",
  "result": {
    "markdown": "---\ntitle: \"Comparing Multiple Means with ANOVA\"\nauthor: \"Arvind Venkatadri\"\nformat: html\neditor: visual\nabstract: \"ANOVA to investigate how frogspawn hatching time varies with temperature.\"\ndate: 28/Mar/2023\ndate-modified: \"2023-07-05\"\norder: 130\nimage: preview.jpg\n---\n\n\n## {{< iconify noto-v1 package >}} Setting up R Packages\n\n\n::: {.cell hash='ANOVA_cache/html/setup_3d8dbb6992e66b24424980b1c014cf9a'}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE)\nlibrary(tidyverse)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(infer)\n```\n:::\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-2_0c90bce576623b6ad8edbf78bcaa73c8'}\n<style type=\"text/css\">\n\n/*https://stackoverflow.com/questions/73546631/how-to-format-tabset-font-in-quarto\n*/\n\n/*\n.panel-tabset .nav-item {\n   font-size: 20px;\n   font-style: italic\n    }\n*/\n</style>\n:::\n\n\n## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction\n\nSuppose we have three sales strategies on our website, to sell a certain\nproduct, say men's shirts. We have observations of customer website\ninteractions over several months. How do we know which strategy makes\npeople buy the fastest ?\n\nIf there is a University course that is offered in parallel in three\ndifferent classrooms, is there a difference between the average marks\nobtained by students in each of the classrooms?\n\nIn each case we have a set of observations in each category: Interaction\nTime vs Sales Strategy in the first example, and Student Marks vs\nClassroom in the second. We can take *mean* scores in each category and\ndecide to compare them. How do we make the comparisons? One way would be\nto compare them pair-wise. But with this rapidly becomes intractable and\nalso dangerous: with increasing number of `groups`, the number of\nmean-comparisons becomes very large $N\\choose 2$ and with each\ncomparison the possibility of some difference showing up, *just by\nchance*, increases! And we end up making the wrong inference and perhaps\nthe wrong decision.\n\nThe trick is of course to make comparisons **all at once** and ANOVA is\nthe technique that allows us to do just that. In this tutorial, we will\ncompare the Hatching Time of frog spawn[^1], at three different lab\ntemperatures.\n\nIn this tutorial, our research question is:\n\n::: callout-note\n## Research Question\n\nHow does frogspawn hatching time vary with temperature?\n:::\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Read the Data\n\nDownload the data by clicking the button below.\n\n\n{{< downloadthis data/frogs.csv dname=\"frogs\" label=\"Download the frogs data\" icon=\"database-fill-down\" type=\"info\" >}}\n\n\n\n::: callout-important\n## Data Folder\n\nSave the CSV it in a subfolder titled \"data\" inside your R work folder.\n:::\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-3_20128bd127e00f2b3072eba7e5acd67f'}\n\n```{.r .cell-code}\nfrogs_orig <- read_csv(\"data/frogs.csv\")\nfrogs_orig\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Frogspawn sample id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature13\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature18\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature25\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"24\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"2\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"3\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"18\"},{\"1\":\"4\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"5\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"6\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"14\"},{\"1\":\"7\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"8\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"9\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"10\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"11\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"12\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"13\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"14\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"15\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"16\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"17\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"18\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"19\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"20\",\"2\":\"NA\",\"3\":\"19\",\"4\":\"NA\"},{\"1\":\"21\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"22\",\"2\":\"25\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"23\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"24\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"25\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"26\",\"2\":\"NA\",\"3\":\"23\",\"4\":\"NA\"},{\"1\":\"27\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"28\",\"2\":\"28\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"29\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"30\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"31\",\"2\":\"24\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"32\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"33\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"18\"},{\"1\":\"34\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"35\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"36\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"14\"},{\"1\":\"37\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"38\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"39\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"40\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"41\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"42\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"43\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"44\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"45\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"46\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"47\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"48\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"49\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"50\",\"2\":\"NA\",\"3\":\"19\",\"4\":\"NA\"},{\"1\":\"51\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"52\",\"2\":\"25\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"53\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"54\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"55\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"56\",\"2\":\"NA\",\"3\":\"23\",\"4\":\"NA\"},{\"1\":\"57\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"58\",\"2\":\"28\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"59\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"60\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nOur response variable is the hatching `Time`. Our explanatory variable\nis a *factor*, `Temperature`, with 3 levels: 13°C, 18°C and 25°C.\nDifferent samples of spawn were subject to each of these temperatures\nrespectively.\n\n## {{< iconify material-symbols pivot-table-chart >}} Workflow: Clean the Data\n\nThe data is badly organized, with a separate column for each\nTemperature, and a common column for Sample ID. There are NA entries\nsince not all samples of spawn are subject to all temperatures. (E.g.\nSample ID #1 was maintained at 13°C). Hence, we should `pivot_longer()`\nthis data, so all Time readings are in one numerical column, all\nTemperatures are also in a column that we should convert into a\n`factor`:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-4_5f7262492456251c5ee0ea31ecc44399'}\n\n```{.r .cell-code}\nfrogs_long <- frogs_orig %>% \n  pivot_longer(., cols = starts_with(\"Temperature\"),\n               cols_vary = \"fastest\", # new in pivot_longer\n               names_to = \"Temp\",\n               values_to = \"Time\") %>% \n  drop_na() %>% \n  \n  # knock off the unnecessary \"Temperature\" word everywhere\n  separate_wider_regex(cols = Temp,\n                       patterns = c(\"Temperature\", \n                                     TempFac = \"\\\\d+\"), \n                       cols_remove = TRUE) %>% \n  \n  # Convert Temp into TempFac, a 3-level factor\n  mutate(TempFac = factor(x = TempFac,\n                          levels = c(13,18,25), \n                          labels = c(\"13\", \"18\", \"25\"))) %>% \n  rename(\"Id\" = `Frogspawn sample id`)\n\nfrogs_long\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"TempFac\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"13\",\"3\":\"24\"},{\"1\":\"2\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"3\",\"2\":\"25\",\"3\":\"18\"},{\"1\":\"4\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"5\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"6\",\"2\":\"25\",\"3\":\"14\"},{\"1\":\"7\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"8\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"9\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"10\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"11\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"12\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"13\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"14\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"15\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"16\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"17\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"18\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"19\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"20\",\"2\":\"18\",\"3\":\"19\"},{\"1\":\"21\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"22\",\"2\":\"13\",\"3\":\"25\"},{\"1\":\"23\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"24\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"25\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"26\",\"2\":\"18\",\"3\":\"23\"},{\"1\":\"27\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"28\",\"2\":\"13\",\"3\":\"28\"},{\"1\":\"29\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"30\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"31\",\"2\":\"13\",\"3\":\"24\"},{\"1\":\"32\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"33\",\"2\":\"25\",\"3\":\"18\"},{\"1\":\"34\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"35\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"36\",\"2\":\"25\",\"3\":\"14\"},{\"1\":\"37\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"38\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"39\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"40\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"41\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"42\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"43\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"44\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"45\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"46\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"47\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"48\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"49\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"50\",\"2\":\"18\",\"3\":\"19\"},{\"1\":\"51\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"52\",\"2\":\"13\",\"3\":\"25\"},{\"1\":\"53\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"54\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"55\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"56\",\"2\":\"18\",\"3\":\"23\"},{\"1\":\"57\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"58\",\"2\":\"13\",\"3\":\"28\"},{\"1\":\"59\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"60\",\"2\":\"25\",\"3\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-5_2d83d716c3cebf52f62ea4c639fb5128'}\n\n```{.r .cell-code}\nfrogs_long %>% count(TempFac)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"20\"},{\"1\":\"18\",\"2\":\"20\"},{\"1\":\"25\",\"2\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nSo we have `20` samples for Hatching `Time` per `TempFac` setting.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: EDA\n\nLet us set a plot theme:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-6_8d0b9e377f7c4ddce13da3ddca7b702f'}\n\n```{.r .cell-code}\n# Data visualisation\n\ntheme_frogs <- function(){  # Creating a function\n  theme_classic() +  # Using pre-defined theme as base\n  theme(axis.text.x = element_text(size = 12, face = \"bold\"),  # Customizing axes text      \n        axis.text.y = element_text(size = 12, face = \"bold\"),\n        axis.title = element_text(size = 14, face = \"bold\"),  # Customizing axis title\n        panel.grid = element_blank(),  # Taking off the default grid\n        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , \"cm\"),\n        legend.text = element_text(size = 12, face = \"italic\"),  # Customizing legend text\n        legend.title = element_text(size = 12, face = \"bold\"),  # Customizing legend title\n        legend.position = \"right\",  # Customizing legend position\n        plot.caption = element_text(size = 12))  # Customizing plot caption\n}                                                                              \n```\n:::\n\n\nLet us plot some histograms of Hatching Time:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-7_bb1c82e3cf39a14618620aac49dfbf2c'}\n\n```{.r .cell-code}\ngf_histogram(data = frogs_long, \n             ~ Time, \n             fill = ~ TempFac,\n             stat = \"count\") %>% \n  gf_vline(xintercept = ~ mean(Time)) %>% \n  gf_labs(x = \"Hatching Time\") %>% \n  gf_theme(theme = theme_frogs()) %>% \n  gf_theme(guides(fill = guide_legend(title = \"Temperature level (°C)\")))\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-7-1.png){width=2100}\n:::\n:::\n\n\nWe should also look at boxplots:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-8_b60abfb9010abdf281ce32929263fd3b'}\n\n```{.r .cell-code}\ngf_boxplot(data = frogs_long, \n             Time ~ TempFac, \n             fill = ~ TempFac) %>% \n  gf_vline(xintercept = ~ mean(Time)) %>% \n  gf_labs(x = \"Temperature\") %>% \n  gf_theme(theme = theme_frogs()) %>% \n  gf_theme(guides(fill = guide_legend(title = \"Temperature level (°C)\")))\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-8-1.png){width=2100}\n:::\n:::\n\n\nThe histograms look well separated and the box plots also show very\nlittle overlap. So we can reasonably hypothesize that Temperature has a\nsignificant effect on Hatching Time.\n\nOne more slightly esoteric plot: Jitter/Scatter with a new categorical\nx-axis:\n\n\n::: {.cell hash='ANOVA_cache/html/using ggprism_b78b3abfa135fa22f46b6eba7526fc6c'}\n\n```{.r .cell-code}\nlibrary(ggprism)\ngf_jitter(frogs_long, Time ~ TempFac, color = ~ TempFac) %>% \n    gf_theme(theme_prism()) %>% \n    gf_refine(theme(legend.position = \"none\"),\n              scale_x_discrete(guide = \"prism_bracket\"))\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/using ggprism-1.png){width=2100}\n:::\n:::\n\n\nLet's go ahead with our ANOVA test.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: ANOVA\n\nWe will first execute the ANOVA test with code and evaluate the results.\nThen we will do an intuitive walk through of the process and finally,\nhand-calculate entire analysis for clear understanding.\n\n::: panel-tabset\n### ANOVA Test with Code\n\nR offers a very simple command to execute an ANOVA test: Note the\nfamiliar `formula` of stating the variables:\n\n\n::: {.cell hash='ANOVA_cache/html/ANOVA with code_ebec11aec2ac7dd114593f85295c07a4'}\n\n```{.r .cell-code}\nfrogs_anova <- aov(Time ~ TempFac, data = frogs_long)\nsummary(frogs_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \nTempFac      2 1020.9   510.5   385.9 <2e-16 ***\nResiduals   57   75.4     1.3                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nfrogs_anova %>% broom::tidy()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sumsq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"meansq\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"TempFac\",\"2\":\"2\",\"3\":\"1020.933\",\"4\":\"510.466667\",\"5\":\"385.8966\",\"6\":\"7.357304e-34\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"75.400\",\"4\":\"1.322807\",\"5\":\"NA\",\"6\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nfrogs_anova %>% broom::glance()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"logLik\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIC\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviance\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"r.squared\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-91.99019\",\"2\":\"191.9804\",\"3\":\"200.3578\",\"4\":\"75.4\",\"5\":\"60\",\"6\":\"0.9312253\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe effect of Temperature on Hatching time is significant, with a\np-value of $<2e-16$. The F-statistic for the ANOVA test is given by\n$385.9$, which is very high, and the `r.squared` value ( to be discussed\nlater) is also large, $0.931$. Clearly `Temperature` has a very\nsignificant effect on the hatching `Time`.\n\nTo find which specific value of `TempFac` has the most effect will\nrequire *pairwise comparison* of the group means, using a standard\n`t-test`. The confidence level for such repeated comparisons will need\nwhat is called ***Bonferroni correction***[^2] to prevent us from\ndetecting a significant (pair-wise) difference simply by chance. To do\nthis we take $\\alpha = 0.05$, the confidence level used and divide it by\n$K$, the number of pair-wise comparisons we intend to make. This new\nvalue is used to decide on the significance of the estimated parameter.\nSo the pairwise comparisons in our current data will have to use\n$\\alpha/3 = 0.0166$ as the confidence level.\n\n### ANOVA Intuitive {#sec-anova-intuitive}\n\nAll that is very well, but what is happening under the hood of the\n`aov()` command?\n\nConsider a data set with a single Quant and a single Qual variable. The\nQual variable has two levels, the Quant data has 20 observations per\nQual level.\n\n\n::: {.cell layout-nrow=\"1\" hash='ANOVA_cache/html/Anova Intuitive_8befc85849a79faad78f4ab25d6175f7'}\n\n```{.r .cell-code}\nlibrary(ggtext)\ndata = tibble(index = 1:40,\n              qual = c(rep(x = \"A\", 20),rep(x = \"B\", 20)),\n              quant = c(rnorm(n = 20, mean = 0, sd = 2), \n                        rnorm(n = 20, mean = 10, sd = 2)))\ndata\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"index\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"qual\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"quant\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"A\",\"3\":\"2.8608469\"},{\"1\":\"2\",\"2\":\"A\",\"3\":\"0.5677406\"},{\"1\":\"3\",\"2\":\"A\",\"3\":\"0.1127415\"},{\"1\":\"4\",\"2\":\"A\",\"3\":\"-1.0264556\"},{\"1\":\"5\",\"2\":\"A\",\"3\":\"-4.5952624\"},{\"1\":\"6\",\"2\":\"A\",\"3\":\"0.3157866\"},{\"1\":\"7\",\"2\":\"A\",\"3\":\"-0.1434959\"},{\"1\":\"8\",\"2\":\"A\",\"3\":\"2.0335033\"},{\"1\":\"9\",\"2\":\"A\",\"3\":\"-1.9386791\"},{\"1\":\"10\",\"2\":\"A\",\"3\":\"0.9624023\"},{\"1\":\"11\",\"2\":\"A\",\"3\":\"-0.4824376\"},{\"1\":\"12\",\"2\":\"A\",\"3\":\"0.1717345\"},{\"1\":\"13\",\"2\":\"A\",\"3\":\"1.0560685\"},{\"1\":\"14\",\"2\":\"A\",\"3\":\"1.3202673\"},{\"1\":\"15\",\"2\":\"A\",\"3\":\"-0.7115485\"},{\"1\":\"16\",\"2\":\"A\",\"3\":\"0.4457605\"},{\"1\":\"17\",\"2\":\"A\",\"3\":\"3.9240816\"},{\"1\":\"18\",\"2\":\"A\",\"3\":\"0.2169600\"},{\"1\":\"19\",\"2\":\"A\",\"3\":\"-1.1364571\"},{\"1\":\"20\",\"2\":\"A\",\"3\":\"-0.3371199\"},{\"1\":\"21\",\"2\":\"B\",\"3\":\"7.1178695\"},{\"1\":\"22\",\"2\":\"B\",\"3\":\"8.4981753\"},{\"1\":\"23\",\"2\":\"B\",\"3\":\"9.7586045\"},{\"1\":\"24\",\"2\":\"B\",\"3\":\"7.7877145\"},{\"1\":\"25\",\"2\":\"B\",\"3\":\"9.1655332\"},{\"1\":\"26\",\"2\":\"B\",\"3\":\"8.3325107\"},{\"1\":\"27\",\"2\":\"B\",\"3\":\"12.5159698\"},{\"1\":\"28\",\"2\":\"B\",\"3\":\"8.1369124\"},{\"1\":\"29\",\"2\":\"B\",\"3\":\"10.5974037\"},{\"1\":\"30\",\"2\":\"B\",\"3\":\"9.2970029\"},{\"1\":\"31\",\"2\":\"B\",\"3\":\"11.2793826\"},{\"1\":\"32\",\"2\":\"B\",\"3\":\"9.5069284\"},{\"1\":\"33\",\"2\":\"B\",\"3\":\"9.2577112\"},{\"1\":\"34\",\"2\":\"B\",\"3\":\"11.9219561\"},{\"1\":\"35\",\"2\":\"B\",\"3\":\"9.8552443\"},{\"1\":\"36\",\"2\":\"B\",\"3\":\"7.1767861\"},{\"1\":\"37\",\"2\":\"B\",\"3\":\"9.0667178\"},{\"1\":\"38\",\"2\":\"B\",\"3\":\"8.2659619\"},{\"1\":\"39\",\"2\":\"B\",\"3\":\"9.9168354\"},{\"1\":\"40\",\"2\":\"B\",\"3\":\"9.2213923\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\noverall_mean <- data %>%\n             summarise(overall_mean = mean(quant))\n#overall_mean\n\ngrouped_means <- data %>%\n  group_by(qual) %>% \n             summarise(grouped_means = mean(quant))\n#grouped_means\n\ngf_point(quant ~ index, \n               color = ~ qual,\n         data = data, title = \"Fig. A\") %>% \n  gf_hline(yintercept =  ~ overall_mean,\n             data = overall_mean) %>% \n  gf_segment(data = data, \n             color = \"black\",\n             overall_mean$overall_mean + quant ~ index + index) %>% \n  gf_theme(theme = theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Anova Intuitive-1.png){width=2100}\n:::\n\n```{.r .cell-code}\ngf_point(quant ~ index, \n         group = ~ qual, \n         colour = ~ qual, \n         data = data, title = \"Fig. B\") %>% \n  gf_hline(yintercept = ~ mean, \n           colour = ~ qual,\n           data = data %>% \n             group_by(qual) %>% \n             summarise(mean = mean(quant))) %>% \n  gf_segment(data = data %>% filter(qual == \"A\"),\n             grouped_means$grouped_means[1] + quant ~ index + index\n             ) %>% \n  gf_segment(data = data %>% filter(qual == \"B\"),\n             grouped_means$grouped_means[2] + quant ~ index + index\n             ) %>% \n  gf_theme(theme = theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Anova Intuitive-2.png){width=2100}\n:::\n:::\n\n\nIn Fig A, the *horizontal* black line is the overall mean of `quant`,\ndenoted as $\\mu_{tot}$. The vertical black lines to the points show the\ndepartures of each point from this overall mean. The sum of *squares* of\nthese vertical black lines in Fig A is called the [**Total Sum of\nSquares** (SST)]{style=\"background-color: yellow;\"}.\n\n$$\nSST = \\Sigma (y - \\mu_{tot})^2\n$$ {#eq-SST}\n\nIf there are $k$ levels in `qual` and $n$ observations $y_ n$ for each\nlevel, we can also write:\n\n$$\nSST = \n\\sum_{i=1}^{kn}y_i^2 - \\frac{ \\left( \\sum_{i=1}^{kn}\ny_i \\right)^2}{kn}\n$$\n\nIn Fig B, the *horizontal* green and red lines are the means of the\nindividual groups, respectively $\\mu_A$ and $\\mu_B$. The green and red\nvertical lines are the departures, or errors, of each point from *its\nown group-mean*. The sum of the *squares* of the green and red lines is\ncalled the [**Total Error Sum of Squares**\n(SSE)]{style=\"background-color: yellow;\"}.\n\n$$\nSSE = \\Sigma [(y - \\mu_i)^2 +... (y - \\mu_k)^2]\n$$ {#eq-SSE}\n\nIf the $\\mu_A$ and $\\mu_B$ are different from $\\mu_{tot}$, then what\nwould be the relationship between $SSA$ and $SSE$ ? Clearly if the all\nmeans are identical then the $SST$ and $SSE$ are equal, since the two\ncoloured lines would be in the same place as the black line. It should\nbe clear that if $\\mu_A$ and $\\mu_B$ are different from the overall\nmean, then $SSE < SST$.\n\nSo, when we desire to detect if the two groups are different in their\nmeans, we take the difference:\n\n$$\nSSA = SST - SSE\n$$ {#eq-SSA}\n\n[$SSA$ is called the **Treatment Sum of\nSquares**]{style=\"background-color: yellow;\"} and is a measure the\ndifferences in means of observations at different levels of the factor.\n\n$SSA$ can also directly be re-written in a very symmetric fashion as:\n\n$$\n\\frac{\\sum_{i=1}^{k} \\left( \\sum_{j=1}^{n}y_{ij}\\right)^2 }{n} - \\frac{\\left( \\sum_{i=1}^{kn}\ny_i \\right)^2}{kn}\n$$\n\nNote that in the first term, we are calculating sums of observations\nwithin each group in the inner summation, which is like a per-group\nmean(without the division). The outer summation takes the sum of squares\nof these undivided summations and divides by $n$.\n\nComparing $SSA$ and $SSE$ now provides us with a method that helps us\ndecide whether these means are different. The logic is that we compare\nglobal differences and local differences. The comparison is of course in\nthe form of a [ratio, the\nF-statistic]{style=\"background-color: yellow;\"}. Since each of these\nmeasures uses a different sets of observations, the comparison is done\nafter scaling each of $SSA$ and $SSE$ by the number of observations\ninfluencing them. This means that we need to divide each of $SSA$ and\n$SSE$ by their [*degrees of\nfreedom*]{style=\"background-color: yellow;\"}, which gives us [a ratio of\n**variances**:]{style=\"background-color: yellow;\"}\n\n$$\nF_{stat} = \\frac{SSA / df_{SSA}}{SSE / df_{SSE}}\n$$\n\nwhere $df_{SSA}$ and $df_{SSE}$ are respectively the degrees of freedom\nin $SSA$ and $SSE$. And so we are in effect deciding if means are\nsignificantly different by analyzing (a ratio of) variances! Hence\n*AN-alysis O-f VA-riance*, **ANOVA**.\n\nIn order to find which of the means is significantly different from\nothers, we need to make a pair-wise comparison of the means, applying\nthe Bonferroni correction as stated before. This means we divide the\ncritial p.value we expect by the number of comparisons we make between\nlevels of the Qual variable.\n\n### ANOVA Manually Demonstrated(Apologies to Spinoza[^3])\n\nLet us hand-calculate the numbers so we know what the test is doing.\n\nHere is the SST:\n\n\n::: {.cell hash='ANOVA_cache/html/SST Total Sum of Squares_258bd3d9bbe8afd6d2752541037f35cf'}\n\n```{.r .cell-code}\n# Calculate overall sum squares SST\n\n\nfrogs_overall <- frogs_long %>% \n  summarise(mean_time = mean(Time), \n            # Overall mean across all readings\n            # The Black Line\n            \n            SST = sum((Time - mean_time)^2),\n            n = n())\nfrogs_overall\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mean_time\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SST\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"21.16667\",\"2\":\"1096.333\",\"3\":\"60\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nSST <- frogs_overall$SST\nSST\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1096.333\n```\n:::\n:::\n\n\nAnd here is our plot to understand the SST:\n\n\n::: {.cell hash='ANOVA_cache/html/Frogs SST Graph_078d770acc9da27a145fd14193b0a684'}\n\n```{.r .cell-code}\nfrogs_plot <- frogs_long %>% \n  arrange(TempFac) %>% \n           rowid_to_column(var = \"index\")\n\nfrogs_mean <- frogs_long %>%\n             summarise(overall_mean = mean(Time))\n\nfrogs_grouped_means <- frogs_long %>%\n  group_by(TempFac) %>% \n             summarise(grouped_means = mean(Time))\n\ngf_point(Time ~ index, \n         color = ~ TempFac,\n         data = frogs_plot) %>% \n  \n gf_hline(yintercept =  ~ overall_mean,\n             data = frogs_mean) %>% \n  \n  gf_segment(data = frogs_plot, \n             color = \"black\",\n             frogs_mean$overall_mean + Time ~ index + index) %>% \n  \n  gf_theme(theme = theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Frogs SST Graph-1.png){width=2100}\n:::\n:::\n\n\nAnd here is the SSE:\n\n\n::: {.cell hash='ANOVA_cache/html/SSE Within Group Sum of Squares_7cb21017643d65053c92e2fb6c1e03d5'}\n\n```{.r .cell-code}\n# Calculate sums of square errors *within* each group\n# with respect to individual group means\n\nfrogs_within_groups <- frogs_long %>% \n  group_by(TempFac) %>% \n   summarise(mean_time = mean(Time),\n            variance_time = var(Time),\n            group_error_squares = sum((Time - mean_time)^2),\n            n = n())\nfrogs_within_groups\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"mean_time\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"variance_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"group_error_squares\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"26.3\",\"3\":\"1.273684\",\"4\":\"24.2\",\"5\":\"20\"},{\"1\":\"18\",\"2\":\"21.0\",\"3\":\"1.263158\",\"4\":\"24.0\",\"5\":\"20\"},{\"1\":\"25\",\"2\":\"16.2\",\"3\":\"1.431579\",\"4\":\"27.2\",\"5\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nfrogs_SSE <- frogs_within_groups %>% \n  summarise(SSE = sum(group_error_squares))\n\nSSE <- frogs_SSE$SSE\nSSE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 75.4\n```\n:::\n:::\n\n::: {.cell hash='ANOVA_cache/html/Frogs SSE Plot_58a6125f0bd9c3ca865e2f232a53d318'}\n\n```{.r .cell-code}\nfrogs_plot <- frogs_long %>% \n  arrange(TempFac) %>% \n           rowid_to_column(var = \"index\")\n\nfrogs_mean <- frogs_long %>%\n             summarise(overall_mean = mean(Time))\n\nfrogs_grouped_means <- frogs_long %>%\n  group_by(TempFac) %>% \n             summarise(grouped_means = mean(Time))\n\ngf_point(Time ~ index, \n         group = ~ TempFac, \n         colour = ~ TempFac, \n         data = frogs_plot) %>% \n  \n  gf_hline(yintercept = ~ grouped_means, \n           colour = ~ TempFac,\n           data = frogs_grouped_means) %>% \n  \n  gf_segment(data = frogs_plot %>% filter(TempFac == 13 ),\n             frogs_grouped_means$grouped_means[1] + Time ~ index + index\n             ) %>% \n  \n  gf_segment(data = frogs_plot %>% filter(TempFac == 18),\n             frogs_grouped_means$grouped_means[2] + Time ~ index + index\n             ) %>% \n  \n  gf_segment(data = frogs_plot %>% filter(TempFac == 25),\n             frogs_grouped_means$grouped_means[3] + Time ~ index + index\n             ) %>% \n  gf_theme(theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Frogs SSE Plot-1.png){width=2100}\n:::\n:::\n\n\nOK, we have $SST$ and $SSE$, so let's get $SSA$:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-16_66faf034b2809cd6c5a3dee5cab47b8c'}\n\n```{.r .cell-code}\nSST\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1096.333\n```\n:::\n\n```{.r .cell-code}\nSSE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 75.4\n```\n:::\n\n```{.r .cell-code}\nSSA <- SST - SSE\nSSA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1020.933\n```\n:::\n:::\n\n\nWe have $SST = 1096$, $SSE = 75.4$ and therefore $SSA = 1020.9$.\n\nIn order to calculate the F-Statistic, we need to compute the variances,\nusing these sum of squares. We obtain variances by dividing by their\n*Degrees of Freedom*:\n\n$$\nF_{stat} = \\frac{SSA / df_{SSA}}{SSE / df_{SSE}}\n$$\n\nwhere $df_{SSA}$ and $df_{SSE}$ are respectively the degrees of freedom\nin SSA and SSE.\n\nLet us calculate these [Degrees of\nFreedom]{style=\"background-color: yellow;\"}. With $k = 3$ levels in the\nfactor `TempFac`, and $n = 20$ points per level, $SST$ clearly has\ndegree of freedom $kn-1$, since it uses all observations but loses one\ndegree to calculate the global mean. (If each level did not have the\nsame number of points $n$, we simply take all observations less one as\nthe degrees of freedom for $SST$).\n\n$SSE$ has $k*(n-1)$ as degrees of freedom, since each of the $k$ groups\nthere are $n$ observations and each group loses one degree to calculate\nits own group mean.\n\nAnd therefore $SSA$ has $k-1$ degrees of freedom.\n\nWe can still calculate these in R, for the sake of method and clarity:\n\n\n::: {.cell hash='ANOVA_cache/html/Degrees of Freedom_6ee5aad83317d2e9732e6b66c095e025'}\n\n```{.r .cell-code}\n# Error Sum of Squares SSE\ndf_SSE <- frogs_long %>% \n  \n  # Takes into account \"unbalanced\" situations\n  group_by(TempFac) %>% \n  summarise(per_group_df_SSE = n() - 1) %>% \n  summarise(df_SSE = sum(per_group_df_SSE)) %>% as.numeric()\n\n\n## Overall Sum of Squares SST\ndf_SST <- frogs_long %>% \n  summarise(df_SST = n() - 1) %>% as.integer()\n\n\n# Treatment Sum of Squares SSA\nk <- length(unique(frogs_long$TempFac))\ndf_SSA <- k - 1\n```\n:::\n\n\nThe degrees of freedom for the quantities are:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-18_7786759711050f9c18a98b489850eace'}\n\n```{.r .cell-code}\ndf_SST\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 59\n```\n:::\n\n```{.r .cell-code}\ndf_SSE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 57\n```\n:::\n\n```{.r .cell-code}\ndf_SSA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n\nNow we are ready to compute the F-statistic:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-19_05caa450b2ed70f64d60e2ead446d404'}\n\n```{.r .cell-code}\n# Finally F_Stat!\n# Combine the sum-square_error for each level of the factor\n# Weighted by degrees of freedom **per level**\n# Which are of course equal here ;-D\n\nMSE <- frogs_within_groups %>% \n  summarise(mean_square_error = sum(group_error_squares/df_SSE)) %>% \n  as.numeric()\nMSE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.322807\n```\n:::\n\n```{.r .cell-code}\nMSA <- SSA/df_SSA # This is OK\nMSA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 510.4667\n```\n:::\n\n```{.r .cell-code}\nF_stat <- MSA/MSE\nF_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 385.8966\n```\n:::\n:::\n\n\nThe `F-stat` is compared with a **critical value** of the\nF-statistic,`F_crit` which is computed using the formula for the\nf-distribution in R. As with our hypothesis tests, we set the\nsignificance level to $\\alpha = 0.95$, but here with the Bonferroni\ncorrection, and quote the two relevant degrees of freedom as parameters\nto `qf()` which computes the critical F value as a **quartile**:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-20_3365336093c4fe2456156d44e4cf0b9d'}\n\n```{.r .cell-code}\nF_crit <-  \n  qf(p = (1 - 0.05/3),  # Significance level is 5% + Bonferroni Correction\n          df1 = df_SSA, # Numerator degrees of freedom \n          df2 = df_SSE  # Denominator degrees of freedom\n     ) \nF_crit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.403048\n```\n:::\n\n```{.r .cell-code}\nF_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 385.8966\n```\n:::\n:::\n\n\nThe `F_crit` value can also be seen in a plot[^4]:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-21_3b760e242f64ad65c5324d1f9e866405'}\n\n```{.r .cell-code}\nmosaic::xpf(q = F_crit, \n            df1 = df_SSA, df2 = df_SSE,\n            log.p = FALSE,lower.tail = TRUE)\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-21-1.png){width=2100}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9833333\n```\n:::\n\n```{.r .cell-code}\ngf_dist(dist = \"f\",\n        params = list(df1 = df_SSA, df2=df_SSE),\n        linewidth  = 1,\n        xlim = c(0.002, 400), title = \"F distribution for Frog ANOVA\") %>% \n  gf_vline(xintercept = F_crit, linetype = \"dotted\", \n           colour = \"red\") %>% \n  gf_vline(xintercept = F_stat, linetype = \"dashed\", \n           color = \"dodgerblue\") %>% \n  gf_text( 0.25 ~ 360, label = \"F_stat\", colour = \"dodgerblue\") %>% \n  gf_text( 0.25 ~ 20, label = \"F_crit\", colour = \"red\") %>% \n  gf_theme(theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-21-2.png){width=2100}\n:::\n:::\n\n\nAny value of F more than the `F_crit` occurs with smaller probability\nthan $0.05/3$. Our F_stat is much higher than `F_crit`, by orders of\nmagnitude! And so we can say with confidence that Temperature has a\nsignificant effect on spawn Time.\n\nAnd that is how ANOVA computes!\n:::\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Checking ANOVA Assumptions\n\nANOVA makes 3 fundamental assumptions:\n\na.  Data are normally distributed.\nb.  Variances are homogeneous.\nc.  Observations are independent.\n\nWe can check these using checks and graphs.\n\n### {{< iconify ic twotone-rule >}} Checks for Normality\n\nThe `shapiro.wilk` test tests if a vector of numeric data is normally\ndistributed and rejects the hypothesis of normality when the\n[p-value](https://variation.com/wp-content/distribution_analyzer_help/hs132.htm)\nis less than or equal to 0.05. \n\n\n::: {.cell hash='ANOVA_cache/html/Check for Normality_d8206126e47724cd5b6c4a6dd5d0512a'}\n\n```{.r .cell-code}\nshapiro.test(x = frogs_long$Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  frogs_long$Time\nW = 0.92752, p-value = 0.001561\n```\n:::\n:::\n\n\nThe p-value is very low and we cannot reject the (alternative)\nhypothesis that the overall data is **not** normal. How about normality\nat each level of the factor?\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-23_7abb199943bf93e73f6405ffb99f81bf'}\n\n```{.r .cell-code}\nfrogs_grouped <- frogs_long %>% \n  group_by(TempFac) %>% \n  nest(.key = \"list\") # naming the nested column \"list\"\n\n# Checking if we can purrr\nfrogs_grouped %>% \n  pluck(\"list\", 1) %>% \n  select(Time) %>% \n  as_vector() %>% \n  shapiro.test(.)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  .\nW = 0.88954, p-value = 0.02638\n```\n:::\n\n```{.r .cell-code}\n# OK now we are set for group-wise Shapiro-Wilk testing with purrr:\n\nfrogs_grouped %>% \n  mutate(shaptest = \n           purrr::map(.x = list, # Column name is \"list\"\n                      .f = \\(.x) select(.data = .x, \n                                        Time) %>% \n                                 as_vector() %>% \n                                 shapiro.test(.)),\n         \n         params = map(.x = shaptest,\n                      .f = \\(.x) broom::tidy(.x))) %>% \n  \n  select(TempFac, params) %>% \n  unnest(cols = params)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"statistic\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"13\",\"2\":\"0.8895426\",\"3\":\"0.02637682\",\"4\":\"Shapiro-Wilk normality test\"},{\"1\":\"18\",\"2\":\"0.9254425\",\"3\":\"0.12614802\",\"4\":\"Shapiro-Wilk normality test\"},{\"1\":\"25\",\"2\":\"0.8978947\",\"3\":\"0.03766278\",\"4\":\"Shapiro-Wilk normality test\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe `shapiro.wilk` test makes a NULL Hypothesis that the data **are**\nnormally distributed and estimates the probability that this could have\nhappened by chance. Except for `TempFac = 18` the p-values are less than\n0.05 and we can reject the NULL hypothesis that each of these is\nnormally distributed. Perhaps this is a sign that we need more than 20\nsamples per factor level. Let there be more frogs !!!\n\nWe can also check the residuals post-model:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-24_2d8b9d9f328dcdb02c3d81b79ec7a8bf'}\n\n```{.r .cell-code}\nfrogs_anova$residuals %>% \n  as_tibble() %>% \n  gf_histogram(~ value,data = .) %>% \n  gf_theme(theme = theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-24-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nfrogs_anova$residuals %>%\n  as_tibble() %>% \n  gf_qq(~ value, data = .) %>% \n  gf_qqstep() %>% \n  gf_qqline() %>% \n  gf_theme(theme = theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-24-2.png){width=2100}\n:::\n\n```{.r .cell-code}\nshapiro.test(frogs_anova$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  frogs_anova$residuals\nW = 0.94814, p-value = 0.01275\n```\n:::\n:::\n\n\nUnsurprisingly, the residuals are also not normally distributed either.\n\n### {{< iconify ic twotone-rule >}} Check for Similar Variance\n\nResponse data with different variances at different levels of an\n*explanatory* variable are said to exhibit **heteroscedasticity**. This\nviolates one of the assumptions of ANOVA.\n\nTo check if the `Time` readings are similar in `variance` across levels\nof `TempFac`, we can use the [Levene\nTest]{style=\"background-color: yellow;\"}, or since our per-group\nobservations are not normally distributed, a non-parametric rank-based\n[Fligner-Killeen Test]{style=\"background-color: yellow;\"}. The NULL\nhypothesis is that the data **are** with similar variances. The tests\nassess how probable this is with the given data assuming this NULL\nhypothesis:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-25_de9253c3a7446e9c0f6eba6876ca0e7b'}\n\n```{.r .cell-code}\nfrogs_long %>% \n  group_by(TempFac) %>% \n  summarise(variance = var(Time))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"variance\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"1.273684\"},{\"1\":\"18\",\"2\":\"1.263158\"},{\"1\":\"25\",\"2\":\"1.431579\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Not too different...OK on with the test\nfligner.test(Time ~ TempFac, data = frogs_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tFligner-Killeen test of homogeneity of variances\n\ndata:  Time by TempFac\nFligner-Killeen:med chi-squared = 0.53898, df = 2, p-value = 0.7638\n```\n:::\n\n```{.r .cell-code}\nDescTools::LeveneTest(Time ~ TempFac, data = frogs_long)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2\",\"2\":\"0.3931034\",\"3\":\"0.6767746\",\"_rn_\":\"group\"},{\"1\":\"57\",\"2\":\"NA\",\"3\":\"NA\",\"_rn_\":\"\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIt seems that there is no cause for concern here; the data do not have\nsignificantly different variances.\n\n### {{< iconify ic twotone-rule >}} Independent Observations\n\nThis is an experiment *design* concern; the way the data is gathered\nmust be specified such that data for each level of the factors ( factor\ncombinations if there are more than one) should be independent.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Effect Size\n\nThe simplest way to find the actual `effect sizes` detected by an ANOVA\ntest is to use (paradoxically) the `summary.lm()` command:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-26_5be984f85998e18ad531e1202f69820f'}\n\n```{.r .cell-code}\ntidy_anova <- \n  frogs_anova %>% \n  summary.lm() %>% \n  broom::tidy()\ntidy_anova\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"26.3\",\"3\":\"0.2571777\",\"4\":\"102.26394\",\"5\":\"2.781059e-66\"},{\"1\":\"TempFac18\",\"2\":\"-5.3\",\"3\":\"0.3637041\",\"4\":\"-14.57228\",\"5\":\"7.081214e-21\"},{\"1\":\"TempFac25\",\"2\":\"-10.1\",\"3\":\"0.3637041\",\"4\":\"-27.76982\",\"5\":\"8.187867e-35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIt may take a bit of effort to understand this. First the `TempFac` is\narranged in order of levels, and the `mean` at the $TempFac = 13$ is\ntitled `Intercept`. That is $26.3$. The other two means for levels $18$\nand $25$ are stated as **differences** from this intercept, $-5.3$ and\n$-10.1$ respectively. The `p.value` for all these effect sizes is well\nbelow the desired confidence level of $0.05$.\n\nWe can easily plot bar-chart with error bars for the effect size:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-27_81eb2fcc02df163bb10573da8d7e0a20'}\n\n```{.r .cell-code}\ntidy_anova %>% \n  mutate(hi = estimate + std.error,\n         lo = estimate - std.error) %>% \n  gf_hline(data = ., yintercept = 0, \n           colour =\"grey\", \n           linewidth = 2) %>% \n  gf_col(estimate ~ term, \n         fill = \"grey\", \n         color = \"black\",\n         width = 0.15) %>% \n  gf_errorbar(hi + lo ~ term,\n              color = \"blue\",\n              width = 0.2) %>% \n  gf_point(estimate ~ term,\n           color = \"red\", \n           size = 3.5) %>% \n  gf_theme(theme_frogs()) %>% \n  gf_refine(scale_x_discrete(\"Temp Values\", \n                             labels = c(\"13°C\", \"18°C\", \"25°C\")))\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-27-1.png){width=2100}\n:::\n:::\n\n\nIf we want an \"absolute value\" plot for effect size, it needs just a\nlittle bit of work:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-28_d227e4ce04534f1b53b629bd54b4dd38'}\n\n```{.r .cell-code}\n# Merging group averages with `std.error`\nfrogs_long %>% \n  group_by(TempFac) %>% \n  summarise(mean = mean(Time)) %>% \n  cbind(std.error = tidy_anova$std.error) %>% \n  mutate(hi = mean + std.error,\n         lo = mean - std.error) %>% \n  gf_hline(data = ., yintercept = 0, \n           colour =\"grey\", \n           linewidth = 2) %>% \n  gf_col(mean ~ TempFac, \n         fill = \"grey\", \n         color = \"black\", width = 0.15) %>% \n  gf_errorbar(hi + lo ~ TempFac,\n                color = \"blue\",\n                width =0.2) %>% \n  gf_point(mean ~ TempFac, \n           color = \"red\", \n           size = 3.5) %>% \n  gf_theme(theme_frogs()) %>% \n  gf_refine(scale_x_discrete(\"Temp Values\", \n                             labels = c(\"13°C\", \"18°C\", \"25°C\")))\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-28-1.png){width=2100}\n:::\n:::\n\n\n## {{< iconify flat-color-icons workflow >}} Workflow: ANOVA using Permutation Tests\n\nWe wish to establish the significance of the effect size due to each of\nthe levels in `TempFac`. From the normality tests conducted earlier we\nsee that except at one level of `TempFac`, the times are are not\nnormally distributed. Hence we opt for a Permutation Test to check for\nsignificance of effect.\n\nAs remarked in Ernst[^5], the non-parametric permutation test can be\nboth *exact* and also **intuitively easier** for students to grasp.\nPermutations are easily executed in R, using packages such as\n`mosaic`[^6].\n\nWe proceed with a Permutation Test for `TempFac`. We shuffle the levels\n(13, 18, 25) randomly between the Times and repeat the ANOVA test each\ntime and calculate the F-statistic. The Null distribution is the\ndistribution of the F-statistic over the many permutations and the\np-value is given by the proportion of times the F-statistic equals or\nexceeds that observed.\n\nWe will use `mosaic` first, and also try with `infer`.\n\n::: panel-tabset\n### Using `mosaic`\n\n`mosaic` offers an easy and intuitive way of doing a repeated\npermutation test, using the `do()` command. We will `shuffle` the\n`TempFac` factor to jumble up the `Time` observations, 5000 times. Each\ntime we shuffle, we compute the F_statistic and record it. We then plot\nthe 5000 F-statistics and compare that with the real-world observation\nof `F-stat`.\n\n\n::: {.cell hash='ANOVA_cache/html/permutation test for ANOVA with mosaic_1aeb185770e681b5209343ccaa8f1eb9'}\n\n```{.r .cell-code}\nobs_F_stat <- \n  frogs_anova %>% \n  broom::tidy() %>% \n  select(statistic)\nobserved_mosaic <- obs_F_stat$statistic[1]\nobserved_mosaic\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 385.8966\n```\n:::\n\n```{.r .cell-code}\nnull_dist_mosaic <- do(5000) * aov(Time ~ shuffle(TempFac), \n                                    data = frogs_long)\nnull_dist_mosaic %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"SS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"MS\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pval\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".row\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"71.23333\",\"4\":\"35.61667\",\"5\":\"1.9804409\",\"6\":\"0.1473917\",\"7\":\"1\",\"8\":\"1\",\"_rn_\":\"shuffle(TempFac)...1\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1025.10000\",\"4\":\"17.98421\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"1\",\"_rn_\":\"Residuals...2\"},{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"20.23333\",\"4\":\"10.11667\",\"5\":\"0.5358703\",\"6\":\"0.5880786\",\"7\":\"1\",\"8\":\"2\",\"_rn_\":\"shuffle(TempFac)...3\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1076.10000\",\"4\":\"18.87895\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"2\",\"_rn_\":\"Residuals...4\"},{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"66.13333\",\"4\":\"33.06667\",\"5\":\"1.8295477\",\"6\":\"0.1697850\",\"7\":\"1\",\"8\":\"3\",\"_rn_\":\"shuffle(TempFac)...5\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1030.20000\",\"4\":\"18.07368\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"3\",\"_rn_\":\"Residuals...6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nnull_dist_mosaic %>% drop_na() %>% \n  select(F) %>% \n  gf_histogram(data = ., ~ F, \n               fill = ~ F >= observed_mosaic,\n               title = \"Null Distribution of ANOVA F-statistic\" ) %>% \n  gf_theme(theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/permutation test for ANOVA with mosaic-1.png){width=2100}\n:::\n:::\n\n\nThe Null distribution of the `F_statistic` under permutation shows it\nnever crosses the real-world observed value, testifying as to the\nstrength of the effect of `TempFac` on hatching `Time`. And the\n`p-value` is:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-30_3847bc6a5b4a2f088901ed313305748b'}\n\n```{.r .cell-code}\np_value <- mean(null_dist_mosaic$F >= observed_mosaic, na.rm = TRUE)\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n### Using `infer`\n\nWe calculate the observed F-stat with `infer`, which also has a very\ndirect, if verbose, syntax for doing permutation tests:\n\n\n::: {.cell hash='ANOVA_cache/html/ANOVA F-statistic with infer_f83a98644e6df16104bd17ebbd56d831'}\n\n```{.r .cell-code}\nobserved_infer <- \n  frogs_long %>% \n  specify(Time ~ TempFac) %>% \n  hypothesise(null = \"independence\") %>% \n  calculate(stat = \"F\")\nobserved_infer\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"stat\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"385.8966\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWe see that the observed F-Statistic is of course $385.8966$ as before.\nNow we use `infer` to generate a NULL distribution using permutation of\nthe factor `TempFac`:\n\n\n::: {.cell hash='ANOVA_cache/html/Permutation using infer_1359a8786c3a6b507cafbc9adc8af79e'}\n\n```{.r .cell-code}\nnull_dist_infer <- frogs_long %>% \n  specify(Time ~ TempFac) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 5000, type = \"permute\") %>% \n  calculate(stat = \"F\")\n\nhead(null_dist_infer)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"replicate\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"stat\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"2.84895154\"},{\"1\":\"2\",\"2\":\"4.04400583\"},{\"1\":\"3\",\"2\":\"0.02428337\"},{\"1\":\"4\",\"2\":\"2.27161710\"},{\"1\":\"5\",\"2\":\"0.67686058\"},{\"1\":\"6\",\"2\":\"0.09738239\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nnull_dist_infer %>% \n  visualise() %>% \n  gf_theme(theme_frogs())\n```\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Permutation using infer-1.png){width=2100}\n:::\n:::\n\n\nAs seen, the `infer` based permutation test also shows that the\npermutationally generated F-statistics are nowhere near that which was\nobserved. The effect of `TempFac` is very strong.\n:::\n\n## {{< iconify fluent-mdl2 decision-solid >}} Conclusions\n\nWe have discussed ANOVA as a means of modelling the effects of a\nCategorical variable on a Continuous (Quant) variable. ANOVA can be\ncarried out using the standard formula `aov` when assumptions on\ndistributions, variances, and independence are met. Permutation ANOVA\ntests can be carried out when these assumptions do not quite hold.\n\n## {{< iconify ooui references-rtl >}} References\n\n1.  The ANOVA tutorial at [Our Coding\n    Club](https://ourcodingclub.github.io/tutorials/anova/).\n2.  Michael Crawley, The R Book,second edition, 2013. Chapter 11.\n3.  David C Howell, [Permutation Tests for Factorial ANOVA\n    Designs](https://www.uvm.edu/~statdhtx/StatPages/Permutation%20Anova/PermTestsAnova.html)\n4.  Marti Anderson, [Permutation tests for univariate or multivariate\n    analysis of variance and\n    regression](https://www.academia.edu/50056272/Permutation_tests_for_univariate_or_multivariate_analysis_of_variance_and_regression?auto=download)\n\n[^1]: The ANOVA tutorial at [Our Coding\n    Club](https://ourcodingclub.github.io/tutorials/anova/).\n\n[^2]: https://www.openintro.org/go/?id=anova-supplement&referrer=/book/ahss/index.php\n\n[^3]: Spinoza: Ethics Geometrically Demonstrated: [spinoza1665.pdf\n    (earlymoderntexts.com)](https://www.earlymoderntexts.com/assets/pdfs/spinoza1665.pdf)\n\n[^4]: Pruim R, Kaplan DT, Horton NJ (2017). \"The mosaic Package: Helping\n    Students to 'Think with Data' Using R.\" The R Journal, 9(1),\n    77--102.\n    https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n\n[^5]: Ernst, Michael D. 2004. \"Permutation Methods: A Basis for Exact\n    Inference.\" Statistical Science 19 (4): 676--85.\n    doi:10.1214/088342304000000396.\n\n[^6]: Pruim R, Kaplan DT, Horton NJ (2017). \"The mosaic Package: Helping\n    Students to 'Think with Data' Using R.\" The R Journal, 9(1),\n    77--102.\n    https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}