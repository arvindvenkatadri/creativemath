{
  "hash": "ec3bacbd228c64f957bdad6b754c2cb5",
  "result": {
    "markdown": "---\ntitle: \"Comparing Multiple Means with ANOVA\"\nauthor: \"Arvind V.\"\nformat: html\neditor: source\nabstract: \"ANOVA to investigate how frogspawn hatching time varies with temperature.\"\ndate: 28/Mar/2023\ndate-modified: \"2023-12-14\"\norder: 130\nimage: preview.jpg\nbibliography: \n  - references.bib\n  - grateful-refs.bib\ncitation: true\n#suppress-bibliography: true\n---\n\n\n## {{< iconify noto-v1 package >}} Setting up R Packages\n\n\n::: {.cell hash='ANOVA_cache/html/setup_e0da8af432cc1bc5f3ecb55225182bf0'}\n\n````{.cell-code}\n```{{r}}\n#| label: setup\n#| message: true\n#| warning: false\nknitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE, tidy = TRUE)\nlibrary(tidyverse) # Tidy data processing \nlibrary(ggformula) # Formula based plots\nlibrary(mosaic) # Data inspection and Statistical Inference \nlibrary(infer) # Statistical Inference\nlibrary(cowplot) # Arranging Plots\n```\n````\n:::\n\n::: {.cell hash='ANOVA_cache/html/Extra Pedagogical Packages_41e373ef7b01907ccd8612eb41bc9580'}\n\n:::\n\n::: {.cell hash='ANOVA_cache/html/plot theme_8d863db458ac54d941e6dc65f8794c3c'}\n\n````{.cell-code}\n```{{r}}\n#| label: plot theme\n# Let us set a plot theme for Data visualization\nlibrary(showtext)\nlibrary(sysfonts)\nfont_add_google(\"Merriweather Sans\", \"Merri\")\nmy_theme <- function() {\n  # Creating a function\n  theme_classic() +  # Using pre-defined theme as base\n    theme(\n      text = element_text(family = \"Merri\"),\n      plot.title = element_text(face = \"bold\", size = 14),\n      axis.text.x = element_text(size = 10, face = \"bold\"),\n      # Customizing axes text\n      axis.text.y = element_text(size = 10, face = \"bold\"),\n      axis.title = element_text(size = 12, face = \"bold\"),\n      # Customizing axis title\n      panel.grid = element_blank(),\n      # Taking off the default grid\n      plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , \"cm\"),\n      legend.text = element_text(size = 8, face = \"italic\"),\n      # Customizing legend text\n      legend.title = element_text(size = 10, face = \"bold\"),\n      # Customizing legend title\n      legend.position = \"right\",\n      # Customizing legend position\n      plot.caption = element_text(size = 8)\n    )  # Customizing plot caption\n}   \n```\n````\n:::\n\n\n## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction\n\nSuppose we have three sales strategies on our website, to sell a certain\nproduct, say men's shirts. We have observations of customer website\ninteractions over several months. How do we know which strategy makes\npeople buy the fastest ?\n\nIf there is a University course that is offered in parallel in three\ndifferent classrooms, is there a difference between the average marks\nobtained by students in each of the classrooms?\n\nIn each case we have a set of observations in each category: Interaction\nTime vs Sales Strategy in the first example, and Student Marks vs\nClassroom in the second. We can take *mean* scores in each category and\ndecide to compare them. How do we make the comparisons? One way would be\nto compare them pair-wise. But with this rapidly becomes intractable and\nalso dangerous: with increasing number of `groups`, the number of\nmean-comparisons becomes very large $N\\choose 2$ and with each\ncomparison the possibility of some difference showing up, *just by\nchance*, increases! And we end up making the wrong inference and perhaps\nthe wrong decision.\n\nThe trick is of course to make comparisons **all at once** and ANOVA is\nthe technique that allows us to do just that. In this tutorial, we will\ncompare the Hatching Time of frog spawn[^1], at three different lab\ntemperatures.\n\nIn this tutorial, our research question is:\n\n::: callout-note\n## Research Question\n\nHow does frogspawn hatching time vary with different temperature\nsettings?\n:::\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Read the Data\n\nDownload the data by clicking the button below.\n\n\n{{< downloadthis data/frogs.csv dname=\"frogs\" label=\"Download the frogs data\" icon=\"database-fill-down\" type=\"info\" >}}\n\n\n\n::: callout-important\n## Data Folder\n\nSave the CSV in a subfolder titled \"data\" inside your R work folder.\n:::\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-4_7fc5470a2aaaf684567800d9e51eb293'}\n\n````{.cell-code}\n```{{r}}\nfrogs_orig <- read_csv(\"data/frogs.csv\")\nfrogs_orig\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Frogspawn sample id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature13\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature18\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature25\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"24\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"2\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"3\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"18\"},{\"1\":\"4\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"5\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"6\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"14\"},{\"1\":\"7\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"8\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"9\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"10\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"11\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"12\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"13\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"14\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"15\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"16\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"17\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"18\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"19\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"20\",\"2\":\"NA\",\"3\":\"19\",\"4\":\"NA\"},{\"1\":\"21\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"22\",\"2\":\"25\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"23\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"24\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"25\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"26\",\"2\":\"NA\",\"3\":\"23\",\"4\":\"NA\"},{\"1\":\"27\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"28\",\"2\":\"28\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"29\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"30\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"31\",\"2\":\"24\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"32\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"33\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"18\"},{\"1\":\"34\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"35\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"36\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"14\"},{\"1\":\"37\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"38\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"39\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"40\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"41\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"42\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"43\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"44\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"45\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"46\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"47\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"48\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"49\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"50\",\"2\":\"NA\",\"3\":\"19\",\"4\":\"NA\"},{\"1\":\"51\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"52\",\"2\":\"25\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"53\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"54\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"55\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"56\",\"2\":\"NA\",\"3\":\"23\",\"4\":\"NA\"},{\"1\":\"57\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"58\",\"2\":\"28\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"59\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"60\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nOur response variable is the hatching `Time`. Our explanatory variable\nis a *factor*, `Temperature`, with 3 levels: 13°C, 18°C and 25°C.\nDifferent samples of spawn were subject to each of these temperatures\nrespectively.\n\n## {{< iconify material-symbols pivot-table-chart >}} Workflow: Clean the Data\n\nThe data is badly organized, with a separate column for each\nTemperature, and a common column for Sample ID. There are NA entries\nsince not all samples of spawn can be subject to all temperatures. (E.g.\nSample ID #1 was maintained at 13°C).\n\nWe will first stack up the `Temperature**` columns into a single column,\nseparate that into pieces and then retain just the number part (13, 18,\n25), getting rid of the *word* `Temperature` from the column titles.\nThen the remaining **numerical** column with temperatures (13, 18, 25)\nwill be converted into a factor.\n\nWe will use `pivot_longer()`and `separate_wider_regex()` to achieve\nthis. \\[See this animation for pivot_longer():\n<https://haswal.github.io/pivot/> \\]\n\n\n::: {.cell layout-ncol=\"2\" hash='ANOVA_cache/html/unnamed-chunk-5_33875e7bf4446cecf500c14a81e329bf'}\n\n````{.cell-code}\n```{{r}}\n#| layout-ncol: 2\nfrogs_orig %>%\n  pivot_longer(\n    .,\n    cols = starts_with(\"Temperature\"),\n    cols_vary = \"fastest\",\n    # new in pivot_longer\n    names_to = \"Temp\",\n    values_to = \"Time\"\n  ) %>%\n  drop_na() %>%\n  \n  separate_wider_regex(\n    cols = Temp,\n  # knock off the unnecessary \"Temperature\" word everywhere\n  # Just keep the digits thereafter\n    patterns = c(\"Temperature\",\n                 TempFac = \"\\\\d+\"),\n    cols_remove = TRUE\n  ) %>%\n  \n  # Convert Temp into TempFac, a 3-level factor\n  mutate(TempFac = factor(\n    x = TempFac,\n    levels = c(13, 18, 25),\n    labels = c(\"13\", \"18\", \"25\")\n  )) %>%\n  rename(\"Id\" = `Frogspawn sample id`) -> frogs_long\n\nfrogs_long\n\nfrogs_long %>% count(TempFac)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"TempFac\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"13\",\"3\":\"24\"},{\"1\":\"2\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"3\",\"2\":\"25\",\"3\":\"18\"},{\"1\":\"4\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"5\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"6\",\"2\":\"25\",\"3\":\"14\"},{\"1\":\"7\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"8\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"9\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"10\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"11\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"12\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"13\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"14\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"15\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"16\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"17\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"18\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"19\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"20\",\"2\":\"18\",\"3\":\"19\"},{\"1\":\"21\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"22\",\"2\":\"13\",\"3\":\"25\"},{\"1\":\"23\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"24\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"25\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"26\",\"2\":\"18\",\"3\":\"23\"},{\"1\":\"27\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"28\",\"2\":\"13\",\"3\":\"28\"},{\"1\":\"29\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"30\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"31\",\"2\":\"13\",\"3\":\"24\"},{\"1\":\"32\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"33\",\"2\":\"25\",\"3\":\"18\"},{\"1\":\"34\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"35\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"36\",\"2\":\"25\",\"3\":\"14\"},{\"1\":\"37\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"38\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"39\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"40\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"41\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"42\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"43\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"44\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"45\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"46\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"47\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"48\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"49\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"50\",\"2\":\"18\",\"3\":\"19\"},{\"1\":\"51\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"52\",\"2\":\"13\",\"3\":\"25\"},{\"1\":\"53\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"54\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"55\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"56\",\"2\":\"18\",\"3\":\"23\"},{\"1\":\"57\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"58\",\"2\":\"13\",\"3\":\"28\"},{\"1\":\"59\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"60\",\"2\":\"25\",\"3\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div><div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"20\"},{\"1\":\"18\",\"2\":\"20\"},{\"1\":\"25\",\"2\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nSo we have cleaned up our data and have `20` samples for Hatching `Time`\nper `TempFac` setting.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: EDA\n\nLet us plot some histograms and boxplots of Hatching Time:\n\n\n::: {.cell .column-screen-inset-right layout-ncol=\"2\" hash='ANOVA_cache/html/unnamed-chunk-6_d4f7b84b5433dce338f6f041fd797ca2'}\n\n````{.cell-code}\n```{{r}}\n#| results: hold\n#| layout-ncol: 2\n#| column: screen-inset-right\ngf_histogram(data = frogs_long,\n             ~ Time,\n             fill = ~ TempFac,\n             stat = \"count\") %>%\n  gf_vline(xintercept = ~ mean(Time)) %>%\n  gf_labs(x = \"Hatching Time\", y = \"Count\") %>%\n  gf_text(7 ~ (mean(Time) + 2),\n          label = \"Overall Mean\") %>%\n  gf_theme(theme = my_theme(),\n           guides(fill = guide_legend(title = \"Temperature level (°C)\"))) \n\n\ngf_boxplot(data = frogs_long,\n           Time ~ TempFac,\n           fill = ~ TempFac) %>%\n  gf_vline(xintercept = ~ mean(Time)) %>%\n  gf_labs(x = \"Temperature\", y = \"Hatching Time\") %>%\n  gf_theme(theme = my_theme(),\n           guides(fill = guide_legend(title = \"Temperature level (°C)\")))\n```\n````\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-6-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-6-2.png){width=2100}\n:::\n:::\n\n\nThe histograms look well separated and the box plots also show very\nlittle overlap. So we can reasonably hypothesize that Temperature has a\nsignificant effect on Hatching Time.\n\nOne more slightly esoteric plot: Jitter/Scatter with a new *categorical\nx-axis* offered by the `ggprism` package:\n\n\n::: {.cell hash='ANOVA_cache/html/using ggprism_176b6d0997e3ac1333b30cc77b19b485'}\n\n````{.cell-code}\n```{{r}}\n#| label: using ggprism\nlibrary(ggprism)\ngf_jitter(\n  frogs_long,\n  Time ~ TempFac,\n  color = ~ TempFac,\n  xlab = \"Temperature as Factor\",\n  ylab = \"Hatching Time\",\n  caption = \"Using `ggprism` package\"\n) %>%\n  gf_theme(theme_prism(base_family = theme_get()$font$family)) %>%\n  gf_refine(theme(legend.position = \"none\"),\n            scale_x_discrete(guide = \"prism_bracket\"))\n```\n````\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/using ggprism-1.png){width=2100}\n:::\n:::\n\n\nLet's go ahead with our ANOVA test.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: ANOVA\n\nWe will first execute the ANOVA test with code and evaluate the results.\nThen we will do an intuitive walk through of the process and finally,\nhand-calculate entire analysis for clear understanding.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### ANOVA Test with Code\n\nR offers a very simple command to execute an ANOVA test: Note the\nfamiliar `formula` of stating the variables:\n\n\n::: {.cell hash='ANOVA_cache/html/ANOVA with code_dd3df112d0d1806a2912da5b76f95e30'}\n\n````{.cell-code}\n```{{r}}\n#| label: ANOVA with code\nfrogs_anova <- aov(Time ~ TempFac, data = frogs_long)\nsummary(frogs_anova)\nfrogs_anova %>% broom::tidy()\nsummary.lm(frogs_anova) %>% broom::tidy()\nfrogs_anova %>% broom::glance()\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \nTempFac      2 1020.9   510.5   385.9 <2e-16 ***\nResiduals   57   75.4     1.3                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sumsq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"meansq\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"TempFac\",\"2\":\"2\",\"3\":\"1020.933\",\"4\":\"510.466667\",\"5\":\"385.8966\",\"6\":\"7.357304e-34\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"75.400\",\"4\":\"1.322807\",\"5\":\"NA\",\"6\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div><div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"26.3\",\"3\":\"0.2571777\",\"4\":\"102.26394\",\"5\":\"2.781059e-66\"},{\"1\":\"TempFac18\",\"2\":\"-5.3\",\"3\":\"0.3637041\",\"4\":\"-14.57228\",\"5\":\"7.081214e-21\"},{\"1\":\"TempFac25\",\"2\":\"-10.1\",\"3\":\"0.3637041\",\"4\":\"-27.76982\",\"5\":\"8.187867e-35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div><div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"logLik\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIC\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviance\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"r.squared\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-91.99019\",\"2\":\"191.9804\",\"3\":\"200.3578\",\"4\":\"75.4\",\"5\":\"60\",\"6\":\"0.9312253\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe effect of Temperature on Hatching time is significant, with a\np-value of $<2e-16$. The F-statistic for the ANOVA test is given by\n$385.9$, which is very high, and the `r.squared` value ( to be discussed\nlater) is also large, $0.931$. Clearly `Temperature` has a very\nsignificant effect on the hatching `Time`.\n\nTo find which specific value of `TempFac` has the most effect will\nrequire *pairwise comparison* of the group means, using a standard\n`t-test`. The confidence level for such repeated comparisons will need\nwhat is called ***Bonferroni correction***[^2] to prevent us from\ndetecting a significant (pair-wise) difference simply by chance. To do\nthis we take $\\alpha = 0.05$, the confidence level used and divide it by\n$K$, the number of pair-wise comparisons we intend to make. This new\nvalue is used to decide on the significance of the estimated parameter.\nSo the pairwise comparisons in our current data will have to use\n$\\alpha/3 = 0.0166$ as the confidence level.\n\n### ANOVA Intuitive {#sec-anova-intuitive}\n\nAll that is very well, but what is happening under the hood of the\n`aov()` command?\n\nConsider a data set with a single Quant and a single Qual variable. The\nQual variable has two levels, the Quant data has 20 observations per\nQual level.\n\n\n::: {.cell layout-nrow=\"1\" hash='ANOVA_cache/html/Anova Intuitive_9b1a13a37add5e9bdceadf394e18507d'}\n\n````{.cell-code}\n```{{r}}\n#| layout-nrow: 1\n#| label: Anova Intuitive\n#| warning: false\nlibrary(ggtext)\nset.seed(42) # for replication\ndata = tibble(\n  index = 1:40,\n  qual = c(rep(x = \"A\", 20), rep(x = \"B\", 20)),\n  quant = c(rnorm(\n    n = 20, mean = 0, sd = 2\n  ),\n  rnorm(\n    n = 20, mean = 10, sd = 2\n  ))\n)\ndata\noverall_mean <- data %>%\n  summarise(overall_mean = mean(quant))\n#overall_mean\n\ngrouped_means <- data %>%\n  group_by(qual) %>%\n  summarise(grouped_means = mean(quant))\n#grouped_means\n\np1 <- gf_segment(\n  data = data,\n  color = \"black\",\n  overall_mean$overall_mean + quant ~ index + index,\n  ylab = \"quant\") %>% \n  gf_point(quant ~ index,\n               color = ~ qual,\n               data = data) %>%\n  gf_hline(yintercept =  ~ overall_mean,\n           data = overall_mean) %>%\n  gf_text(4.25 ~ 30,\n          label = expression(paste(mu, \"_tot\")),\n          inherit = F) %>%\n  gf_theme(my_theme())\n\np2 <- gf_point(\n  quant ~ index,\n  group = ~ qual,\n  colour = ~ qual,\n  data = data\n) %>%\n  gf_hline(\n    yintercept = ~ mean,\n    colour = ~ qual,\n    data = data %>%\n      group_by(qual) %>%\n      summarise(mean = mean(quant))\n  ) %>%\n  gf_segment(data = data %>% filter(qual == \"A\"),\n             grouped_means$grouped_means[1] + quant ~ index + index) %>%\n  gf_segment(data = data %>% filter(qual == \"B\"),\n             grouped_means$grouped_means[2] + quant ~ index + index) %>%\n  gf_text(10.0 ~ 10,\n          label = expression(paste(mu, \"_B\")),\n          inherit = F) %>%\n  gf_text(1 ~ 38,\n          label = expression(paste(mu, \"_A\")),\n          inherit = F) %>%\n  gf_theme(my_theme())\n\n\ncowplot::plot_grid(p1, p2, labels = c(\"Fig A: SST\", \"Fig B: SSE\"))\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"index\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"qual\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"quant\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"A\",\"3\":\"2.7419169\"},{\"1\":\"2\",\"2\":\"A\",\"3\":\"-1.1293963\"},{\"1\":\"3\",\"2\":\"A\",\"3\":\"0.7262568\"},{\"1\":\"4\",\"2\":\"A\",\"3\":\"1.2657252\"},{\"1\":\"5\",\"2\":\"A\",\"3\":\"0.8085366\"},{\"1\":\"6\",\"2\":\"A\",\"3\":\"-0.2122490\"},{\"1\":\"7\",\"2\":\"A\",\"3\":\"3.0230440\"},{\"1\":\"8\",\"2\":\"A\",\"3\":\"-0.1893181\"},{\"1\":\"9\",\"2\":\"A\",\"3\":\"4.0368474\"},{\"1\":\"10\",\"2\":\"A\",\"3\":\"-0.1254282\"},{\"1\":\"11\",\"2\":\"A\",\"3\":\"2.6097393\"},{\"1\":\"12\",\"2\":\"A\",\"3\":\"4.5732908\"},{\"1\":\"13\",\"2\":\"A\",\"3\":\"-2.7777214\"},{\"1\":\"14\",\"2\":\"A\",\"3\":\"-0.5575775\"},{\"1\":\"15\",\"2\":\"A\",\"3\":\"-0.2666427\"},{\"1\":\"16\",\"2\":\"A\",\"3\":\"1.2719008\"},{\"1\":\"17\",\"2\":\"A\",\"3\":\"-0.5685058\"},{\"1\":\"18\",\"2\":\"A\",\"3\":\"-5.3129108\"},{\"1\":\"19\",\"2\":\"A\",\"3\":\"-4.8809339\"},{\"1\":\"20\",\"2\":\"A\",\"3\":\"2.6402267\"},{\"1\":\"21\",\"2\":\"B\",\"3\":\"9.3867228\"},{\"1\":\"22\",\"2\":\"B\",\"3\":\"6.4373831\"},{\"1\":\"23\",\"2\":\"B\",\"3\":\"9.6561653\"},{\"1\":\"24\",\"2\":\"B\",\"3\":\"12.4293494\"},{\"1\":\"25\",\"2\":\"B\",\"3\":\"13.7903869\"},{\"1\":\"26\",\"2\":\"B\",\"3\":\"9.1390617\"},{\"1\":\"27\",\"2\":\"B\",\"3\":\"9.4854612\"},{\"1\":\"28\",\"2\":\"B\",\"3\":\"6.4736738\"},{\"1\":\"29\",\"2\":\"B\",\"3\":\"10.9201947\"},{\"1\":\"30\",\"2\":\"B\",\"3\":\"8.7200102\"},{\"1\":\"31\",\"2\":\"B\",\"3\":\"10.9109002\"},{\"1\":\"32\",\"2\":\"B\",\"3\":\"11.4096747\"},{\"1\":\"33\",\"2\":\"B\",\"3\":\"12.0702070\"},{\"1\":\"34\",\"2\":\"B\",\"3\":\"8.7821472\"},{\"1\":\"35\",\"2\":\"B\",\"3\":\"11.0099102\"},{\"1\":\"36\",\"2\":\"B\",\"3\":\"6.5659826\"},{\"1\":\"37\",\"2\":\"B\",\"3\":\"8.4310820\"},{\"1\":\"38\",\"2\":\"B\",\"3\":\"8.2981848\"},{\"1\":\"39\",\"2\":\"B\",\"3\":\"5.1715847\"},{\"1\":\"40\",\"2\":\"B\",\"3\":\"10.0722452\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Anova Intuitive-1.png){width=2100}\n:::\n:::\n\n\nIn Fig A, the *horizontal* black line is the overall mean of `quant`,\ndenoted as $\\mu_{tot}$. The vertical black lines to the points show the\ndepartures of each point from this overall mean. The sum of *squares* of\nthese vertical black lines in Fig A is called the [**Total Sum of\nSquares** (SST)]{style=\"background-color: yellow;\"}.\n\n$$\nSST = \\Sigma (y - \\mu_{tot})^2\n$$ {#eq-SST}\n\n::: callout-note\nIf there are $k$ levels in `qual` and $n$ observations $y_ n$ for each\nlevel, we can also write:\n\n$$\nSST = \n\\sum_{i=1}^{kn}y_i^2 - \\frac{ \\left( \\sum_{i=1}^{kn}\ny_i \\right)^2}{kn}\n$$\n:::\n\nIn Fig B, the *horizontal* green and red lines are the means of the\nindividual groups, respectively $\\mu_A$ and $\\mu_B$. The green and red\nvertical lines are the departures, or errors, of each point from *its\nown group-mean*. The sum of the *squares* of the green and red lines is\ncalled the [**Total Error Sum of Squares**\n(SSE)]{style=\"background-color: yellow;\"}.\n\n$$\nSSE = \\Sigma [(y - \\mu_i)^2 +... (y - \\mu_k)^2]\n$$ {#eq-SSE}\n\nIf the $\\mu_A$ and $\\mu_B$ are different from $\\mu_{tot}$, then what\nwould be the relationship between $SST$ and $SSE$ ? [Clearly if the all\nmeans are identical then the $SST$ and $SSE$ are equal, since the two\ncoloured lines would be in the same place as the black\nline]{style=\"background-color: yellow;\"}. It should be clear that if\n$\\mu_A$ and $\\mu_B$ are different from the overall mean $\\mu_{tot}$,\nthen $SSE < SST$.\n\nSo, when we desire to detect if the two groups are different in their\nmeans, we take the difference:\n\n$$\nSSA = SST - SSE\n$$ {#eq-SSA}\n\n[$SSA$ is called the **Treatment Sum of\nSquares**]{style=\"background-color: yellow;\"} and is a measure the\ndifferences in means of observations at different levels of the factor.\n\n::: callout-note\n$SSA$ can also directly be re-written in a very symmetric fashion as:\n\n$$\n\\frac{\\sum_{i=1}^{k} \\left( \\sum_{j=1}^{n}y_{ij}\\right)^2 }{n} - \\frac{\\left( \\sum_{i=1}^{kn}\ny_i \\right)^2}{kn}\n$$\n\nNote that in the first term, we are calculating sums of observations\nwithin each group in the inner summation, which is like a per-group\nmean(without the division). The outer summation takes the sum of squares\nof these undivided summations and divides by $n$.\n:::\n\nComparing $SSA$ and $SSE$ now provides us with a method that helps us\ndecide whether these means are different. $SSA$ is the leftover\nunexplained error using $\\mu_{tot}$ as the estimate (NULL Hypothesis).\n$SSE$ is the unexplained error using individual means per group\n(Alternative Hypothesis). The logic in comparing these two global\ndifferences and local differences is there *must* be a significant\n**reduction** in unexplained error going from NULL to Alternative\nHypothesis.\n\nBefore we compare, we need to scale: since each of these measures uses a\ndifferent set of observations, the comparison is done after scaling each\nof $SSA$ and $SSE$ by the number of observations influencing them. (a\nsort of \"per capita\" error). This means that we need to divide each of\n$SSA$ and $SSE$ by their [*degrees of\nfreedom*]{style=\"background-color: yellow;\"}, which gives us [a ratio of\n**variances**, the F-statistic]{style=\"background-color: yellow;\"}:\n\n$$\nF_{stat} = \\frac{SSA / df_{SSA}}{SSE / df_{SSE}}\n$$\n\nwhere $df_{SSA}$ and $df_{SSE}$ are respectively the degrees of freedom\nin $SSA$ and $SSE$. [And so we are in effect deciding if means are\nsignificantly different by analyzing (a ratio of)\nvariances!]{style=\"background-color: yellow;\"} Hence *AN-alysis O-f\nVA-riance*, **ANOVA**.\n\nIn order to find which of the means is significantly different from\nothers, we need to make a pair-wise comparison of the means, applying\nthe Bonferroni correction as stated before. This means we divide the\ncritical `p.value` we expect by the number of comparisons we make\nbetween levels of the Qual variable. More on this shortly.\n\n### ANOVA Manually Demonstrated[^3](Apologies to Spinoza)\n\nNow that we understand what `aov()` is doing, let us hand-calculate the\nnumbers for our `frogs` dataset and check. Let us visualize our\ncalculations first.\n\n\n::: {.cell layout-ncol=\"2\" hash='ANOVA_cache/html/Frogs SST and SSE Graphs_e741b186674a7c7bd63ee5a04f744d09'}\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Frogs SST and SSE Graphs-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Frogs SST and SSE Graphs-2.png){width=2100}\n:::\n:::\n\n\nHere is the SST:\n\n\n::: {.cell hash='ANOVA_cache/html/SST Total Sum of Squares_0204efa9cb508bb4ace7a3378d6eded9'}\n\n````{.cell-code}\n```{{r}}\n#| label: SST Total Sum of Squares\n#| results: hold\n# Calculate overall sum squares SST\n\n\nfrogs_overall <- frogs_long %>% \n  summarise(mean_time = mean(Time), \n            # Overall mean across all readings\n            # The Black Line\n            \n            SST = sum((Time - mean_time)^2),\n            n = n())\nfrogs_overall\n\nSST <- frogs_overall$SST\nSST\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mean_time\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SST\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"21.16667\",\"2\":\"1096.333\",\"3\":\"60\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1096.333\n```\n:::\n:::\n\n\nAnd here is the SSE:\n\n\n::: {.cell hash='ANOVA_cache/html/SSE Within Group Sum of Squares_a5c0f489d805d85c4728e5b5c53e26f9'}\n\n````{.cell-code}\n```{{r}}\n#| label: SSE Within Group Sum of Squares\n#| results: hold\n\n# Calculate sums of square errors *within* each group\n# with respect to individual group means\n\nfrogs_within_groups <- frogs_long %>% \n  group_by(TempFac) %>% \n   summarise(mean_time = mean(Time),\n            variance_time = var(Time),\n            group_error_squares = sum((Time - mean_time)^2),\n            n = n())\nfrogs_within_groups\n\nfrogs_SSE <- frogs_within_groups %>% \n  summarise(SSE = sum(group_error_squares))\n\nSSE <- frogs_SSE$SSE\nSSE\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"mean_time\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"variance_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"group_error_squares\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"26.3\",\"3\":\"1.273684\",\"4\":\"24.2\",\"5\":\"20\"},{\"1\":\"18\",\"2\":\"21.0\",\"3\":\"1.263158\",\"4\":\"24.0\",\"5\":\"20\"},{\"1\":\"25\",\"2\":\"16.2\",\"3\":\"1.431579\",\"4\":\"27.2\",\"5\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 75.4\n```\n:::\n:::\n\n\nOK, we have $SST$ and $SSE$, so let's get $SSA$:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-13_c31fcc6903bfdd80cfeb4df958a9c100'}\n\n````{.cell-code}\n```{{r}}\n#| results: hold\nSST\nSSE\nSSA <- SST - SSE\nSSA\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1096.333\n[1] 75.4\n[1] 1020.933\n```\n:::\n:::\n\n\nWe have $SST = 1096$, $SSE = 75.4$ and therefore $SSA = 1020.9$.\n\nIn order to calculate the F-Statistic, we need to compute the variances,\nusing these sum of squares. We obtain variances by dividing by their\n*Degrees of Freedom*:\n\n$$\nF_{stat} = \\frac{SSA / df_{SSA}}{SSE / df_{SSE}}\n$$\n\nwhere $df_{SSA}$ and $df_{SSE}$ are respectively the degrees of freedom\nin SSA and SSE.\n\nLet us calculate these [Degrees of\nFreedom]{style=\"background-color: yellow;\"}.\n\nWith $k = 3$ levels in the factor `TempFac`, and $n = 20$ points per\nlevel, $SST$ clearly has degree of freedom $kn-1$, since it uses all\nobservations but loses one degree to calculate the global mean. (If each\nlevel did not have the same number of points $n$, we simply take all\nobservations less one as the degrees of freedom for $SST$).\n\n$SSE$ has $k*(n-1)$ as degrees of freedom, since each of the $k$ groups\nthere are $n$ observations and each group loses one degree to calculate\nits own group mean.\n\nAnd therefore $SSA$, being their difference, has $k-1$ degrees of\nfreedom.\n\nWe can still calculate these in R, for the sake of method and clarity:\n\n\n::: {.cell hash='ANOVA_cache/html/Degrees of Freedom_73c1e66e4be00d568c60653278fbf4b7'}\n\n````{.cell-code}\n```{{r}}\n#| label: Degrees of Freedom\n\n# Error Sum of Squares SSE\ndf_SSE <- frogs_long %>%\n  \n  # Takes into account \"unbalanced\" situations\n  group_by(TempFac) %>%\n  summarise(per_group_df_SSE = n() - 1) %>%\n  summarise(df_SSE = sum(per_group_df_SSE)) %>% as.numeric()\n\n\n## Overall Sum of Squares SST\ndf_SST <- frogs_long %>%\n  summarise(df_SST = n() - 1) %>% as.integer()\n\n\n# Treatment Sum of Squares SSA\nk <- length(unique(frogs_long$TempFac))\ndf_SSA <- k - 1\n```\n````\n:::\n\n\nThe degrees of freedom for the quantities are:\n\n\n::: {.cell layout-ncol=\"2\" hash='ANOVA_cache/html/unnamed-chunk-15_01144120cbb9faf14712b2fec7142772'}\n\n````{.cell-code}\n```{{r}}\n#| results: hold\n#| layout-ncol: 2\ndf_SST\ndf_SSE\ndf_SSA\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 59\n[1] 57\n[1] 2\n```\n:::\n:::\n\n\nNow we are ready to compute the F-statistic: dividing each\nsum-of-squares byt its degrees of freedom gives us *variances* which we\nwill compare, using the *F-statistic* as a ratio:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-16_6af2bc50b2f4871835fd3440612fb5af'}\n\n````{.cell-code}\n```{{r}}\n#| results: hold\n# Finally F_Stat!\n# Combine the sum-square_error for each level of the factor\n# Weighted by degrees of freedom **per level**\n# Which are of course equal here ;-D\n\nMSE <- frogs_within_groups %>% \n  summarise(mean_square_error = sum(group_error_squares/df_SSE)) %>% \n  as.numeric()\nMSE\n\nMSA <- SSA/df_SSA # This is OK\nMSA\n\nF_stat <- MSA/MSE\nF_stat\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.322807\n[1] 510.4667\n[1] 385.8966\n```\n:::\n:::\n\n\nThe `F-stat` is compared with a **critical value** of the\nF-statistic,`F_crit` which is computed using the formula for the\nf-distribution in R. As with our hypothesis tests, we set the\nsignificance level to $\\alpha = 0.95$, but here with the Bonferroni\ncorrection, and quote the two relevant degrees of freedom as parameters\nto `qf()` which computes the critical F value as a **quartile**:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-17_2ef716236bee4e87c6fe51036124dc4a'}\n\n````{.cell-code}\n```{{r}}\n#| results: hold\nF_crit <-  \n  qf(p = (1 - 0.05/3),  # Significance level is 5% + Bonferroni Correction\n          df1 = df_SSA, # Numerator degrees of freedom \n          df2 = df_SSE  # Denominator degrees of freedom\n     ) \nF_crit\nF_stat\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.403048\n[1] 385.8966\n```\n:::\n:::\n\n\nThe `F_crit` value can also be seen in a plot[^4],[^5]:\n\n\n::: {.cell layout=\"[[45,45,10]]\" hash='ANOVA_cache/html/unnamed-chunk-18_731f417d455429a1d641d619951ae787'}\n\n````{.cell-code}\n```{{r}}\n#| layout: [[45,45,10]]\n\ngf_dist(dist = \"f\",\n        params = list(df1 = df_SSA, df2=df_SSE),\n        linewidth  = 1,\n        xlim = c(0.002, 400), title = \"F distribution for Frog ANOVA\") %>% \n  gf_vline(xintercept = F_crit, linetype = \"dotted\", \n           colour = \"red\") %>% \n  gf_vline(xintercept = F_stat, linetype = \"dashed\", \n           color = \"dodgerblue\") %>% \n  gf_text( 0.25 ~ 360, label = \"F_stat\", colour = \"dodgerblue\") %>% \n  gf_text( 0.25 ~ 20, label = \"F_crit\", colour = \"red\")  %>%\n  gf_theme(my_theme())\n\n\nmosaic::xpf(q = F_crit, \n            df1 = df_SSA, df2 = df_SSE,\n            log.p = FALSE,lower.tail = TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9833333\n```\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-18-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-18-2.png){width=2100}\n:::\n:::\n\n\nAny value of F more than the `F_crit` occurs with smaller probability\nthan $0.05/3$. Our F_stat is much higher than `F_crit`, by orders of\nmagnitude! And so we can say with confidence that Temperature has a\nsignificant effect on spawn Time.\n\nAnd that is how ANOVA computes!\n:::\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Checking ANOVA Assumptions\n\nANOVA makes 3 fundamental assumptions:\n\na.  Data (and errors) are normally distributed.\nb.  Variances are equal.\nc.  Observations are independent.\n\nWe can check these using checks and graphs.\n\n### {{< iconify ic twotone-rule >}} Checks for Normality\n\nThe `shapiro.wilk` test tests if a vector of numeric data is normally\ndistributed and rejects the hypothesis of normality when the\n[p-value](https://variation.com/wp-content/distribution_analyzer_help/hs132.htm)\nis less than or equal to 0.05. \n\n\n::: {.cell hash='ANOVA_cache/html/Check for Normality_08a2e9c3fa7867993ff02f75ec3c5e5c'}\n\n````{.cell-code}\n```{{r}}\n#| label: Check for Normality\nshapiro.test(x = frogs_long$Time)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  frogs_long$Time\nW = 0.92752, p-value = 0.001561\n```\n:::\n:::\n\n\nThe p-value is very low and we cannot reject the (alternative)\nhypothesis that the overall data is **not** normal. How about normality\nat each level of the factor?\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-20_471b6df381d74d7c23139990ef0c26b8'}\n\n````{.cell-code}\n```{{r}}\nfrogs_grouped <- frogs_long %>% \n  group_by(TempFac) %>% \n  nest(.key = \"list\") # naming the nested column \"list\"\n\n# Checking if we can purrr\nfrogs_grouped %>% \n  pluck(\"list\", 1) %>% \n  select(Time) %>% \n  as_vector() %>% \n  shapiro.test(.)\n\n# OK now we are set for group-wise Shapiro-Wilk testing with purrr:\n\nfrogs_grouped %>% \n  mutate(shaptest = \n           purrr::map(.x = list, # Column name is \"list\"\n                      .f = \\(.x) select(.data = .x, \n                                        Time) %>% \n                                 as_vector() %>% \n                                 shapiro.test(.)),\n         \n         params = map(.x = shaptest,\n                      .f = \\(.x) broom::tidy(.x))) %>% \n  \n  select(TempFac, params) %>% \n  unnest(cols = params)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  .\nW = 0.88954, p-value = 0.02638\n```\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"statistic\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"13\",\"2\":\"0.8895426\",\"3\":\"0.02637682\",\"4\":\"Shapiro-Wilk normality test\"},{\"1\":\"18\",\"2\":\"0.9254425\",\"3\":\"0.12614802\",\"4\":\"Shapiro-Wilk normality test\"},{\"1\":\"25\",\"2\":\"0.8978947\",\"3\":\"0.03766278\",\"4\":\"Shapiro-Wilk normality test\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe `shapiro.wilk` test makes a NULL Hypothesis that the data **are**\nnormally distributed and estimates the probability that this could have\nhappened by chance. Except for `TempFac = 18` the p-values are less than\n0.05 and we can reject the NULL hypothesis that each of these is\nnormally distributed. Perhaps this is a sign that we need more than 20\nsamples per factor level. Let there be more frogs !!!\n\nWe can also check the residuals post-model:\n\n\n::: {.cell .column-screen-inset-right layout-ncol=\"3\" hash='ANOVA_cache/html/unnamed-chunk-21_459cc4e16a5c5136c90ba831c4aed0b5'}\n\n````{.cell-code}\n```{{r}}\n#| layout-ncol: 3\n#| column: screen-inset-right\nfrogs_anova$residuals %>% \n  as_tibble() %>% \n  gf_dhistogram(~ value,data = .) %>% \n  gf_fitdistr() %>%\n  gf_theme(my_theme())\n\n\nfrogs_anova$residuals %>%\n  as_tibble() %>% \n  gf_qq(~ value, data = .) %>% \n  gf_qqstep() %>% \n  gf_qqline() %>%\n  gf_theme(my_theme())\n\n\nshapiro.test(frogs_anova$residuals)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  frogs_anova$residuals\nW = 0.94814, p-value = 0.01275\n```\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-21-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-21-2.png){width=2100}\n:::\n:::\n\n\nUnsurprisingly, the residuals are also not normally distributed either.\n\n### {{< iconify ic twotone-rule >}} Check for Similar Variance\n\nResponse data with different variances at different levels of an\n*explanatory* variable are said to exhibit **heteroscedasticity**. This\nviolates one of the assumptions of ANOVA.\n\nTo check if the `Time` readings are similar in `variance` across levels\nof `TempFac`, we can use the [Levene\nTest]{style=\"background-color: yellow;\"}, or since our per-group\nobservations are not normally distributed, a non-parametric rank-based\n[Fligner-Killeen Test]{style=\"background-color: yellow;\"}. The NULL\nhypothesis is that the data **are** with similar variances. The tests\nassess how probable this is with the given data assuming this NULL\nhypothesis:\n\n\n::: {.cell .column-body-outset-right layout-ncol=\"2\" hash='ANOVA_cache/html/unnamed-chunk-22_de9178f913b9f4f6d9ab1a82ec492d6a'}\n\n````{.cell-code}\n```{{r}}\n#| layout-ncol: 2\n#| column: body-outset-right\n#| results: hold\nfrogs_long %>% \n  group_by(TempFac) %>% \n  summarise(variance = var(Time))\n\n# Not too different...OK on with the test\nfligner.test(Time ~ TempFac, data = frogs_long)\n\n\nDescTools::LeveneTest(Time ~ TempFac, data = frogs_long)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"variance\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"1.273684\"},{\"1\":\"18\",\"2\":\"1.263158\"},{\"1\":\"25\",\"2\":\"1.431579\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tFligner-Killeen test of homogeneity of variances\n\ndata:  Time by TempFac\nFligner-Killeen:med chi-squared = 0.53898, df = 2, p-value = 0.7638\n```\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2\",\"2\":\"0.3931034\",\"3\":\"0.6767746\",\"_rn_\":\"group\"},{\"1\":\"57\",\"2\":\"NA\",\"3\":\"NA\",\"_rn_\":\"\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIt seems that there is no cause for concern here; the data do not have\nsignificantly different variances.\n\n### {{< iconify ic twotone-rule >}} Independent Observations\n\nThis is an experiment *design* concern; the way the data is gathered\nmust be specified such that data for each level of the factors ( factor\ncombinations if there are more than one) should be independent.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Effect Size\n\nThe simplest way to find the actual `effect sizes` detected by an ANOVA\ntest is to use (paradoxically) the `summary.lm()` command:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-23_8d33f02bf4d805dee5bd0fd1755bb6d0'}\n\n````{.cell-code}\n```{{r}}\ntidy_anova <- \n  frogs_anova %>% \n  summary.lm() %>% \n  broom::tidy()\ntidy_anova\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"26.3\",\"3\":\"0.2571777\",\"4\":\"102.26394\",\"5\":\"2.781059e-66\"},{\"1\":\"TempFac18\",\"2\":\"-5.3\",\"3\":\"0.3637041\",\"4\":\"-14.57228\",\"5\":\"7.081214e-21\"},{\"1\":\"TempFac25\",\"2\":\"-10.1\",\"3\":\"0.3637041\",\"4\":\"-27.76982\",\"5\":\"8.187867e-35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIt may take a bit of effort to understand this. First the `TempFac` is\narranged in order of levels, and the `mean` at the $TempFac = 13$ is\ntitled `Intercept`. That is $26.3$. The other two means for levels $18$\nand $25$ are stated as **differences** from this intercept, $-5.3$ and\n$-10.1$ respectively. The `p.value` for all these effect sizes is well\nbelow the desired confidence level of $0.05$.\n\n::: callout-note\n### Standard Errors\n\nObserve that the `std.error` for the intercept is $0.257$ while that for\n`TempFac18` and `TempFac25` is $0.257 \\times \\sqrt2 = 0.363$ since the\nlatter are **differences** in means, while the former is a **single\nmean**. The Variance of a difference is the sum of the individual\nvariances, which are equal here.\n:::\n\nWe can easily plot bar-chart with error bars for the effect size:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-24_419b8146407366665e183bb15874f5bc'}\n\n````{.cell-code}\n```{{r}}\ntidy_anova %>% \n  mutate(hi = estimate + std.error,\n         lo = estimate - std.error) %>% \n  gf_hline(data = ., yintercept = 0, \n           colour =\"grey\", \n           linewidth = 2) %>% \n  gf_col(estimate ~ term, \n         fill = \"grey\", \n         color = \"black\",\n         width = 0.15) %>% \n  gf_errorbar(hi + lo ~ term,\n              color = \"blue\",\n              width = 0.2) %>% \n  gf_point(estimate ~ term,\n           color = \"red\", \n           size = 3.5) %>% \n  gf_refine(scale_x_discrete(\"Temp Values\", \n                             labels = c(\"13°C\", \"18°C\", \"25°C\")))  %>%\n  gf_theme(my_theme())\n```\n````\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-24-1.png){width=2100}\n:::\n:::\n\n\nIf we want an \"absolute value\" plot for effect size, it needs just a\nlittle bit of work:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-25_74b48af27e9403946e59113c8005bf73'}\n\n````{.cell-code}\n```{{r}}\n# Merging group averages with `std.error`\nfrogs_long %>% \n  group_by(TempFac) %>% \n  summarise(mean = mean(Time)) %>% \n  cbind(std.error = tidy_anova$std.error) %>% \n  mutate(hi = mean + std.error,\n         lo = mean - std.error) %>% \n  gf_hline(data = ., yintercept = 0, \n           colour =\"grey\", \n           linewidth = 2) %>% \n  gf_col(mean ~ TempFac, \n         fill = \"grey\", \n         color = \"black\", width = 0.15) %>% \n  gf_errorbar(hi + lo ~ TempFac,\n                color = \"blue\",\n                width =0.2) %>% \n  gf_point(mean ~ TempFac, \n           color = \"red\", \n           size = 3.5) %>% \n  gf_refine(scale_x_discrete(\"Temp Values\", \n                             labels = c(\"13°C\", \"18°C\", \"25°C\"))) %>%\n  gf_theme(my_theme())\n```\n````\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-25-1.png){width=2100}\n:::\n:::\n\n\nIn both graphs, note the difference in the error-bar heights.\n\n### Using other packages\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### Using ggstatsplot\n\nThere is a very neat package called `ggstatsplot`[^6] that allows us to\nplot very comprehensive statistical graphs. Let us quickly do this:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-26_bcc1e799998dd1db5c5cf6178a831ff9'}\n\n````{.cell-code}\n```{{r}}\n#| message: false\nlibrary(ggstatsplot)\nfrogs_long %>%\n  ggstatsplot::ggbetweenstats(x = TempFac, y = Time,\n                              title = \"ANOVA : Frogs Spawn Time vs Temperature Setting\")\n```\n````\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/unnamed-chunk-26-1.png){width=2100}\n:::\n:::\n\n\n### Using supernova\n\nWe can also obtain crisp-looking anova tables from the new `supernova`\npackage [^7], which is based on the methods discussed in Judd et\nal.\\@sec--references\n\n\n::: {.cell layout-nrow=\"2\" hash='ANOVA_cache/html/unnamed-chunk-27_c36e3af9518d04a25435107730e4361f'}\n\n````{.cell-code}\n```{{r}}\n#| layout-nrow: 2\nlibrary(supernova)\nsupernova::supernova(frogs_anova)\nsupernova::pairwise(frogs_anova)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n Analysis of Variance Table (Type III SS)\n Model: Time ~ TempFac\n\n                               SS df      MS       F   PRE     p\n ----- --------------- | -------- -- ------- ------- ----- -----\n Model (error reduced) | 1020.933  2 510.467 385.897 .9312 .0000\n Error (from model)    |   75.400 57   1.323                    \n ----- --------------- | -------- -- ------- ------- ----- -----\n Total (empty model)   | 1096.333 59  18.582                    \n\n\n  group_1 group_2    diff pooled_se       q    df   lower  upper p_adj\n  <chr>   <chr>     <dbl>     <dbl>   <dbl> <int>   <dbl>  <dbl> <dbl>\n1 18      13       -5.300     0.257 -20.608    57  -6.175 -4.425 .0000\n2 25      13      -10.100     0.257 -39.272    57 -10.975 -9.225 .0000\n3 25      18       -4.800     0.257 -18.664    57  -5.675 -3.925 .0000\n```\n:::\n:::\n\n\nThe `supernova` table clearly shows the reduction the Sum of Squares as\nwe go from a NULL (empty) model to a full ANOVA model.\n:::\n\n## {{< iconify flat-color-icons workflow >}} Workflow: ANOVA using Permutation Tests\n\nWe wish to establish the significance of the effect size due to each of\nthe levels in `TempFac`. From the normality tests conducted earlier we\nsee that except at one level of `TempFac`, the times are are not\nnormally distributed. Hence we opt for a Permutation Test to check for\nsignificance of effect.\n\nAs remarked in Ernst[^8], the non-parametric permutation test can be\nboth *exact* and also **intuitively easier** for students to grasp.\nPermutations are easily executed in R, using packages such as\n`mosaic`[^9].\n\nWe proceed with a Permutation Test for `TempFac`. We shuffle the levels\n(13, 18, 25) randomly between the Times and repeat the ANOVA test each\ntime and calculate the F-statistic. The Null distribution is the\ndistribution of the F-statistic over the many permutations and the\np-value is given by the proportion of times the F-statistic equals or\nexceeds that observed.\n\nWe will use `mosaic` first, and also try with `infer`.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### Using mosaic\n\n`mosaic` offers an easy and intuitive way of doing a repeated\npermutation test, using the `do()` command. We will `shuffle` the\n`TempFac` factor to jumble up the `Time` observations, 4999 times. Each\ntime we shuffle, we compute the F_statistic and record it. We then plot\nthe 4999 F-statistics and compare that with the real-world observation\nof `F-stat`.\n\n\n::: {.cell hash='ANOVA_cache/html/permutation test for ANOVA with mosaic_a088ed6c3762cac3e450115d01cecbc5'}\n\n````{.cell-code}\n```{{r}}\n#| label: permutation test for ANOVA with mosaic\nobs_F_stat <- \n  frogs_anova %>% \n  broom::tidy() %>% \n  select(statistic)\nobserved_mosaic <- obs_F_stat$statistic[1]\nobserved_mosaic\n\nnull_dist_mosaic <- do(4999) * aov(Time ~ shuffle(TempFac), \n                                    data = frogs_long)\nnull_dist_mosaic %>% head()\n\nnull_dist_mosaic %>% drop_na() %>% \n  select(F) %>% \n  gf_histogram(data = ., ~ F, \n               fill = ~ F >= observed_mosaic,\n               title = \"Null Distribution of ANOVA F-statistic\",\n               xlab = \"Simulated F values (using Permutation)\",\n               ylab = \"Count\") %>% \n  gf_vline(xintercept = observed_mosaic) %>%\n  gf_text(750 ~ observed_mosaic - 325, label = \"Observed F\") %>%\n  gf_refine(scale_x_continuous(trans = \"log10\"),\n            annotation_logticks(),\n            scale_fill_discrete(name = \"Simulated F > Observed F ?\")) %>%\n  gf_theme(my_theme())\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 385.8966\n```\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"SS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"MS\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pval\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".row\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"1.033333\",\"4\":\"0.5166667\",\"5\":\"0.02688761\",\"6\":\"0.9734830\",\"7\":\"1\",\"8\":\"1\",\"_rn_\":\"shuffle(TempFac)...1\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1095.300000\",\"4\":\"19.2157895\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"1\",\"_rn_\":\"Residuals...2\"},{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"31.033333\",\"4\":\"15.5166667\",\"5\":\"0.83023561\",\"6\":\"0.4411490\",\"7\":\"1\",\"8\":\"2\",\"_rn_\":\"shuffle(TempFac)...3\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1065.300000\",\"4\":\"18.6894737\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"2\",\"_rn_\":\"Residuals...4\"},{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"22.633333\",\"4\":\"11.3166667\",\"5\":\"0.60077303\",\"6\":\"0.5518227\",\"7\":\"1\",\"8\":\"3\",\"_rn_\":\"shuffle(TempFac)...5\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1073.700000\",\"4\":\"18.8368421\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"3\",\"_rn_\":\"Residuals...6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/permutation test for ANOVA with mosaic-1.png){width=2100}\n:::\n:::\n\n\nThe Null distribution of the `F_statistic` under permutation shows it\nnever crosses the real-world observed value, testifying as to the\nstrength of the effect of `TempFac` on hatching `Time`. And the\n`p-value` is:\n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-29_ac78cdd4a0d76ec18f4f6557551627a5'}\n\n````{.cell-code}\n```{{r}}\np_value <- mean(null_dist_mosaic$F >= observed_mosaic, na.rm = TRUE)\np_value\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n### Using infer\n\nWe calculate the observed F-stat with `infer`, which also has a very\ndirect, if verbose, syntax for doing permutation tests:\n\n\n::: {.cell hash='ANOVA_cache/html/ANOVA F-statistic with infer_3332d69b02f66363319e4c3858d5131c'}\n\n````{.cell-code}\n```{{r}}\n#| label: ANOVA F-statistic with infer\n\nobserved_infer <- \n  frogs_long %>% \n  specify(Time ~ TempFac) %>% \n  hypothesise(null = \"independence\") %>% \n  calculate(stat = \"F\")\nobserved_infer\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"stat\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"385.8966\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWe see that the observed F-Statistic is of course $385.8966$ as before.\nNow we use `infer` to generate a NULL distribution using permutation of\nthe factor `TempFac`:\n\n\n::: {.cell hash='ANOVA_cache/html/Permutation using infer_837a3df412bd5500077cc77e2236a537'}\n\n````{.cell-code}\n```{{r}}\n#| label: Permutation using infer\n\nnull_dist_infer <- frogs_long %>% \n  specify(Time ~ TempFac) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 4999 , type = \"permute\") %>% \n  calculate(stat = \"F\")\n\nhead(null_dist_infer)\n\nnull_dist_infer %>% \n  visualise(method = \"simulation\") +\n  shade_p_value(obs_stat = observed_infer$stat, direction = \"right\") + \n  scale_x_continuous(trans = \"log10\", expand = c(0,0)) +\n  coord_cartesian(xlim = c(0.2,500), clip = \"off\") + \n  annotation_logticks(outside = FALSE) + \n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"replicate\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"stat\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"0.36153704\"},{\"1\":\"2\",\"2\":\"0.56287787\"},{\"1\":\"3\",\"2\":\"0.11571572\"},{\"1\":\"4\",\"2\":\"0.77253138\"},{\"1\":\"5\",\"2\":\"0.08430153\"},{\"1\":\"6\",\"2\":\"1.78545120\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output-display}\n![](ANOVA_files/figure-html/Permutation using infer-1.png){width=2100}\n:::\n:::\n\n\nAs seen, the `infer` based permutation test also shows that the\npermutationally generated F-statistics are nowhere near that which was\nobserved. The effect of `TempFac` is very strong.\n:::\n\n## {{< iconify fluent-mdl2 decision-solid >}} Conclusions\n\nWe have discussed ANOVA as a means of modelling the effects of a\nCategorical variable on a Continuous (Quant) variable. ANOVA can be\ncarried out using the standard formula `aov` when assumptions on\ndistributions, variances, and independence are met. Permutation ANOVA\ntests can be carried out when these assumptions do not quite hold.\n\n## {{< iconify ooui references-rtl >}} References {#sec--references}\n::: {#refs style=\"font-size: 60%;\"}\n\\\nThe ANOVA tutorial at [Our Coding\n    Club](https://ourcodingclub.github.io/tutorials/anova/)\\\nAntoine Soetewey. *How to: one-way ANOVA by hand*.     <https://statsandr.com/blog/how-to-one-way-anova-by-hand/>\\\nANOVA in R - Stats and R <https://statsandr.com/blog/anova-in-r/>\\\nMichael Crawley, The R Book,second edition, 2013. Chapter 11.\\\nDavid C Howell, [Permutation Tests for Factorial ANOVA\n    Designs](https://www.uvm.edu/~statdhtx/StatPages/Permutation%20Anova/PermTestsAnova.html)\\\nMarti Anderson, [Permutation tests for univariate or multivariate\n    analysis of variance and regression](https://www.academia.edu/50056272/Permutation_tests_for_univariate_or_multivariate_analysis_of_variance_and_regression?auto=download)\\\nJudd, Charles M., Gary H. McClelland, and Carey S. Ryan. 2017.\n    \"Introduction to Data Analysis.\" In, 1--9. Routledge.\n    https://doi.org/10.4324/9781315744131-1.\\\n    Patil, I. (2021). *Visualizations with statistical details: The\n    'ggstatsplot' approach.* Journal of Open Source Software, 6(61),\n    3167, doi:10.21105/joss.03167\n    \n\n\n::: {.cell hash='ANOVA_cache/html/unnamed-chunk-32_c5f0a3e130453682d3a54f803e52a6e5'}\n::: {.cell-output-display}\nPackage       Version   Citation     \n------------  --------  -------------\nDescTools     0.99.50   @DescTools   \nggprism       1.0.4     @ggprism     \nggstatsplot   0.12.1    @ggstatsplot \nggtext        0.1.2     @ggtext      \nsupernova     2.5.8     @supernova\n:::\n:::\n\n:::\n\n\n\n[^1]: The ANOVA tutorial at [Our Coding\n    Club](https://ourcodingclub.github.io/tutorials/anova/).\n\n[^2]: https://www.openintro.org/go/?id=anova-supplement&referrer=/book/ahss/index.php\n\n[^3]: Spinoza: Ethics Geometrically Demonstrated: [spinoza1665.pdf\n    (earlymoderntexts.com)](https://www.earlymoderntexts.com/assets/pdfs/spinoza1665.pdf)\n\n[^4]: Pruim R, Kaplan DT, Horton NJ (2017). \"The mosaic Package: Helping\n    Students to 'Think with Data' Using R.\" The R Journal, 9(1),\n    77--102.\n    https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n\n[^5]: `mosaic::xpf()` gives both a graph and the probabilities.\n\n[^6]: ggplot2 Based Plots with Statistical Details • ggstatsplot\n    <https://indrajeetpatil.github.io/ggstatsplot/>\n\n[^7]: <https://github.com/UCLATALL/supernova>\n\n[^8]: Ernst, Michael D. 2004. \"Permutation Methods: A Basis for Exact\n    Inference.\" Statistical Science 19 (4): 676--85.\n    doi:10.1214/088342304000000396.\n\n[^9]: Pruim R, Kaplan DT, Horton NJ (2017). \"The mosaic Package: Helping\n    Students to 'Think with Data' Using R.\" The R Journal, 9(1),\n    77--102.\n    https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}