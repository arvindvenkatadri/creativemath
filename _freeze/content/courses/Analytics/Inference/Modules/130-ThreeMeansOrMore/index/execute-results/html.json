{
  "hash": "5cbe8bd14e8d5ad6cdca9f8b7246816b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Comparing Multiple Means with ANOVA\"\nabstract: \"ANOVA to investigate how frogspawn hatching time varies with temperature.\"\ndate: 28/Mar/2023\ndate-modified: \"2024-09-07\"\norder: 130\nimage: preview.jpg\nbibliography: \n  - references.bib\n  - grateful-refs.bib\ncitation: true\n#suppress-bibliography: true\n---\n\n\n\n\n## {{< iconify noto-v1 package >}} Setting up R Packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(tidy = TRUE)\nlibrary(tidyverse) # Tidy data processing\nlibrary(ggformula) # Formula based plots\nlibrary(mosaic) # Data inspection and Statistical Inference\nlibrary(broom) # Tidy outputs from Statistical Analyses\nlibrary(infer) # Statistical Inference\nlibrary(patchwork) # Arranging Plots\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction\n\nSuppose we have three sales strategies on our website, to sell a certain product, say men's shirts. We have observations of customer website interactions over several months. How do we know which strategy makes people buy the fastest ?\n\nIf there is a University course that is offered in parallel in three different classrooms, is there a difference between the average marks obtained by students in each of the classrooms?\n\nIn each case we have a set of observations in each category: Interaction Time vs Sales Strategy in the first example, and Student Marks vs Classroom in the second. We can take *mean* scores in each category and decide to compare them. How do we make the comparisons? One way would be to compare them pair-wise. But with this rapidly becomes intractable and also dangerous: with increasing number of `groups`, the number of mean-comparisons becomes very large $N\\choose 2$ and with each comparison the possibility of some difference showing up, *just by chance*, increases! And we end up making the wrong inference and perhaps the wrong decision.\n\nThe trick is of course to make comparisons **all at once** and ANOVA is the technique that allows us to do just that. In this tutorial, we will compare the Hatching Time of frog spawn[^1], at three different lab temperatures.\n\n[^1]: The ANOVA tutorial at [Our Coding Club](https://ourcodingclub.github.io/tutorials/anova/).\n\nIn this tutorial, our research question is:\n\n::: callout-note\n## Research Question\n\nHow does frogspawn hatching time vary with different temperature settings?\n:::\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Read the Data\n\nDownload the data by clicking the button below.\n\n\n\n\n{{< downloadthis data/frogs.csv dname=\"frogs\" label=\"Download the frogs data\" icon=\"database-fill-down\" type=\"info\" >}}\n\n\n\n\n\n\n::: callout-important\n## Data Folder\n\nSave the CSV in a subfolder titled \"data\" inside your R work folder.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrogs_orig <- read_csv(\"data/frogs.csv\")\nfrogs_orig\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Frogspawn sample id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature13\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature18\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Temperature25\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"24\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"2\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"3\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"18\"},{\"1\":\"4\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"5\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"6\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"14\"},{\"1\":\"7\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"8\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"9\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"10\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"11\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"12\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"13\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"14\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"15\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"16\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"17\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"18\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"19\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"20\",\"2\":\"NA\",\"3\":\"19\",\"4\":\"NA\"},{\"1\":\"21\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"22\",\"2\":\"25\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"23\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"24\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"25\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"26\",\"2\":\"NA\",\"3\":\"23\",\"4\":\"NA\"},{\"1\":\"27\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"28\",\"2\":\"28\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"29\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"30\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"31\",\"2\":\"24\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"32\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"33\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"18\"},{\"1\":\"34\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"35\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"36\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"14\"},{\"1\":\"37\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"38\",\"2\":\"NA\",\"3\":\"22\",\"4\":\"NA\"},{\"1\":\"39\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"40\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"41\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"42\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"15\"},{\"1\":\"43\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"44\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"45\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"46\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"47\",\"2\":\"NA\",\"3\":\"20\",\"4\":\"NA\"},{\"1\":\"48\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"16\"},{\"1\":\"49\",\"2\":\"27\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"50\",\"2\":\"NA\",\"3\":\"19\",\"4\":\"NA\"},{\"1\":\"51\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"52\",\"2\":\"25\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"53\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"54\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"55\",\"2\":\"26\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"56\",\"2\":\"NA\",\"3\":\"23\",\"4\":\"NA\"},{\"1\":\"57\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"},{\"1\":\"58\",\"2\":\"28\",\"3\":\"NA\",\"4\":\"NA\"},{\"1\":\"59\",\"2\":\"NA\",\"3\":\"21\",\"4\":\"NA\"},{\"1\":\"60\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nOur response variable is the hatching `Time`. Our explanatory variable is a *factor*, `Temperature`, with 3 levels: 13°C, 18°C and 25°C. Different samples of spawn were subject to each of these temperatures respectively.\n\n## {{< iconify material-symbols pivot-table-chart >}} Workflow: Clean the Data\n\nThe data is badly organized, with a separate column for each Temperature, and a common column for Sample ID. There are NA entries since not all samples of spawn can be subject to all temperatures. (E.g. Sample ID #1 was maintained at 13°C).\n\nWe will first stack up the `Temperature` columns into a single column, separate that into pieces and then retain just the number part (13, 18, 25), getting rid of the *word* `Temperature` from the column titles. Then the remaining **numerical** column with temperatures (13, 18, 25) will be converted into a factor.\n\nWe will use `pivot_longer()`and `separate_wider_regex()` to achieve this. \\[See this animation for pivot_longer(): <https://haswal.github.io/pivot/> \\]\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nfrogs_orig %>%\n  pivot_longer(\n    .,\n    cols = starts_with(\"Temperature\"),\n    cols_vary = \"fastest\",\n    # new in pivot_longer\n    names_to = \"Temp\",\n    values_to = \"Time\"\n  ) %>%\n  drop_na() %>%\n  ##\n  separate_wider_regex(\n    cols = Temp,\n    # knock off the unnecessary \"Temperature\" word\n    # Just keep the digits thereafter\n    patterns = c(\"Temperature\",\n      TempFac = \"\\\\d+\"\n    ),\n    cols_remove = TRUE\n  ) %>%\n  # Convert Temp into TempFac, a 3-level factor\n  mutate(TempFac = factor(\n    x = TempFac,\n    levels = c(13, 18, 25),\n    labels = c(\"13\", \"18\", \"25\")\n  )) %>%\n  rename(\"Id\" = `Frogspawn sample id`) -> frogs_long\n\nfrogs_long\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"TempFac\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"13\",\"3\":\"24\"},{\"1\":\"2\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"3\",\"2\":\"25\",\"3\":\"18\"},{\"1\":\"4\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"5\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"6\",\"2\":\"25\",\"3\":\"14\"},{\"1\":\"7\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"8\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"9\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"10\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"11\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"12\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"13\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"14\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"15\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"16\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"17\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"18\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"19\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"20\",\"2\":\"18\",\"3\":\"19\"},{\"1\":\"21\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"22\",\"2\":\"13\",\"3\":\"25\"},{\"1\":\"23\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"24\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"25\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"26\",\"2\":\"18\",\"3\":\"23\"},{\"1\":\"27\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"28\",\"2\":\"13\",\"3\":\"28\"},{\"1\":\"29\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"30\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"31\",\"2\":\"13\",\"3\":\"24\"},{\"1\":\"32\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"33\",\"2\":\"25\",\"3\":\"18\"},{\"1\":\"34\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"35\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"36\",\"2\":\"25\",\"3\":\"14\"},{\"1\":\"37\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"38\",\"2\":\"18\",\"3\":\"22\"},{\"1\":\"39\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"40\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"41\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"42\",\"2\":\"25\",\"3\":\"15\"},{\"1\":\"43\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"44\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"45\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"46\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"47\",\"2\":\"18\",\"3\":\"20\"},{\"1\":\"48\",\"2\":\"25\",\"3\":\"16\"},{\"1\":\"49\",\"2\":\"13\",\"3\":\"27\"},{\"1\":\"50\",\"2\":\"18\",\"3\":\"19\"},{\"1\":\"51\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"52\",\"2\":\"13\",\"3\":\"25\"},{\"1\":\"53\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"54\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"55\",\"2\":\"13\",\"3\":\"26\"},{\"1\":\"56\",\"2\":\"18\",\"3\":\"23\"},{\"1\":\"57\",\"2\":\"25\",\"3\":\"17\"},{\"1\":\"58\",\"2\":\"13\",\"3\":\"28\"},{\"1\":\"59\",\"2\":\"18\",\"3\":\"21\"},{\"1\":\"60\",\"2\":\"25\",\"3\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nfrogs_long %>% count(TempFac)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"20\"},{\"1\":\"18\",\"2\":\"20\"},{\"1\":\"25\",\"2\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nSo we have cleaned up our data and have `20` samples for Hatching `Time` per `TempFac` setting.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: EDA\n\nLet us plot some histograms and boxplots of Hatching Time:\n\n\n\n\n::: {.cell .column-screen-inset-right layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n##\ngf_histogram(\n  data = frogs_long,\n  ~Time,\n  fill = ~TempFac,\n  stat = \"count\",\n  alpha = 0.5\n) %>%\n  gf_vline(xintercept = ~ mean(Time)) %>%\n  gf_labs(x = \"Hatching Time\", y = \"Count\") %>%\n  gf_text(7 ~ (mean(Time) + 2),\n    label = \"Overall Mean\"\n  ) %>%\n  gf_refine(guides(fill = guide_legend(title = \"Temperature level (°C)\")))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=2100}\n:::\n\n```{.r .cell-code}\n###\ngf_boxplot(\n  data = frogs_long,\n  Time ~ TempFac,\n  fill = ~TempFac,\n  alpha = 0.5\n) %>%\n  gf_vline(xintercept = ~ mean(Time)) %>%\n  gf_labs(\n    x = \"Temperature\", y = \"Hatching Time\",\n    caption = \"X-axis is reversed\"\n  ) %>%\n  gf_refine(\n    scale_x_discrete(limits = rev),\n    guides(fill = guide_legend(title = \"Temperature level (°C)\"))\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=2100}\n:::\n:::\n\n\n\n\n\nThe histograms look well separated and the box plots also show very little overlap. So we can reasonably hypothesize that Temperature has a significant effect on Hatching Time.\n\nOne more slightly esoteric plot: Jitter/Scatter with a new *categorical x-axis* offered by the `ggprism` package:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n##\nlibrary(ggprism)\ngf_jitter(\n  frogs_long,\n  Time ~ TempFac,\n  color = ~TempFac,\n  xlab = \"Temperature as Factor\",\n  ylab = \"Hatching Time\",\n  caption = \"Using `ggprism` package\"\n) %>%\n  gf_theme(theme_prism(base_family = theme_get()$font$family)) %>%\n  gf_refine(\n    theme(legend.position = \"none\"),\n    scale_x_discrete(guide = \"prism_bracket\")\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/using-ggprism-1.png){width=2100}\n:::\n:::\n\n\n\n\nLet's go ahead with our ANOVA test.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: ANOVA\n\nWe will first execute the ANOVA test with code and evaluate the results. Then we will do an intuitive walk through of the process and finally, hand-calculate entire analysis for clear understanding.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### ANOVA Test with Code\n\nR offers a very simple command to execute an ANOVA test: Note the familiar `formula` of stating the variables:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrogs_anova <- aov(Time ~ TempFac, data = frogs_long)\nfrogs_anova %>% broom::tidy()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sumsq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"meansq\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"TempFac\",\"2\":\"2\",\"3\":\"1020.933\",\"4\":\"510.466667\",\"5\":\"385.8966\",\"6\":\"7.357304e-34\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"75.400\",\"4\":\"1.322807\",\"5\":\"NA\",\"6\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nsummary.lm(frogs_anova) %>% broom::tidy()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"26.3\",\"3\":\"0.2571777\",\"4\":\"102.26394\",\"5\":\"2.781059e-66\"},{\"1\":\"TempFac18\",\"2\":\"-5.3\",\"3\":\"0.3637041\",\"4\":\"-14.57228\",\"5\":\"7.081214e-21\"},{\"1\":\"TempFac25\",\"2\":\"-10.1\",\"3\":\"0.3637041\",\"4\":\"-27.76982\",\"5\":\"8.187867e-35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nThe effect of Temperature on Hatching time is significant, with a p-value of $<2e-16$. The F-statistic for the ANOVA test is given by $385.9$, which is very high, and the `r.squared` value ( to be discussed later) is also large, $0.931$. Clearly `Temperature` has a very significant effect on the hatching `Time`.\n\nTo find which specific value of `TempFac` has the most effect will require *pairwise comparison* of the group means, using a standard `t-test`. The confidence level for such repeated comparisons will need what is called ***Bonferroni correction***[^2] to prevent us from detecting a significant (pair-wise) difference simply by chance. To do this we take $\\alpha = 0.05$, the confidence level used and divide it by $K$, the number of pair-wise comparisons we intend to make. This new value is used to decide on the significance of the estimated parameter. So the pairwise comparisons in our current data will have to use $\\alpha/3 = 0.0166$ as the confidence level.\n\n### ANOVA Intuitive {#sec-anova-intuitive}\n\nAll that is very well, but what is happening under the hood of the `aov()` command?\n\nConsider a data set with a single Quant and a single Qual variable. The Qual variable has two levels, the Quant data has 20 observations per Qual level.\n\n\n\n\n::: {.cell layout-nrow=\"1\"}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"index\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"qual\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"quant\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"A\",\"3\":\"2.7419169\"},{\"1\":\"2\",\"2\":\"A\",\"3\":\"-1.1293963\"},{\"1\":\"3\",\"2\":\"A\",\"3\":\"0.7262568\"},{\"1\":\"4\",\"2\":\"A\",\"3\":\"1.2657252\"},{\"1\":\"5\",\"2\":\"A\",\"3\":\"0.8085366\"},{\"1\":\"6\",\"2\":\"A\",\"3\":\"-0.2122490\"},{\"1\":\"7\",\"2\":\"A\",\"3\":\"3.0230440\"},{\"1\":\"8\",\"2\":\"A\",\"3\":\"-0.1893181\"},{\"1\":\"9\",\"2\":\"A\",\"3\":\"4.0368474\"},{\"1\":\"10\",\"2\":\"A\",\"3\":\"-0.1254282\"},{\"1\":\"11\",\"2\":\"A\",\"3\":\"2.6097393\"},{\"1\":\"12\",\"2\":\"A\",\"3\":\"4.5732908\"},{\"1\":\"13\",\"2\":\"A\",\"3\":\"-2.7777214\"},{\"1\":\"14\",\"2\":\"A\",\"3\":\"-0.5575775\"},{\"1\":\"15\",\"2\":\"A\",\"3\":\"-0.2666427\"},{\"1\":\"16\",\"2\":\"A\",\"3\":\"1.2719008\"},{\"1\":\"17\",\"2\":\"A\",\"3\":\"-0.5685058\"},{\"1\":\"18\",\"2\":\"A\",\"3\":\"-5.3129108\"},{\"1\":\"19\",\"2\":\"A\",\"3\":\"-4.8809339\"},{\"1\":\"20\",\"2\":\"A\",\"3\":\"2.6402267\"},{\"1\":\"21\",\"2\":\"B\",\"3\":\"9.3867228\"},{\"1\":\"22\",\"2\":\"B\",\"3\":\"6.4373831\"},{\"1\":\"23\",\"2\":\"B\",\"3\":\"9.6561653\"},{\"1\":\"24\",\"2\":\"B\",\"3\":\"12.4293494\"},{\"1\":\"25\",\"2\":\"B\",\"3\":\"13.7903869\"},{\"1\":\"26\",\"2\":\"B\",\"3\":\"9.1390617\"},{\"1\":\"27\",\"2\":\"B\",\"3\":\"9.4854612\"},{\"1\":\"28\",\"2\":\"B\",\"3\":\"6.4736738\"},{\"1\":\"29\",\"2\":\"B\",\"3\":\"10.9201947\"},{\"1\":\"30\",\"2\":\"B\",\"3\":\"8.7200102\"},{\"1\":\"31\",\"2\":\"B\",\"3\":\"10.9109002\"},{\"1\":\"32\",\"2\":\"B\",\"3\":\"11.4096747\"},{\"1\":\"33\",\"2\":\"B\",\"3\":\"12.0702070\"},{\"1\":\"34\",\"2\":\"B\",\"3\":\"8.7821472\"},{\"1\":\"35\",\"2\":\"B\",\"3\":\"11.0099102\"},{\"1\":\"36\",\"2\":\"B\",\"3\":\"6.5659826\"},{\"1\":\"37\",\"2\":\"B\",\"3\":\"8.4310820\"},{\"1\":\"38\",\"2\":\"B\",\"3\":\"8.2981848\"},{\"1\":\"39\",\"2\":\"B\",\"3\":\"5.1715847\"},{\"1\":\"40\",\"2\":\"B\",\"3\":\"10.0722452\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/Anova-Intuitive-1.png){width=2100}\n:::\n:::\n\n\n\n\nIn Fig A, the *horizontal* black line is the overall mean of `quant`, denoted as $\\mu_{tot}$. The vertical black lines to the points show the departures of each point from this overall mean. The sum of *squares* of these vertical black lines in Fig A is called the [**Total Sum of Squares** (SST)]{style=\"background-color: yellow;\"}.\n\n$$\nSST = \\Sigma (y - \\mu_{tot})^2\n$$ {#eq-SST}\n\n::: callout-note\nIf there are $k$ levels in `qual` and $n$ observations $y_ n$ for each level, we can also write:\n\n$$\nSST = \n\\sum_{i=1}^{kn}y_i^2 - \\frac{ \\left( \\sum_{i=1}^{kn}\ny_i \\right)^2}{kn}\n$$\n:::\n\nIn Fig B, the *horizontal* green and red lines are the means of the individual groups, respectively $\\mu_A$ and $\\mu_B$. The green and red vertical lines are the departures, or errors, of each point from *its own group-mean*. The sum of the *squares* of the green and red lines is called the [**Total Error Sum of Squares** (SSE)]{style=\"background-color: yellow;\"}.\n\n$$\nSSE = \\Sigma [(y - \\mu_i)^2 +... (y - \\mu_k)^2]\n$$ {#eq-SSE}\n\nIf the $\\mu_A$ and $\\mu_B$ are different from $\\mu_{tot}$, then what would be the relationship between $SST$ and $SSE$ ? [Clearly if the all means are identical then the $SST$ and $SSE$ are equal, since the two coloured lines would be in the same place as the black line]{style=\"background-color: yellow;\"}. It should be clear that if $\\mu_A$ and $\\mu_B$ are different from the overall mean $\\mu_{tot}$, then $SSE < SST$.\n\nSo, when we desire to detect if the two groups are different in their means, we take the difference:\n\n$$\nSSA = SST - SSE\n$$ {#eq-SSA}\n\n[$SSA$ is called the **Treatment Sum of Squares**]{style=\"background-color: yellow;\"} and is a measure the differences in means of observations at different levels of the factor.\n\n::: callout-note\n$SSA$ can also directly be re-written in a very symmetric fashion as:\n\n$$\n\\frac{\\sum_{i=1}^{k} \\left( \\sum_{j=1}^{n}y_{ij}\\right)^2 }{n} - \\frac{\\left( \\sum_{i=1}^{kn}\ny_i \\right)^2}{kn}\n$$\n\nNote that in the first term, we are calculating sums of observations within each group in the inner summation, which is like a per-group mean(without the division). The outer summation takes the sum of squares of these undivided summations and divides by $n$.\n:::\n\nComparing $SSA$ and $SSE$ now provides us with a method that helps us decide whether these means are different. $SSA$ is the leftover unexplained error using $\\mu_{tot}$ as the estimate (NULL Hypothesis). $SSE$ is the unexplained error using individual means per group (Alternative Hypothesis). The logic in comparing these two global differences and local differences is that there *must* be a significant **reduction** in unexplained error going from NULL to Alternative Hypothesis.\n\nBefore we compare, we need to scale: since each of these measures uses a different set of observations, the comparison is done after scaling each of $SSA$ and $SSE$ by the [number of observations]{.bg-washed-green} influencing them. (a sort of \"per capita\" error, an idea we saw when we defined [Standard Errors](../../Modules/20-SampProb/index.qmd#the-standard-error)). This means that we need to divide each of $SSA$ and $SSE$ by their [*degrees of freedom*]{style=\"background-color: yellow;\"}, which gives us [a ratio of **variances**, the F-statistic]{style=\"background-color: yellow;\"}:\n\n$$\nF_{stat} = \\frac{SSA / df_{SSA}}{SSE / df_{SSE}}\n$$\n\nwhere $df_{SSA}$ and $df_{SSE}$ are respectively the degrees of freedom in $SSA$ and $SSE$. [And so we are in effect deciding if means are significantly different by analyzing (a ratio of) variances!]{style=\"background-color: yellow;\"} Hence *AN-alysis O-f VA-riance*, **ANOVA**.\n\nIn order to find which of the means is significantly different from others, we need to make a pair-wise comparison of the means, applying the Bonferroni correction as stated before. This means we divide the critical `p.value` we expect by the number of comparisons we make between levels of the Qual variable. More on this shortly.\n\n### ANOVA Manually Demonstrated[^3](Apologies to Spinoza)\n\nNow that we understand what `aov()` is doing, let us hand-calculate the numbers for our `frogs` dataset and check. Let us visualize our calculations first.\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![](index_files/figure-html/Frogs-SST-and-SSE-Graphs-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/Frogs-SST-and-SSE-Graphs-2.png){width=2100}\n:::\n:::\n\n\n\n\nHere is the SST:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate overall sum squares SST\n\n\nfrogs_overall <- frogs_long %>%\n  summarise(\n    mean_time = mean(Time),\n    # Overall mean across all readings\n    # The Black Line\n\n    SST = sum((Time - mean_time)^2),\n    n = n()\n  )\nfrogs_overall\n\nSST <- frogs_overall$SST\nSST\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mean_time\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SST\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"21.16667\",\"2\":\"1096.333\",\"3\":\"60\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1096.333\n```\n\n\n:::\n:::\n\n\n\n\nAnd here is the SSE:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate sums of square errors *within* each group\n# with respect to individual group means\n\nfrogs_within_groups <- frogs_long %>%\n  group_by(TempFac) %>%\n  summarise(\n    mean_time = mean(Time),\n    variance_time = var(Time),\n    group_error_squares = sum((Time - mean_time)^2),\n    n = n()\n  )\nfrogs_within_groups\n\nfrogs_SSE <- frogs_within_groups %>%\n  summarise(SSE = sum(group_error_squares))\n\nSSE <- frogs_SSE$SSE\nSSE\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"mean_time\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"variance_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"group_error_squares\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"26.3\",\"3\":\"1.273684\",\"4\":\"24.2\",\"5\":\"20\"},{\"1\":\"18\",\"2\":\"21.0\",\"3\":\"1.263158\",\"4\":\"24.0\",\"5\":\"20\"},{\"1\":\"25\",\"2\":\"16.2\",\"3\":\"1.431579\",\"4\":\"27.2\",\"5\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 75.4\n```\n\n\n:::\n:::\n\n\n\n\nOK, we have $SST$ and $SSE$, so let's get $SSA$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSST\nSSE\nSSA <- SST - SSE\nSSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1096.333\n[1] 75.4\n[1] 1020.933\n```\n\n\n:::\n:::\n\n\n\n\nWe have $SST = 1096$, $SSE = 75.4$ and therefore $SSA = 1020.9$.\n\nIn order to calculate the F-Statistic, we need to compute the variances, using these sum of squares. We obtain variances by dividing by their *Degrees of Freedom*:\n\n$$\nF_{stat} = \\frac{SSA / df_{SSA}}{SSE / df_{SSE}}\n$$\n\nwhere $df_{SSA}$ and $df_{SSE}$ are respectively the degrees of freedom in SSA and SSE.\n\nLet us calculate these [Degrees of Freedom]{style=\"background-color: yellow;\"}.\n\nWith $k = 3$ levels in the factor `TempFac`, and $n = 20$ points per level, $SST$ clearly has degree of freedom $kn-1$, since it uses all observations but loses one degree to calculate the global mean. (If each level did not have the same number of points $n$, we simply take all observations less one as the degrees of freedom for $SST$).\n\n$SSE$ has $k*(n-1)$ as degrees of freedom, since each of the $k$ groups there are $n$ observations and each group loses one degree to calculate its own group mean.\n\nAnd therefore $SSA$, being their difference, has $k-1$ degrees of freedom.\n\nWe can still calculate these in R, for the sake of method and clarity:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Error Sum of Squares SSE\ndf_SSE <- frogs_long %>%\n  # Takes into account \"unbalanced\" situations\n  group_by(TempFac) %>%\n  summarise(per_group_df_SSE = n() - 1) %>%\n  summarise(df_SSE = sum(per_group_df_SSE)) %>%\n  as.numeric()\n\n\n## Overall Sum of Squares SST\ndf_SST <- frogs_long %>%\n  summarise(df_SST = n() - 1) %>%\n  as.integer()\n\n\n# Treatment Sum of Squares SSA\nk <- length(unique(frogs_long$TempFac))\ndf_SSA <- k - 1\n```\n:::\n\n\n\n\nThe degrees of freedom for the quantities are:\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\ndf_SST\ndf_SSE\ndf_SSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 59\n[1] 57\n[1] 2\n```\n\n\n:::\n:::\n\n\n\n\nNow we are ready to compute the F-statistic: dividing each sum-of-squares byt its degrees of freedom gives us *variances* which we will compare, using the *F-statistic* as a ratio:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Finally F_Stat!\n# Combine the sum-square_error for each level of the factor\n# Weighted by degrees of freedom **per level**\n# Which are of course equal here ;-D\n\nMSE <- frogs_within_groups %>%\n  summarise(mean_square_error = sum(group_error_squares / df_SSE)) %>%\n  as.numeric()\nMSE\n\nMSA <- SSA / df_SSA # This is OK\nMSA\n\nF_stat <- MSA / MSE\nF_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.322807\n[1] 510.4667\n[1] 385.8966\n```\n\n\n:::\n:::\n\n\n\n\nThe `F-stat` is compared with a **critical value** of the F-statistic,`F_crit` which is computed using the formula for the f-distribution in R. As with our hypothesis tests, we set the significance level to $\\alpha = 0.95$, but here with the Bonferroni correction, and quote the two relevant degrees of freedom as parameters to `qf()` which computes the critical F value as a **quartile**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nF_crit <-\n  qf(\n    p = (1 - 0.05 / 3), # Significance level is 5% + Bonferroni Correction\n    df1 = df_SSA, # Numerator degrees of freedom\n    df2 = df_SSE # Denominator degrees of freedom\n  )\nF_crit\nF_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.403048\n[1] 385.8966\n```\n\n\n:::\n:::\n\n\n\n\nThe `F_crit` value can also be seen in a plot[^4],[^5]:\n\n\n\n\n::: {.cell layout=\"[[45,45,10]]\"}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\ngf_dist(\n  dist = \"f\",\n  params = list(df1 = df_SSA, df2 = df_SSE),\n  # linewidth  = 1,\n  # xlim = c(0, 400),\n  # title = \"F distribution for Frog ANOVA\"\n) %>%\n  gf_vline(\n    xintercept = F_crit, linetype = \"dotted\",\n    colour = \"red\", title = \"F distribution for Frog ANOVA\"\n  ) %>%\n  gf_vline(\n    xintercept = F_stat, linetype = \"dashed\",\n    color = \"dodgerblue\"\n  ) %>%\n  gf_text(0.25 ~ 360, label = \"F_stat\", colour = \"dodgerblue\") %>%\n  gf_text(0.25 ~ 20, label = \"F_crit\", colour = \"red\") %>%\n  gf_theme(theme = theme_classic())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nmosaic::xpf(\n  q = F_crit,\n  df1 = df_SSA, df2 = df_SSE,\n  log.p = FALSE, lower.tail = TRUE\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-2.png){width=2100}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9833333\n```\n\n\n:::\n:::\n\n\n\n\nAny value of F more than the `F_crit` occurs with smaller probability than $0.05/3$. Our F_stat is much higher than `F_crit`, by orders of magnitude! And so we can say with confidence that Temperature has a significant effect on spawn Time.\n\nAnd that is how ANOVA computes!\n:::\n\n[^2]: https://www.openintro.org/go/?id=anova-supplement&referrer=/book/ahss/index.php\n\n[^3]: Spinoza: Ethics Geometrically Demonstrated: [spinoza1665.pdf (earlymoderntexts.com)](https://www.earlymoderntexts.com/assets/pdfs/spinoza1665.pdf)\n\n[^4]: Pruim R, Kaplan DT, Horton NJ (2017). \"The mosaic Package: Helping Students to 'Think with Data' Using R.\" The R Journal, 9(1), 77--102. https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n\n[^5]: `mosaic::xpf()` gives both a graph and the probabilities.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Checking ANOVA Assumptions\n\nANOVA makes 3 fundamental assumptions:\n\na.  Data (and errors) are normally distributed.\nb.  Variances are equal.\nc.  Observations are independent.\n\nWe can check these using checks and graphs.\n\n### {{< iconify ic twotone-rule >}} Checks for Normality\n\nThe `shapiro.wilk` test tests if a vector of numeric data is normally distributed and rejects the hypothesis of normality when the [p-value](https://variation.com/wp-content/distribution_analyzer_help/hs132.htm) is less than or equal to 0.05. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(x = frogs_long$Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  frogs_long$Time\nW = 0.92752, p-value = 0.001561\n```\n\n\n:::\n:::\n\n\n\n\nThe p-value is very low and we cannot reject the (alternative) hypothesis that the overall data is **not** normal. How about normality at each level of the factor?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrogs_grouped <- frogs_long %>%\n  group_by(TempFac) %>%\n  nest(.key = \"list\") # naming the nested column \"list\"\nfrogs_grouped\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"list\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"<tibble[,2]>\"},{\"1\":\"18\",\"2\":\"<tibble[,2]>\"},{\"1\":\"25\",\"2\":\"<tibble[,2]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Checking if we can purrr\nfrogs_grouped %>%\n  purrr::pluck(\"list\", 1) %>%\n  dplyr::select(Time) %>%\n  as_vector() %>%\n  shapiro.test(.)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  .\nW = 0.88954, p-value = 0.02638\n```\n\n\n:::\n\n```{.r .cell-code}\n# OK now we are set for group-wise Shapiro-Wilk testing with purrr:\n\nfrogs_grouped %>%\n  mutate(\n    shaptest =\n      purrr::map(\n        .x = list, # Column name is \"list\"\n        .f = \\(.x) select(\n          .data = .x,\n          Time\n        ) %>%\n          as_vector() %>%\n          shapiro.test(.)\n      ),\n    params =\n      purrr::map(\n        .x = shaptest,\n        .f = \\(.x) broom::tidy(.x)\n      )\n  ) %>%\n  select(TempFac, params) %>%\n  unnest(cols = params)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"statistic\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"13\",\"2\":\"0.8895426\",\"3\":\"0.02637682\",\"4\":\"Shapiro-Wilk normality test\"},{\"1\":\"18\",\"2\":\"0.9254425\",\"3\":\"0.12614802\",\"4\":\"Shapiro-Wilk normality test\"},{\"1\":\"25\",\"2\":\"0.8978947\",\"3\":\"0.03766278\",\"4\":\"Shapiro-Wilk normality test\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n#### Using `dplyr::group_modify()\nfrogs_long %>%\n  group_by(TempFac) %>%\n  group_modify(~ .x %>%\n    select(Time) %>%\n    as_vector() %>%\n    shapiro.test() %>%\n    broom::tidy())\n```\n:::\n\n\n\n\nThe `shapiro.wilk` test makes a NULL Hypothesis that the data **are** normally distributed and estimates the probability that this could have happened by chance. Except for `TempFac = 18` the p-values are less than 0.05 and we can reject the NULL hypothesis that each of these is normally distributed. Perhaps this is a sign that we need more than 20 samples per factor level. Let there be more frogs !!!\n\nWe can also check the residuals post-model:\n\n\n\n\n::: {.cell .column-screen-inset-right layout-ncol=\"3\"}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\nfrogs_anova$residuals %>%\n  as_tibble() %>%\n  gf_dhistogram(~value, data = .) %>%\n  gf_fitdistr()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nfrogs_anova$residuals %>%\n  as_tibble() %>%\n  gf_qq(~value, data = .) %>%\n  gf_qqstep() %>%\n  gf_qqline()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-2.png){width=2100}\n:::\n\n```{.r .cell-code}\nshapiro.test(frogs_anova$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  frogs_anova$residuals\nW = 0.94814, p-value = 0.01275\n```\n\n\n:::\n:::\n\n\n\n\nUnsurprisingly, the residuals are also not normally distributed either.\n\n### {{< iconify ic twotone-rule >}} Check for Similar Variance\n\nResponse data with different variances at different levels of an *explanatory* variable are said to exhibit **heteroscedasticity**. This violates one of the assumptions of ANOVA.\n\nTo check if the `Time` readings are similar in `variance` across levels of `TempFac`, we can use the [Levene Test]{style=\"background-color: yellow;\"}, or since our per-group observations are not normally distributed, a non-parametric rank-based [Fligner-Killeen Test]{style=\"background-color: yellow;\"}. The NULL hypothesis is that the data **are** with similar variances. The tests assess how probable this is with the given data assuming this NULL hypothesis:\n\n\n\n\n::: {.cell .column-body-outset-right layout-ncol=\"2\"}\n\n```{.r .cell-code}\nfrogs_long %>%\n  group_by(TempFac) %>%\n  summarise(variance = var(Time))\n\n# Not too different...OK on with the test\nfligner.test(Time ~ TempFac, data = frogs_long)\n\n\nDescTools::LeveneTest(Time ~ TempFac, data = frogs_long)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"TempFac\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"variance\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"13\",\"2\":\"1.273684\"},{\"1\":\"18\",\"2\":\"1.263158\"},{\"1\":\"25\",\"2\":\"1.431579\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tFligner-Killeen test of homogeneity of variances\n\ndata:  Time by TempFac\nFligner-Killeen:med chi-squared = 0.53898, df = 2, p-value = 0.7638\n```\n\n\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2\",\"2\":\"0.3931034\",\"3\":\"0.6767746\",\"_rn_\":\"group\"},{\"1\":\"57\",\"2\":\"NA\",\"3\":\"NA\",\"_rn_\":\"\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nIt seems that there is no cause for concern here; the data do not have significantly different variances.\n\n### {{< iconify ic twotone-rule >}} Independent Observations\n\nThis is an experiment *design* concern; the way the data is gathered must be specified such that data for each level of the factors ( factor combinations if there are more than one) should be independent.\n\n## {{< iconify flat-color-icons workflow >}} Workflow: Effect Size\n\nThe simplest way to find the actual `effect sizes` detected by an ANOVA test is to use (paradoxically) the `summary.lm()` command:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_anova <-\n  frogs_anova %>%\n  summary.lm() %>%\n  broom::tidy()\ntidy_anova\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"std.error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"26.3\",\"3\":\"0.2571777\",\"4\":\"102.26394\",\"5\":\"2.781059e-66\"},{\"1\":\"TempFac18\",\"2\":\"-5.3\",\"3\":\"0.3637041\",\"4\":\"-14.57228\",\"5\":\"7.081214e-21\"},{\"1\":\"TempFac25\",\"2\":\"-10.1\",\"3\":\"0.3637041\",\"4\":\"-27.76982\",\"5\":\"8.187867e-35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nIt may take a bit of effort to understand this. First the `TempFac` is arranged in order of levels, and the `mean` at the $TempFac = 13$ is titled `Intercept`. That is $26.3$. The other two means for levels $18$ and $25$ are stated as **differences** from this intercept, $-5.3$ and $-10.1$ respectively. The `p.value` for all these effect sizes is well below the desired confidence level of $0.05$.\n\n::: callout-note\n### Standard Errors\n\nObserve that the `std.error` for the intercept is $0.257$ while that for `TempFac18` and `TempFac25` is $0.257 \\times \\sqrt2 = 0.363$ since the latter are **differences** in means, while the former is a **single mean**. The Variance of a difference is the sum of the individual variances, which are equal here.\n:::\n\nWe can easily plot bar-chart with error bars for the effect size:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\ntidy_anova %>%\n  mutate(\n    hi = estimate + std.error,\n    lo = estimate - std.error\n  ) %>%\n  gf_hline(\n    data = ., yintercept = 0,\n    colour = \"grey\",\n    linewidth = 2\n  ) %>%\n  gf_col(estimate ~ term,\n    fill = \"grey\",\n    color = \"black\",\n    width = 0.15\n  ) %>%\n  gf_errorbar(hi + lo ~ term,\n    color = \"blue\",\n    width = 0.2\n  ) %>%\n  gf_point(estimate ~ term,\n    color = \"red\",\n    size = 3.5\n  ) %>%\n  gf_refine(scale_x_discrete(\"Temp Values\",\n    labels = c(\"13°C\", \"18°C\", \"25°C\")\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=2100}\n:::\n:::\n\n\n\n\nIf we want an \"absolute value\" plot for effect size, it needs just a little bit of work:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Merging group averages with `std.error`\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\nfrogs_long %>%\n  group_by(TempFac) %>%\n  summarise(mean = mean(Time)) %>%\n  cbind(std.error = tidy_anova$std.error) %>%\n  mutate(\n    hi = mean + std.error,\n    lo = mean - std.error\n  ) %>%\n  gf_hline(\n    data = ., yintercept = 0,\n    colour = \"grey\",\n    linewidth = 2\n  ) %>%\n  gf_col(mean ~ TempFac,\n    fill = \"grey\",\n    color = \"black\", width = 0.15\n  ) %>%\n  gf_errorbar(hi + lo ~ TempFac,\n    color = \"blue\",\n    width = 0.2\n  ) %>%\n  gf_point(mean ~ TempFac,\n    color = \"red\",\n    size = 3.5\n  ) %>%\n  gf_refine(scale_x_discrete(\"Temp Values\",\n    labels = c(\"13°C\", \"18°C\", \"25°C\")\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=2100}\n:::\n:::\n\n\n\n\nIn both graphs, note the difference in the error-bar heights.\n\nThe ANOVA test does not tell us that the \"treatments\" (i.e. levels of `TempFac`) are equally effective. We need to use a *multiple comparison* procedure to arrive at an answer to that question. We compute the pair-wise differences in effect-size:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrogs_anova %>% stats::TukeyHSD()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Time ~ TempFac, data = frogs_long)\n\n$TempFac\n       diff        lwr       upr p adj\n18-13  -5.3  -6.175224 -4.424776     0\n25-13 -10.1 -10.975224 -9.224776     0\n25-18  -4.8  -5.675224 -3.924776     0\n```\n\n\n:::\n:::\n\n\n\nWe see that **each** of the pairwise differences in effect-size is significant, with `p = 0` !\n\n### Using other packages\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### Using ggstatsplot\n\nThere is a very neat package called `ggstatsplot`[^6] that allows us to plot very comprehensive statistical graphs. Let us quickly do this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\nlibrary(ggstatsplot)\nfrogs_long %>%\n  ggstatsplot::ggbetweenstats(\n    x = TempFac, y = Time,\n    title = \"ANOVA : Frogs Spawn Time vs Temperature Setting\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=2100}\n:::\n:::\n\n\n\n\n### Using supernova\n\nWe can also obtain crisp-looking anova tables from the new `supernova` package [^7], which is based on the methods discussed in Judd et al. @sec-references\n\n\n\n\n::: {.cell layout-nrow=\"2\"}\n\n```{.r .cell-code}\nlibrary(supernova)\nsupernova::supernova(frogs_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Analysis of Variance Table (Type III SS)\n Model: Time ~ TempFac\n\n                               SS df      MS       F   PRE     p\n ----- --------------- | -------- -- ------- ------- ----- -----\n Model (error reduced) | 1020.933  2 510.467 385.897 .9312 .0000\n Error (from model)    |   75.400 57   1.323                    \n ----- --------------- | -------- -- ------- ------- ----- -----\n Total (empty model)   | 1096.333 59  18.582                    \n```\n\n\n:::\n\n```{.r .cell-code}\nsupernova::pairwise(frogs_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\n  group_1 group_2    diff pooled_se       q    df   lower  upper p_adj\n  <chr>   <chr>     <dbl>     <dbl>   <dbl> <int>   <dbl>  <dbl> <dbl>\n1 18      13       -5.300     0.257 -20.608    57  -6.175 -4.425 .0000\n2 25      13      -10.100     0.257 -39.272    57 -10.975 -9.225 .0000\n3 25      18       -4.800     0.257 -18.664    57  -5.675 -3.925 .0000\n```\n\n\n:::\n:::\n\n\n\n\nThe `supernova` table clearly shows the reduction the Sum of Squares as we go from a NULL (empty) model to a full ANOVA model.\n:::\n\n[^6]: ggplot2 Based Plots with Statistical Details • ggstatsplot <https://indrajeetpatil.github.io/ggstatsplot/>\n\n[^7]: <https://github.com/UCLATALL/supernova>\n\n## {{< iconify flat-color-icons workflow >}} Workflow: ANOVA using Permutation Tests\n\nWe wish to establish the significance of the effect size due to each of the levels in `TempFac`. From the normality tests conducted earlier we see that except at one level of `TempFac`, the times are are not normally distributed. Hence we opt for a Permutation Test to check for significance of effect.\n\nAs remarked in Ernst[^8], the non-parametric permutation test can be both *exact* and also **intuitively easier** for students to grasp. Permutations are easily executed in R, using packages such as `mosaic`[^9].\n\n[^8]: Ernst, Michael D. 2004. \"Permutation Methods: A Basis for Exact Inference.\" Statistical Science 19 (4): 676--85. doi:10.1214/088342304000000396.\n\n[^9]: Pruim R, Kaplan DT, Horton NJ (2017). \"The mosaic Package: Helping Students to 'Think with Data' Using R.\" The R Journal, 9(1), 77--102. https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n\nWe proceed with a Permutation Test for `TempFac`. We shuffle the levels (13, 18, 25) randomly between the Times and repeat the ANOVA test each time and calculate the F-statistic. The Null distribution is the distribution of the F-statistic over the many permutations and the p-value is given by the proportion of times the F-statistic equals or exceeds that observed.\n\nWe will use `mosaic` first, and also try with `infer`.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### Using mosaic\n\n`mosaic` offers an easy and intuitive way of doing a repeated permutation test, using the `do()` command. We will `shuffle` the `TempFac` factor to jumble up the `Time` observations, 4999 times. Each time we shuffle, we compute the F_statistic and record it. We then plot the 4999 F-statistics and compare that with the real-world observation of `F-stat`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\nobs_F_stat <-\n  frogs_anova %>%\n  broom::tidy() %>%\n  select(statistic)\nobserved_mosaic <- obs_F_stat$statistic[1]\nobserved_mosaic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 385.8966\n```\n\n\n:::\n\n```{.r .cell-code}\nnull_dist_mosaic <- do(4999) * aov(Time ~ shuffle(TempFac),\n  data = frogs_long\n)\nnull_dist_mosaic %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"SS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"MS\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pval\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".row\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"1.033333\",\"4\":\"0.5166667\",\"5\":\"0.02688761\",\"6\":\"0.9734830\",\"7\":\"1\",\"8\":\"1\",\"_rn_\":\"shuffle(TempFac)...1\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1095.300000\",\"4\":\"19.2157895\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"1\",\"_rn_\":\"Residuals...2\"},{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"31.033333\",\"4\":\"15.5166667\",\"5\":\"0.83023561\",\"6\":\"0.4411490\",\"7\":\"1\",\"8\":\"2\",\"_rn_\":\"shuffle(TempFac)...3\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1065.300000\",\"4\":\"18.6894737\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"2\",\"_rn_\":\"Residuals...4\"},{\"1\":\"shuffle(TempFac)\",\"2\":\"2\",\"3\":\"22.633333\",\"4\":\"11.3166667\",\"5\":\"0.60077303\",\"6\":\"0.5518227\",\"7\":\"1\",\"8\":\"3\",\"_rn_\":\"shuffle(TempFac)...5\"},{\"1\":\"Residuals\",\"2\":\"57\",\"3\":\"1073.700000\",\"4\":\"18.8368421\",\"5\":\"NA\",\"6\":\"NA\",\"7\":\"2\",\"8\":\"3\",\"_rn_\":\"Residuals...6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nnull_dist_mosaic %>%\n  drop_na() %>%\n  select(F) %>%\n  gf_histogram(\n    data = ., ~F,\n    fill = ~ F >= observed_mosaic,\n    title = \"Null Distribution of ANOVA F-statistic\",\n    xlab = \"Simulated F values (using Permutation)\",\n    ylab = \"Count\"\n  ) %>%\n  gf_vline(xintercept = observed_mosaic) %>%\n  gf_text(750 ~ observed_mosaic - 325, label = \"Observed F\") %>%\n  gf_refine(\n    scale_x_continuous(trans = \"log10\"),\n    annotation_logticks(),\n    scale_fill_discrete(name = \"Simulated F > Observed F ?\")\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/permutation test for ANOVA with mosaic-1.png){width=2100}\n:::\n:::\n\n\n\n\nThe Null distribution of the `F_statistic` under permutation shows it never crosses the real-world observed value, testifying as to the strength of the effect of `TempFac` on hatching `Time`. And the `p-value` is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_value <- mean(null_dist_mosaic$F >= observed_mosaic, na.rm = TRUE)\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\n### Using infer\n\nWe calculate the observed F-stat with `infer`, which also has a very direct, if verbose, syntax for doing permutation tests:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobserved_infer <-\n  frogs_long %>%\n  specify(Time ~ TempFac) %>%\n  hypothesise(null = \"independence\") %>%\n  calculate(stat = \"F\")\nobserved_infer\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"stat\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"385.8966\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nWe see that the observed F-Statistic is of course $385.8966$ as before. Now we use `infer` to generate a NULL distribution using permutation of the factor `TempFac`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist_infer <- frogs_long %>%\n  specify(Time ~ TempFac) %>%\n  hypothesise(null = \"independence\") %>%\n  generate(reps = 4999, type = \"permute\") %>%\n  calculate(stat = \"F\")\n\nhead(null_dist_infer)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"replicate\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"stat\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"0.36153704\"},{\"1\":\"2\",\"2\":\"0.56287787\"},{\"1\":\"3\",\"2\":\"0.11571572\"},{\"1\":\"4\",\"2\":\"0.77253138\"},{\"1\":\"5\",\"2\":\"0.08430153\"},{\"1\":\"6\",\"2\":\"1.78545120\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nnull_dist_infer %>%\n  visualise(method = \"simulation\") +\n  shade_p_value(obs_stat = observed_infer$stat, direction = \"right\") +\n  scale_x_continuous(trans = \"log10\", expand = c(0, 0)) +\n  coord_cartesian(xlim = c(0.2, 500), clip = \"off\") +\n  annotation_logticks(outside = FALSE) +\n  theme_custom()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Permutation using infer-1.png){width=2100}\n:::\n:::\n\n\n\n\nAs seen, the `infer` based permutation test also shows that the permutationally generated F-statistics are nowhere near that which was observed. The effect of `TempFac` is very strong.\n:::\n\n## {{< iconify fluent-mdl2 decision-solid >}} Conclusions\n\nWe have discussed ANOVA as a means of modelling the effects of a Categorical variable on a Continuous (Quant) variable. ANOVA can be carried out using the standard formula `aov` when assumptions on distributions, variances, and independence are met. Permutation ANOVA tests can be carried out when these assumptions do not quite hold.\n\n::: callout-note\n### Two-Way ANOVA\n\nWhat if we have *two* Categorical variables as predictors? We then need to perform a **Two-Way ANOVA** analysis, where we look at the predictors individually (*main effects*) and together (*interaction effects*). Here too, we need to verify if the number of observations are balanced across all combinations of factors of the two Qualitative predictors. There are three different classical approaches (Type1, Type2 and Type3 ANOVA) for testing hypotheses in ANOVA for unbalanced designs, as they are called. [@langsrud2003].\n\n:::\n\n::: callout-note\n### Informative Hypothesis Testing: Models which incorporate a priori Beliefs\n\nNote that when we specified our research question, we had no specific hypothesis about the means, *other than that they might be different*. In many situations, we may have reason to believe in the relative \"ordering\" of the means for different levels of the Categorical variable. The one-sided t-test is the simplest example (e.g., $\\mu_1 >= 0$ and $\\mu_1 >= \\mu_2$); this readily extends to the multi-parameter setting, where more than one inequality constraint can be imposed on the parameters (e.g., $\\mu_1 <= \\mu_2 <= \\mu_3$.\\\nIt *is* possible to incorporate these beliefs into the ANOVA model, using what is called as **informative hypothesis testing**, which have certain advantages compared to unconstrained models. The R package called `restriktor` has the capability to develop such models with beliefs.\n:::\n\n## {{< iconify ooui references-rtl >}} References {#sec-references}\n\n1. The ANOVA tutorial at [Our Coding Club](https://ourcodingclub.github.io/tutorials/anova/)\\\n1. Antoine Soetewey. *How to: one-way ANOVA by hand*. <https://statsandr.com/blog/how-to-one-way-anova-by-hand/>\\\n1. ANOVA in R - Stats and R <https://statsandr.com/blog/anova-in-r/>\\\n1. Michael Crawley.(2013) The R Book,second edition. Chapter 11.\\\n1. David C Howell, [Permutation Tests for Factorial ANOVA Designs](https://www.uvm.edu/~statdhtx/StatPages/Permutation%20Anova/PermTestsAnova.html)\\\n1. Marti Anderson, [Permutation tests for univariate or multivariate analysis of variance and regression](https://www.academia.edu/50056272/Permutation_tests_for_univariate_or_multivariate_analysis_of_variance_and_regression?auto=download)\\\n1. Judd, Charles M., Gary H. McClelland, and Carey S. Ryan.(2017). \"Introduction to Data Analysis.\" In, 1--9. Routledge. https://doi.org/10.4324/9781315744131-1.\\\n1. Patil, I. (2021). *Visualizations with statistical details: The 'ggstatsplot' approach.* Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\\\n1. Langsrud, Øyvind. (2003). *ANOVA for unbalanced data: Use type II instead of type III sums of squares*. Statistics and Computing. 13. 163-167. https://doi.org/10.1023/A:1023260610025. <https://www.researchgate.net/publication/220286726_ANOVA_for_unbalanced_data_Use_type_II_instead_of_type_III_sums_of_squares>\\\n1. Kim TK. (2017). *Understanding one-way ANOVA using conceptual figures*. Korean J Anesthesiol. 2017 Feb;70(1):22-26. doi: 10.4097/kjae.2017.70.1.22. Epub 2017 Jan 26. PMID: 28184262; PMCID: PMC5296382.\\\n1. *Anova – Type I/II/III SS explained*.<https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/>\n\n\n::: {#refs style=\"font-size: 60%;\"}\n###### {{< iconify lucide package-check >}} R Package Citations\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nPackage       Version   Citation     \n------------  --------  -------------\nDescTools     0.99.56   @DescTools   \nggprism       1.0.5     @ggprism     \nggstatsplot   0.12.4    @ggstatsplot \nggtext        0.1.2     @ggtext      \nrestriktor    0.5.80    @restriktor  \nsupernova     3.0.0     @supernova   \n\n\n:::\n:::\n\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}