{
  "hash": "d0f4ed6e7258fa9aae2253e0530791e6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"\\U0001F3B2 Samples, Populations, Statistics and Inference\"\ndate: 25/Nov/2022\ndate-modified: \"2024-04-19\"\norder: 20\nabstract: \"How much ~~Land~~ Data does a Man need?\"\nimage: preview.jpg\ncategories:\n- Sampling\n- Central Limit Theorem\n- Standard Error\n- Confidence Intervals\nbibliography: \n  - grateful-refs.bib\ncitation: true\nfilters: \n  - shinylive\n---\n\n\n## {{< fa folder-open >}} Slides and Tutorials\n\n|                                                                                                 |     |     |                                                                                        |\n|------------------|--------------------|------------------|------------------|\n| <a href=\"./files/sampling-tutorial.qmd\"><i class=\"fa-brands fa-r-project\"></i> R Tutorial</a>   |     |     | <a href=\"./files/data/qdd-data.zip\"> <i class=\"fa-solid fa-database\"></i> Datasets</a> |\n\n## {{< iconify noto-v1 package >}} Setting up R Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123456) # TO get repeatable graphs!\n\nlibrary(tidyverse) # Data Processing in R\nlibrary(mosaic) # Our workhorse for stats, sampling\nlibrary(skimr) # Good to Examine data\nlibrary(ggformula) # Formula interface for graphs\n\n# load the NHANES data library\nlibrary(NHANES)\n\nlibrary(cowplot) # ggplot themes and stacking of plots\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](preview.jpg){fig-align='center' fig-alt='Photo by Anirudh on unsplash' width=102}\n:::\n:::\n\n\n## {{< iconify clarity group-solid >}} What is a Population?\n\nA *population* is a collection of individuals or observations we are\ninterested in. This is also commonly denoted as a study population. We\nmathematically denote the population's size using upper-case `N`.\n\nA *population parameter* is some numerical summary about the population\nthat is unknown but you wish you knew. For example, when this quantity\nis a mean like *the mean height of all Bangaloreans*, the population\nparameter of interest is the *population mean*.\n\nA *census* is an exhaustive enumeration or counting of all N individuals\nin the population. We do this in order to compute the population\nparameter's value exactly. Of note is that as the number N of\nindividuals in our population increases, conducting a census gets more\nexpensive (in terms of time, energy, and money).\n\n::: callout-important\n## {{< iconify carbon parameter >}} Parameters\n\nPopulations *P*arameters are usually indicated by Greek Letters.\n:::\n\n## {{< iconify game-icons card-pickup >}} What is a Sample?\n\nSampling is the act of collecting a small subset from the population, \nwhich we generally do when we can't perform a **census**. We mathematically denote the sample size using lower case `n`, as opposed to upper case `N` which denotes the population's size. Typically the sample size `n` is much\nsmaller than the population size `N`. Thus sampling is a much cheaper\nalternative than performing a census.\n\nA **sample statistic**, also known as a *point estimate*, is a summary\nstatistic like a `mean` or `standard deviation` that is computed from a\nsample.\n\n::: callout-note\n## Why do we sample?\n\nBecause we cannot conduct a census ( not always ) --- and **sometimes we won't even know how big the population is** --- we take samples. And we\n*still* want to do useful work for/with the population, after\nestimating its parameters, *an act of generalizing* from sample to\npopulation. So the question is, **can we estimate useful parameters of the population, using just samples? Can point estimates serve as useful guides to population parameters?**\n\n[This act of generalizing from sample to population is at the heart of\n**statistical inference**.]{style=\"background-color: yellow;\"}\n:::\n\n::: callout-important\n## An Alliterative Mnemonic\n\nNOTE: there is an\n[*alliterative*](https://www.grammarly.com/blog/alliteration/)\n[*mnemonic*](https://www.merriam-webster.com/dictionary/mnemonic) here:\n**S**amples have **S**tatistics; **P**opulations have **P**arameters.\n:::\n\n## {{< iconify fluent-mdl2 test-parameter >}} Population Parameters and Sample Statistics\n\n|                    | Population Parameter | Sample Statistic |\n|--------------------|----------------------|------------------|\n| Mean               | $\\mu$                | $\\bar{x}$        |\n| Standard Deviation | $\\sigma$             | s                |\n| Proportion         | p                    | $\\hat{p}$        |\n| Correlation        | $\\rho$               | r                |\n| Slope (Regression) | $\\beta_1$            | $b_1$            |\n\n: Parameters and Statistics\n\n::: callout-note\n## Question\n\nQ.1. What is the mean commute time for workers in a particular city?\n\nA.1. The *parameter* is the mean commute time $\\mu$ for a *population*\ncontaining all workers who work in the city. We *estimate* it using\n$\\bar{x}$, the mean of the random sample of people who work in the city.\n:::\n\n::: callout-note\n## Question\n\nQ.2. What is the correlation between the size of dinner bills and the\nsize of tips at a restaurant?\n\nA.2. The *parameter is* $\\rho$ , the correlation between bill amount and\ntip size for a *population* of all dinner bills at that restaurant. We\nestimate it using r, the correlation from a random sample of dinner\nbills.\n:::\n\n::: callout-note\n## Question\n\nQ.3. How much difference is there in the proportion of 30 to 39-year-old\nresidents who have only a cell phone (no land line phone) compared to 50\nto 59-year-olds in the country?\n\nA.3. The *population* is all citizens of the country, and the parameter\nis $p_1 - p_2$, the difference in proportion of 30 to 39-year-old\nresidents who have only a cell phone ($p_1$) and the proportion with the\nsame property among all 50 to 59-year olds ($p_2$). We estimate it using\n($\\hat{p_1} - \\hat{p_2}$), the difference in sample proportions computed\nfrom random samples taken from each group.\n:::\n\nSample statistics vary and in the following we will estimate this\nuncertainty and decide how reliable they might be as estimates of\npopulation parameters.\n\n## {{< iconify pajamas issue-type-test-case >}} Case Study #1: Sampling the NHANES dataset\n\nWe will first execute some samples from a known dataset. We load up the\nNHANES dataset and inspect it.\n\n\n::: {.cell .column-body-outset-right layout-ncol=\"3\"}\n\n```{.r .cell-code}\ndata(\"NHANES\")\n#mosaic::inspect(NHANES)\nskimr::skim(NHANES)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |       |\n|:------------------------|:------|\n|Name                     |NHANES |\n|Number of rows           |10000  |\n|Number of columns        |76     |\n|_______________________  |       |\n|Column type frequency:   |       |\n|factor                   |31     |\n|numeric                  |45     |\n|________________________ |       |\n|Group variables          |None   |\n\n\n**Variable type: factor**\n\n|skim_variable    | n_missing| complete_rate|ordered | n_unique|top_counts                                 |\n|:----------------|---------:|-------------:|:-------|--------:|:------------------------------------------|\n|SurveyYr         |         0|          1.00|FALSE   |        2|200: 5000, 201: 5000                       |\n|Gender           |         0|          1.00|FALSE   |        2|fem: 5020, mal: 4980                       |\n|AgeDecade        |       333|          0.97|FALSE   |        8|40: 1398,  0-: 1391,  10: 1374,  20: 1356  |\n|Race1            |         0|          1.00|FALSE   |        5|Whi: 6372, Bla: 1197, Mex: 1015, Oth: 806  |\n|Race3            |      5000|          0.50|FALSE   |        6|Whi: 3135, Bla: 589, Mex: 480, His: 350    |\n|Education        |      2779|          0.72|FALSE   |        5|Som: 2267, Col: 2098, Hig: 1517, 9 -: 888  |\n|MaritalStatus    |      2769|          0.72|FALSE   |        6|Mar: 3945, Nev: 1380, Div: 707, Liv: 560   |\n|HHIncome         |       811|          0.92|FALSE   |       12|mor: 2220, 750: 1084, 250: 958, 350: 863   |\n|HomeOwn          |        63|          0.99|FALSE   |        3|Own: 6425, Ren: 3287, Oth: 225             |\n|Work             |      2229|          0.78|FALSE   |        3|Wor: 4613, Not: 2847, Loo: 311             |\n|BMICatUnder20yrs |      8726|          0.13|FALSE   |        4|Nor: 805, Obe: 221, Ove: 193, Und: 55      |\n|BMI_WHO          |       397|          0.96|FALSE   |        4|18.: 2911, 30.: 2751, 25.: 2664, 12.: 1277 |\n|Diabetes         |       142|          0.99|FALSE   |        2|No: 9098, Yes: 760                         |\n|HealthGen        |      2461|          0.75|FALSE   |        5|Goo: 2956, Vgo: 2508, Fai: 1010, Exc: 878  |\n|LittleInterest   |      3333|          0.67|FALSE   |        3|Non: 5103, Sev: 1130, Mos: 434             |\n|Depressed        |      3327|          0.67|FALSE   |        3|Non: 5246, Sev: 1009, Mos: 418             |\n|SleepTrouble     |      2228|          0.78|FALSE   |        2|No: 5799, Yes: 1973                        |\n|PhysActive       |      1674|          0.83|FALSE   |        2|Yes: 4649, No: 3677                        |\n|TVHrsDay         |      5141|          0.49|FALSE   |        7|2_h: 1275, 1_h: 884, 3_h: 836, 0_t: 638    |\n|CompHrsDay       |      5137|          0.49|FALSE   |        7|0_t: 1409, 0_h: 1073, 1_h: 1030, 2_h: 589  |\n|Alcohol12PlusYr  |      3420|          0.66|FALSE   |        2|Yes: 5212, No: 1368                        |\n|SmokeNow         |      6789|          0.32|FALSE   |        2|No: 1745, Yes: 1466                        |\n|Smoke100         |      2765|          0.72|FALSE   |        2|No: 4024, Yes: 3211                        |\n|Smoke100n        |      2765|          0.72|FALSE   |        2|Non: 4024, Smo: 3211                       |\n|Marijuana        |      5059|          0.49|FALSE   |        2|Yes: 2892, No: 2049                        |\n|RegularMarij     |      5059|          0.49|FALSE   |        2|No: 3575, Yes: 1366                        |\n|HardDrugs        |      4235|          0.58|FALSE   |        2|No: 4700, Yes: 1065                        |\n|SexEver          |      4233|          0.58|FALSE   |        2|Yes: 5544, No: 223                         |\n|SameSex          |      4232|          0.58|FALSE   |        2|No: 5353, Yes: 415                         |\n|SexOrientation   |      5158|          0.48|FALSE   |        3|Het: 4638, Bis: 119, Hom: 85               |\n|PregnantNow      |      8304|          0.17|FALSE   |        3|No: 1573, Yes: 72, Unk: 51                 |\n\n\n**Variable type: numeric**\n\n|skim_variable   | n_missing| complete_rate|     mean|       sd|       p0|      p25|      p50|      p75|      p100|hist  |\n|:---------------|---------:|-------------:|--------:|--------:|--------:|--------:|--------:|--------:|---------:|:-----|\n|ID              |         0|          1.00| 61944.64|  5871.17| 51624.00| 56904.50| 62159.50| 67039.00|  71915.00|▇▇▇▇▇ |\n|Age             |         0|          1.00|    36.74|    22.40|     0.00|    17.00|    36.00|    54.00|     80.00|▇▇▇▆▅ |\n|AgeMonths       |      5038|          0.50|   420.12|   259.04|     0.00|   199.00|   418.00|   624.00|    959.00|▇▇▇▆▃ |\n|HHIncomeMid     |       811|          0.92| 57206.17| 33020.28|  2500.00| 30000.00| 50000.00| 87500.00| 100000.00|▃▆▃▁▇ |\n|Poverty         |       726|          0.93|     2.80|     1.68|     0.00|     1.24|     2.70|     4.71|      5.00|▅▅▃▃▇ |\n|HomeRooms       |        69|          0.99|     6.25|     2.28|     1.00|     5.00|     6.00|     8.00|     13.00|▂▆▇▂▁ |\n|Weight          |        78|          0.99|    70.98|    29.13|     2.80|    56.10|    72.70|    88.90|    230.70|▂▇▂▁▁ |\n|Length          |      9457|          0.05|    85.02|    13.71|    47.10|    75.70|    87.00|    96.10|    112.20|▁▃▆▇▃ |\n|HeadCirc        |      9912|          0.01|    41.18|     2.31|    34.20|    39.58|    41.45|    42.92|     45.40|▁▂▇▇▅ |\n|Height          |       353|          0.96|   161.88|    20.19|    83.60|   156.80|   166.00|   174.50|    200.40|▁▁▁▇▂ |\n|BMI             |       366|          0.96|    26.66|     7.38|    12.88|    21.58|    25.98|    30.89|     81.25|▇▆▁▁▁ |\n|Pulse           |      1437|          0.86|    73.56|    12.16|    40.00|    64.00|    72.00|    82.00|    136.00|▂▇▃▁▁ |\n|BPSysAve        |      1449|          0.86|   118.15|    17.25|    76.00|   106.00|   116.00|   127.00|    226.00|▃▇▂▁▁ |\n|BPDiaAve        |      1449|          0.86|    67.48|    14.35|     0.00|    61.00|    69.00|    76.00|    116.00|▁▁▇▇▁ |\n|BPSys1          |      1763|          0.82|   119.09|    17.50|    72.00|   106.00|   116.00|   128.00|    232.00|▂▇▂▁▁ |\n|BPDia1          |      1763|          0.82|    68.28|    13.78|     0.00|    62.00|    70.00|    76.00|    118.00|▁▁▇▆▁ |\n|BPSys2          |      1647|          0.84|   118.48|    17.49|    76.00|   106.00|   116.00|   128.00|    226.00|▃▇▂▁▁ |\n|BPDia2          |      1647|          0.84|    67.66|    14.42|     0.00|    60.00|    68.00|    76.00|    118.00|▁▁▇▆▁ |\n|BPSys3          |      1635|          0.84|   117.93|    17.18|    76.00|   106.00|   116.00|   126.00|    226.00|▃▇▂▁▁ |\n|BPDia3          |      1635|          0.84|    67.30|    14.96|     0.00|    60.00|    68.00|    76.00|    116.00|▁▁▇▇▁ |\n|Testosterone    |      5874|          0.41|   197.90|   226.50|     0.25|    17.70|    43.82|   362.41|   1795.60|▇▂▁▁▁ |\n|DirectChol      |      1526|          0.85|     1.36|     0.40|     0.39|     1.09|     1.29|     1.58|      4.03|▅▇▂▁▁ |\n|TotChol         |      1526|          0.85|     4.88|     1.08|     1.53|     4.11|     4.78|     5.53|     13.65|▂▇▁▁▁ |\n|UrineVol1       |       987|          0.90|   118.52|    90.34|     0.00|    50.00|    94.00|   164.00|    510.00|▇▅▂▁▁ |\n|UrineFlow1      |      1603|          0.84|     0.98|     0.95|     0.00|     0.40|     0.70|     1.22|     17.17|▇▁▁▁▁ |\n|UrineVol2       |      8522|          0.15|   119.68|    90.16|     0.00|    52.00|    95.00|   171.75|    409.00|▇▆▃▂▁ |\n|UrineFlow2      |      8524|          0.15|     1.15|     1.07|     0.00|     0.48|     0.76|     1.51|     13.69|▇▁▁▁▁ |\n|DiabetesAge     |      9371|          0.06|    48.42|    15.68|     1.00|    40.00|    50.00|    58.00|     80.00|▁▂▆▇▂ |\n|DaysPhysHlthBad |      2468|          0.75|     3.33|     7.40|     0.00|     0.00|     0.00|     3.00|     30.00|▇▁▁▁▁ |\n|DaysMentHlthBad |      2466|          0.75|     4.13|     7.83|     0.00|     0.00|     0.00|     4.00|     30.00|▇▁▁▁▁ |\n|nPregnancies    |      7396|          0.26|     3.03|     1.80|     1.00|     2.00|     3.00|     4.00|     32.00|▇▁▁▁▁ |\n|nBabies         |      7584|          0.24|     2.46|     1.32|     0.00|     2.00|     2.00|     3.00|     12.00|▇▅▁▁▁ |\n|Age1stBaby      |      8116|          0.19|    22.65|     4.77|    14.00|    19.00|    22.00|    26.00|     39.00|▆▇▅▂▁ |\n|SleepHrsNight   |      2245|          0.78|     6.93|     1.35|     2.00|     6.00|     7.00|     8.00|     12.00|▁▅▇▁▁ |\n|PhysActiveDays  |      5337|          0.47|     3.74|     1.84|     1.00|     2.00|     3.00|     5.00|      7.00|▇▇▃▅▅ |\n|TVHrsDayChild   |      9347|          0.07|     1.94|     1.43|     0.00|     1.00|     2.00|     3.00|      6.00|▇▆▂▂▂ |\n|CompHrsDayChild |      9347|          0.07|     2.20|     2.52|     0.00|     0.00|     1.00|     6.00|      6.00|▇▁▁▁▃ |\n|AlcoholDay      |      5086|          0.49|     2.91|     3.18|     1.00|     1.00|     2.00|     3.00|     82.00|▇▁▁▁▁ |\n|AlcoholYear     |      4078|          0.59|    75.10|   103.03|     0.00|     3.00|    24.00|   104.00|    364.00|▇▁▁▁▁ |\n|SmokeAge        |      6920|          0.31|    17.83|     5.33|     6.00|    15.00|    17.00|    19.00|     72.00|▇▂▁▁▁ |\n|AgeFirstMarij   |      7109|          0.29|    17.02|     3.90|     1.00|    15.00|    16.00|    19.00|     48.00|▁▇▂▁▁ |\n|AgeRegMarij     |      8634|          0.14|    17.69|     4.81|     5.00|    15.00|    17.00|    19.00|     52.00|▂▇▁▁▁ |\n|SexAge          |      4460|          0.55|    17.43|     3.72|     9.00|    15.00|    17.00|    19.00|     50.00|▇▅▁▁▁ |\n|SexNumPartnLife |      4275|          0.57|    15.09|    57.85|     0.00|     2.00|     5.00|    12.00|   2000.00|▇▁▁▁▁ |\n|SexNumPartYear  |      5072|          0.49|     1.34|     2.78|     0.00|     1.00|     1.00|     1.00|     69.00|▇▁▁▁▁ |\n\n\n:::\n:::\n\n\nLet us create a NHANES (sub)-dataset without duplicated IDs and only\nadults:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNHANES <-\n  NHANES %>%\n  distinct(ID, .keep_all = TRUE) \n\n#create a dataset of only adults\nNHANES_adult <-  \n  NHANES %>%\n  filter(Age >= 18) %>% drop_na(Height)\n```\n:::\n\n\n### {{< iconify mdi head-thinking-outline >}} {{< iconify clarity group-solid >}} An \"Assumed\" Population\n\n::: callout-important\n## An \"Assumed\" Population\n\nFor now, we will **treat** this dataset as our **Population**. So each\nvariable in the dataset is a *population* for that particular\nquantity/category, with appropriate *population parameters* such as\n`mean`s, `sd`-s, and `proportions`.\n:::\n\nLet us calculate the **population parameters** for the `Height` data\nfrom our \"assumed\" population:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# NHANES_adult is assumed population\npop_mean_height <- mean(~ Height, data = NHANES_adult)\npop_sd_height <- sd(~ Height, data = NHANES_adult)\n\npop_mean_height\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 168.3497\n```\n\n\n:::\n\n```{.r .cell-code}\npop_sd_height\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10.15705\n```\n\n\n:::\n:::\n\n\n### {{< iconify game-icons card-pickup >}} Sampling\n\nNow, we will sample **ONCE** from the NHANES `Height` variable. Let us\ntake a sample of `sample size` 50. We will compare **sample statistics**\nwith **population parameters** on the basis of this ONE sample of 50:\n\n\n::: {.cell layout=\"[[20,20,60]]\"}\n\n```{.r .cell-code}\nsample_height <- sample(NHANES_adult, size = 50) %>% \n  select(Height)\nsample_height\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Height\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"172.0\"},{\"1\":\"158.8\"},{\"1\":\"171.0\"},{\"1\":\"159.1\"},{\"1\":\"156.5\"},{\"1\":\"170.2\"},{\"1\":\"148.5\"},{\"1\":\"158.7\"},{\"1\":\"167.7\"},{\"1\":\"158.6\"},{\"1\":\"154.3\"},{\"1\":\"173.9\"},{\"1\":\"154.2\"},{\"1\":\"164.3\"},{\"1\":\"174.9\"},{\"1\":\"149.4\"},{\"1\":\"164.2\"},{\"1\":\"168.1\"},{\"1\":\"171.9\"},{\"1\":\"180.1\"},{\"1\":\"156.5\"},{\"1\":\"157.6\"},{\"1\":\"162.7\"},{\"1\":\"176.0\"},{\"1\":\"167.5\"},{\"1\":\"157.9\"},{\"1\":\"150.2\"},{\"1\":\"164.0\"},{\"1\":\"162.6\"},{\"1\":\"171.2\"},{\"1\":\"180.6\"},{\"1\":\"167.1\"},{\"1\":\"188.5\"},{\"1\":\"185.1\"},{\"1\":\"137.3\"},{\"1\":\"161.5\"},{\"1\":\"185.3\"},{\"1\":\"188.3\"},{\"1\":\"153.7\"},{\"1\":\"160.8\"},{\"1\":\"157.3\"},{\"1\":\"174.2\"},{\"1\":\"178.8\"},{\"1\":\"169.1\"},{\"1\":\"151.8\"},{\"1\":\"171.5\"},{\"1\":\"160.8\"},{\"1\":\"160.0\"},{\"1\":\"176.9\"},{\"1\":\"182.1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nsample_mean_height <- mean(~ Height, data = sample_height)\nsample_mean_height\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 165.866\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plotting the histogram of this sample\nsample_height %>% \n  gf_histogram(~ Height, bins = 10) %>% \n  \n  gf_vline(xintercept = sample_mean_height, \n           color = \"red\") %>% \n  \n  gf_vline(xintercept = pop_mean_height, \n           colour = \"blue\") %>% \n  \n  gf_label(7 ~ (pop_mean_height + 8), \n          label = \"Population Mean Height\", \n          color = \"blue\") %>% \n  \n  gf_label(7 ~ (sample_mean_height - 8), \n          label = \"Sample Mean Height\", color = \"red\") \n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-8-1.png){width=2100}\n:::\n:::\n\n\n### {{< iconify ic baseline-loop >}} {{< iconify game-icons card-pickup >}} {{< iconify icon-park-outline average >}} Repeated Samples and Sample Means\n\nOK, so the `sample_mean_height` is not too far from the\n`pop_mean_height`. Is this always true? Let us check: we will create 500\nsamples each of size 50. And calculate their mean as the *sample\nstatistic*, giving us a data frame containing 500 `sample means`. We\nwill then see if these 500 means lie close to the `pop_mean_height`:\n\n\n::: {.cell layout=\"[[20,20,60]]\"}\n\n```{.r .cell-code}\nsample_height_500 <- do(500) * {\n  sample(NHANES_adult, size = 50) %>%\n    select(Height) %>%\n    summarise(\n      sample_mean_500 = mean(Height),\n      sample_min_500 = min(Height),\n      sample_max_500 = max(Height))\n}\n\nhead(sample_height_500)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"sample_mean_500\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sample_min_500\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sample_max_500\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".row\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"166.988\",\"2\":\"144.4\",\"3\":\"188.8\",\"4\":\"1\",\"5\":\"1\"},{\"1\":\"166.738\",\"2\":\"143.6\",\"3\":\"190.8\",\"4\":\"1\",\"5\":\"2\"},{\"1\":\"166.864\",\"2\":\"146.6\",\"3\":\"192.3\",\"4\":\"1\",\"5\":\"3\"},{\"1\":\"170.150\",\"2\":\"146.6\",\"3\":\"191.6\",\"4\":\"1\",\"5\":\"4\"},{\"1\":\"169.000\",\"2\":\"149.3\",\"3\":\"190.7\",\"4\":\"1\",\"5\":\"5\"},{\"1\":\"165.948\",\"2\":\"143.4\",\"3\":\"188.3\",\"4\":\"1\",\"5\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ndim(sample_height_500)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 500   5\n```\n\n\n:::\n\n```{.r .cell-code}\nsample_height_500 %>%\n  gf_point(.index ~ sample_mean_500, color = \"red\",\n           title = \"Sample Means are close to the Population Mean\",\n           subtitle = \"Sample Means are Random!\") %>%\n  \n  gf_segment(\n    .index + .index ~ sample_min_500 + sample_max_500,\n    color = \"red\",\n    linewidth = 0.3,\n    alpha = 0.3,\n    ylab = \"Sample Index (1-500)\",\n    xlab = \"Sample Means\"\n  ) %>%\n  \n  gf_vline(xintercept = ~ pop_mean_height, \n           color = \"blue\") %>%\n  \n  gf_label(-15 ~ pop_mean_height, label = \"Population Mean\", \n           color = \"blue\") \n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-9-1.png){width=2100}\n:::\n:::\n\n\n::: callout-note\n### Sample Means are a Random Variable\n\nThe **sample-means** are a random variable! And hence they will have a\n`mean` and `sd`. Do not get confused ;-D\n:::\n\nThe `sample_mean`s (red dots), are themselves random because the samples\nare random, of course. It appears that they are generally in the\nvicinity of the `pop_mean` (blue line).\n\n### {{< iconify game-icons card-pickup >}} {{< iconify tabler chart-histogram >}} Distribution of Sample-Means\n\nSince the **sample-means** are themselves random variables, let's plot\nthe **distribution** of these 500 sample-means themselves, called **a\ndistribution of sample-means**. We will also plot the position of the\npopulation mean `pop_mean_height` parameter, the mean of the `Height`\nvariable.\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nsample_height_500 %>% \n  gf_dhistogram(~ sample_mean_500,bins = 30, xlab = \"Height\") %>% \n  \n  gf_vline(xintercept = pop_mean_height, \n           color = \"blue\") %>% \n  \n  gf_label(0.01 ~ pop_mean_height, \n            label = \"Population Mean\", \n            color = \"blue\") \n\n\n# How does this **distribution of sample-means** compare with the\n# overall distribution of the population?\n# \nsample_height_500 %>% \n  gf_dhistogram(~ sample_mean_500, bins = 30,xlab = \"Height\") %>% \n  \n  gf_vline(xintercept = pop_mean_height, \n           color = \"blue\") %>% \n  \n   gf_label(0.01 ~ pop_mean_height, \n            label = \"Population Mean\", \n            color = \"blue\") %>% \n\n  ## Add the population histogram\n  gf_histogram(~ Height, data = NHANES_adult, \n               alpha = 0.2, fill = \"blue\", \n               bins = 30) %>% \n  \n  gf_label(0.025 ~ (pop_mean_height + 20), \n           label = \"Population Distribution\", color = \"blue\") \n```\n\n::: {.cell-output-display}\n![Sample](sampling_files/figure-html/Sampling-Mean-Distribution-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![Sample and Population](sampling_files/figure-html/Sampling-Mean-Distribution-2.png){width=2100}\n:::\n\nDistributions\n:::\n\n\n### {{< iconify carbon concept >}} Central Limit Theorem\n\nWe see in the Figure above that\n\n-   the *distribution of sample-means* is centered around the\n    `pop_mean`.\n-   That the standard deviation of the *distribution of sample means* is\n    less than that of the original population. But exactly what is it?\n-   And what is the kind of distribution?\n\nOne more experiment.\n\nNow let's repeatedly sample `Height` and compute the sample mean, and\nlook at the resulting histograms and [Q-Q\nplots.](https://www.youtube.com/watch?v=okjYjClSjOg) (Q-Q plots check\nwhether a certain distribution is close to being normal or not.)\n\nWe will use sample sizes of `c(8, 16, ,32, 64)` and generate 1000\nsamples each time, take the means and plot these 1000 means:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\n\nsamples_height_08 <- do(1000) * mean(resample(NHANES_adult$Height, size = 08))\n\nsamples_height_16 <- do(1000) * mean(resample(NHANES_adult$Height, size = 16))\n\nsamples_height_32 <- do(1000) * mean(resample(NHANES_adult$Height, size = 32))\n\nsamples_height_64 <- do(1000) * mean(resample(NHANES_adult$Height, size = 64))\n\n# samples_height_128 <- do(1000) * mean(resample(NHANES_adult$Height, size = 128))\n\n# Quick Check\nhead(samples_height_08)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"171.2250\",\"_rn_\":\"1\"},{\"1\":\"170.2000\",\"_rn_\":\"2\"},{\"1\":\"170.9875\",\"_rn_\":\"3\"},{\"1\":\"166.5250\",\"_rn_\":\"4\"},{\"1\":\"167.3000\",\"_rn_\":\"5\"},{\"1\":\"171.9375\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNow let's create separate `Q-Q plots` for the different sample sizes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Now let's create separate Q-Q plots for the different sample sizes.\n# ggplot2::theme_set(theme_classic())\n\np1 <- gf_qq( ~ mean,data = samples_height_08,\n             title = \"N = 8\", \n             color = \"dodgerblue\") %>%\n  gf_qqline()\n\np2 <- gf_qq( ~ mean,data = samples_height_16,\n            title = \"N = 16\", \n            color = \"sienna\") %>%\n  gf_qqline()\n\np3 <- gf_qq( ~ mean,data = samples_height_32,\n            title = \"N = 32\", \n            color = \"palegreen\") %>%\n  gf_qqline()\n\np4 <- gf_qq( ~ mean,data = samples_height_64,\n            title = \"N = 64\", \n            color = \"violetred\") %>%\n  gf_qqline()\n\ncowplot::plot_grid(p1, p2, p3, p4)\n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-12-1.png){width=2100}\n:::\n:::\n\n\nLet us plot their individual histograms to compare them:\n\n\n::: {.cell layout-nrow=\"2\" layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# Let us overlay their individual histograms to compare them:\np5 <- gf_dhistogram(~ mean,\n              data = samples_height_08,\n              color = \"grey\",\n              fill = \"dodgerblue\",title = \"N = 8\") %>%\n  gf_fitdistr() %>%\n  gf_vline(xintercept = pop_mean_height, inherit = FALSE,\n           color = \"blue\") %>%\n  gf_label(-0.025 ~ pop_mean_height, \n           label = \"Population Mean\", \n           color = \"blue\") %>% \n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08,0.02))))\n\np6 <- gf_dhistogram(~ mean,\n              data = samples_height_16,\n              color = \"grey\",\n              fill = \"sienna\",title = \"N = 16\") %>%\n  gf_fitdistr() %>%\n  gf_vline(xintercept = pop_mean_height,\n           color = \"blue\") %>%\n  gf_label(-.025 ~ pop_mean_height, \n           label = \"Population Mean\", \n           color = \"blue\") %>% \n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08,0.02))))\n\np7 <- gf_dhistogram(~ mean,\n                    data = samples_height_32 ,\n                    na.rm = TRUE,\n                    color = \"grey\",\n                    fill = \"palegreen\",title = \"N =32\") %>%\n  gf_fitdistr() %>%\n  gf_vline(xintercept = pop_mean_height,\n           color = \"blue\") %>%\n  gf_label(-.025 ~ pop_mean_height, \n           label = \"Population Mean\", color = \"blue\") %>% \n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08,0.02))))\n\np8 <- gf_dhistogram(~ mean, \n                    data = samples_height_64,\n                    na.rm = TRUE,\n                    color = \"grey\",\n                    fill = \"violetred\",title = \"N = 64\") %>% \n  gf_fitdistr() %>% \n  gf_vline(xintercept = pop_mean_height,\n         color = \"blue\") %>%\n  gf_label(-.025 ~ pop_mean_height, \n           label = \"Population Mean\", color = \"blue\") %>% \n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08,0.02))))\n\n#patchwork::wrap_plots(p5,p6,p7,p8)\np5\n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-13-1.png){width=2100}\n:::\n\n```{.r .cell-code}\np6\n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-13-2.png){width=2100}\n:::\n\n```{.r .cell-code}\np7\n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-13-3.png){width=2100}\n:::\n\n```{.r .cell-code}\np8\n```\n\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-13-4.png){width=2100}\n:::\n:::\n\n\nAnd if we overlay the histograms:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sampling_files/figure-html/unnamed-chunk-14-1.png){width=2100}\n:::\n:::\n\n\nThe QQ plots show that the results become more normally distributed\n(i.e. following the straight line) as the samples get larger. From the\nhistograms we learn that the sample-means are normally distributed\naround the *population mean*. [This feels intuitively right because when\nwe sample from the population, many values will be close to the\n*population mean*, and values far away from the mean will be\nincreasingly scarce.]{style=\"background-color: yellow;\"}\n\nLet us calculate the mean of the sample-means:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(~ mean, data  = samples_height_08)\nmean(~ mean, data  = samples_height_16)\nmean(~ mean, data  = samples_height_32)\nmean(~ mean, data  = samples_height_64)\npop_mean_height\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 168.0245\n[1] 168.4516\n[1] 168.3748\n[1] 168.3037\n[1] 168.3497\n```\n\n\n:::\n:::\n\n\nAnd the sample `sd`s:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(~ mean, data  = samples_height_08)\nsd(~ mean, data  = samples_height_16)\nsd(~ mean, data  = samples_height_32)\nsd(~ mean, data  = samples_height_64)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.65638\n[1] 2.454437\n[1] 1.807573\n[1] 1.251853\n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Central Limit Theorem\n\nThis is the **Central Limit Theorem (CLT)**\n\n-   the [sample-means are normally distributed around the *population\n    mean*]{style=\"background-color: yellow;\"}.\n-   the sample-means become \"more normally distributed\" with sample\n    length, as shown by the (small but definite) improvements in the Q-Q\n    plots with sample-size.\n-   the sample-mean distributions narrow with sample length, i.e [the\n    `sd` decreases with increasing sample\n    size.]{style=\"background-color: yellow;\"}\n-   This is [regardless of the distribution of the *population*\n    parameter]{style=\"background-color: yellow;\"} itself.[^1]\n:::\n\n## {{< iconify dashicons code-standards >}} Standard Error\n\nAs we saw above, the standard deviations of the sample-mean\ndistributions reduce with sample size. In fact their SDs are defined by:\n\n`sd = pop_sd/sqrt(sample_size)`[^2] where sample-size here is one of\n`c(8, 16,32,64)`\n\nThe standard deviation of the **sample-mean distribution** is called the\n**Standard Error**. This statistic derived from the sample, will help us\ninfer our population parameters with a precise estimate of the\n*uncertainty* involved.\n\n$$\nStandard\\ Error\\ \\pmb {se} = \\frac{population\\ sd}{\\sqrt[]{sample\\ size}} \\\\\\\n\\pmb {se} = \\frac{\\sigma}{\\sqrt[]{n}}\n$$\n\nIn our sampling experiments, the Standard Errors evaluate to:\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\npop_sd_height <- sd(~ Height, data = NHANES_adult)\n\npop_sd_height/sqrt(8)\npop_sd_height/sqrt(16)\npop_sd_height/sqrt(32)\npop_sd_height/sqrt(64)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.591058\n[1] 2.539262\n[1] 1.795529\n[1] 1.269631\n```\n\n\n:::\n:::\n\n\nAs seen, these are identical to the Standard Deviations of the\nindividual sample-mean distributions.\n\n## {{< iconify fluent auto-fit-width-24-filled >}} Confidence intervals\n\nWhen we work with samples, we want to be able to speak with a certain\ndegree of confidence about the **population mean**, based on the\nevaluation of **one** sample mean, not a large number of them. Given\nthat sample-means are normally distributed around the **population means**, we can say that $68\\%$ of *all possible sample-mean* lie within\n$\\pm SE$ of the *population mean*; and further that $95 \\%$ of *all\npossible sample-mean* lie within $\\pm 2*SE$ of the *population mean*.\n\nThese two intervals $sample.mean \\pm SE$ and $sample.mean \\pm 1.5*SE$\nare called the **confidence intervals** for the population mean, at\nlevels $68\\%$ and $95 \\%$ probability respectively.\n\n## {{< iconify flat-color-icons workflow >}} Workflow\n\nThus if we want to estimate a *population parameter*:\n\n-   we take one **random** sample from the population\n\n-   we calculate the estimate from the sample\n\n-   we calculate the sample-sd\n\n-   we calculate the *Standard Error* as $\\frac{sample-sd}{\\sqrt[]{n}}$\n\n-   we calculate 95% confidence intervals for the *population parameter*\n    based on the formula\n\n    $CI_{95\\%}= sample.mean \\pm 2*SE$.\n\n-   Since Standard Error decreases with sample size, we need to make our\n    sample of adequate size.( $n=30$ seems appropriate in most cases.\n    Why?)\n  \n- And we do not have to worry about the distribution of the population. It need not be normal !!\n\n## {{< iconify material-symbols interactive-space-outline >}} An interactive Sampling app\n\nHere below is an interactive sampling app. Choose the number of samples you want from a **normally-distributed population** $N(\\mu = 0, \\sigma = 1)$. Vary the sample size to see how the sample mean varies around the tru population mean. \n\n```{shinylive-r}\n#| standalone: true\n#| viewerHeight: 600\n#| viewerWidth: 1000\nlibrary(shiny)\nlibrary(bslib)\n\n# Define UI for app that draws a histogram ----\nui <- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    numericInput(\"n\", \"Sample count\", 100),\n    checkboxInput(\"pause\", \"Pause\", FALSE),\n  ),\n  plotOutput(\"plot\", width=800)\n)\n\nserver <- function(input, output, session) {\n  data <- reactive({\n    input$resample\n    if (!isTRUE(input$pause)) {\n      invalidateLater(1000)\n    }\n    rnorm(input$n)\n  })\n  \n  output$plot <- renderPlot({\n    hist(data(),\n      breaks = 40,\n      xlim = c(-3, 3),\n      ylim = c(0, 1.5),\n      lty = \"blank\",\n      xlab = \"value\",\n      freq = FALSE,\n      main = \"\"\n    )\n    \n    x <- seq(from = -3, to = 3, length.out = 500)\n    y <- dnorm(x)\n    lines(x, y, lwd=1.5)\n    \n    lwd <- 5\n    abline(v=0, col=\"red\", lwd=lwd, lty=2)\n    abline(v=mean(data()), col=\"blue\", lwd=lwd, lty=1)\n\n    legend(legend = c(\"Normal\", \"Mean\", \"Sample mean\"),\n      col = c(\"black\", \"red\", \"blue\"),\n      lty = c(1, 2, 1),\n      lwd = c(1, lwd, lwd),\n      x = 0.25,\n      y = 1.25\n    )\n  }, res=140)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)\n\n```\nWhat if we sample from *not* a normal distribution but say, a Poisson Distribution? Will we still see the sample mean hover around the population mean?\n\n\n::: {.cell}\n\n:::\n\n\n## An Interactive app for the CLT\n\n<https://gallery.shinyapps.io/CLT_mean/>\n\n\n## {{< iconify ooui references-rtl >}} References\n\n1.  Diez, David M & Barr, Christopher D & Çetinkaya-Rundel, Mine,\n    *OpenIntro Statistics*. <https://www.openintro.org/book/os/>\n\n2.  Stats Test Wizard.\n    <https://www.socscistatistics.com/tests/what_stats_test_wizard.aspx>\n\n3.  Diez, David M & Barr, Christopher D & Çetinkaya-Rundel, Mine:\n    *OpenIntro Statistics*. Available online\n    <https://www.openintro.org/book/os/>\n\n4.  Måns Thulin, *Modern Statistics with R: From wrangling and exploring\n    data to inference and predictive modelling*\n    <http://www.modernstatisticswithr.com/>\n\n5.  Jonas Kristoffer Lindeløv, Common statistical tests are linear\n    models (or: how to teach stats)\n    <https://lindeloev.github.io/tests-as-linear/>\n\n6.  CheatSheet\n    <https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf>\n\n7.  Common statistical tests are linear models: a work through by Steve\n    Doogue <https://steverxd.github.io/Stat_tests/>\n\n8.  Jeffrey Walker \"Elements of Statistical Modeling for Experimental\n    Biology\".\n    <https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/>\n\n9.  Adam Loy, Lendie Follett & Heike Hofmann (2016) Variations of\n    *Q*--*Q* Plots: The Power of Our Eyes!, The American Statistician,\n    70:2, 202-214, DOI:\n    [10.1080/00031305.2015.1077728](https://doi.org/10.1080/00031305.2015.1077728)\n\n\n[^1]: The \\`Height\\` variable seems to be normally distributed at\n    population level. We will try other non-normal population variables\n    as an exercise in the tutorials.\n\n[^2]: Once `sample size = population`, we have complete access to the\n    population and there is no question of estimation error! So\n    `sample_sd = pop_sd`!\n\n::: {#refs style=\"font-size: 60%;\"}\n\n###### {{< iconify lucide package-check >}} R Package Citations\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nPackage         Version   Citation       \n--------------  --------  ---------------\nNHANES          2.1.0     @NHANES        \nregressinator   0.1.3     @regressinator \nsmovie          1.1.6     @smovie        \nTeachHist       0.2.1     @TeachHist     \nTeachingDemos   2.13      @TeachingDemos \nvisualize       4.5.0     @visualize     \n\n\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}