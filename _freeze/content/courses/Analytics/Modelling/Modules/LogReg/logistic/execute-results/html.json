{
  "hash": "0e976e625e87f9e53d3678fd85b6623a",
  "result": {
    "markdown": "---\ntitle: \"Modelling with Logistic Regression\"\nauthor: \"Arvind Venkatadri\"\ndate: 13/Apr/2023\ndate-modified: \"2023-09-01\"\norder: 20\nformat:\n  html:\n    html-math-method: katex\nimage: preview.png\nimage-alt: \"\"\ncategories: \n  - Logistic Regression\n  - Qualitative Variable\n  - Probability\n---\n\n::: {.cell hash='logistic_cache/html/setup_36a7acdb40dde9f25d1cddad4d7cede4'}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE)\nlibrary(tidyverse)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(infer)\nlibrary(regressinator) # pedagogic tool for GLMs\nlibrary(GLMsData)\n```\n:::\n\n\n## Introduction\n\nWe saw with the **general linear model** that it models the **mean** of\na target variable as a linear weighted sum of the predictor variables.\n\nA general linear model can be stated as: \n\n$$\n\\begin{cases}\n& y_i = \\beta_0 + \\beta_1 * x_{1i} + \\beta_2*x_{2i}...+ \\beta_p*x_{pi} + \\epsilon_i\\\\\nwhere\\\\\n& p = number~ of ~ predictors~ x_p\\\\\n& y_i, ~ i = 1, . . . , n~ is ~ the ~ response ~ variable\\\\\n& \\epsilon_i = an~ error~ term, for~ the ~ i^{th} ~ predictions\n\\end{cases}\n$$\n\nThis model is considered to be **general** because of the dependence on\npotentially more than one explanatory variable, v.s. the **simple**\nlinear model:[^1] $y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i$. The general linear model gives us model \"shapes\" that start from a simple straight line to a *p-dimensional hyperplane*.\n\nThe model is **linear in the parameters** $\\beta_i$, e.g. these are OK:\n\n$$\n\\color{blue}{\n\\begin{cases}\n & y_i = \\pmb\\beta_0 + \\pmb\\beta_1x_1 + \\pmb\\beta_2x_1^2 + \\epsilon_i\\\\\n & y_1 = \\pmb\\beta_0 + \\pmb\\gamma_1\\pmb\\delta_1x_1 + exp(\\pmb\\beta_2)x_2+ \\epsilon_i\\\\\n\\end{cases}\n}\n$$\n\nbut not, for example, these:\n\n$$\n\\color{red}{\n\\begin{cases}\n & y_i = \\pmb\\beta_0 + \\pmb\\beta_1x_1^{\\beta_2} + \\epsilon_i\\\\\n & y_i = \\pmb\\beta_0 + exp(\\pmb\\beta_1x_1) + \\epsilon_i\\\\\n\\end{cases}\n}\n$$\n\nAlthough a very useful framework, there are some situations where\ngeneral linear models are not appropriate:\n\n-   the range of Y is restricted (e.g. binary, count)\n-   the variance of Y depends on the mean(Taylor's Law)[^2]\n\n**Generalized linear models** extend the general linear model framework\nto address both of these issues.\n\n## Generalized Linear Model\n\n::: callout-important\nA generalized linear model is made up of a linear predictor:\n\n$$\n\\eta_i = \\beta_0 + \\beta_1x_{1i} + ... + \\beta_px_{pi}\n$$ \n\nand two functions:\n\n-   a link function that describes how the mean, $E(Y_i) = \\mu_i$,\n    depends on the linear predictor:\\\n    \n    $$\n    g(\\mu_i) = \\eta_i\n    $$\n    \n-   a variance function that describes how the variance, $var(Y_i)$\n    depends on the mean:\\\n    \n    $$\n    var(Y_i) = \\Phi*V(\\mu_i)\n    $$\n\nwhere the dispersion parameter $\\Phi$ is a constant. \n:::\n\nFor example we can obtain our *general linear model* with the following choice: \n\n$$\n\\begin{align}\n& g(\\mu_i) = \\mu_i\\\\\n& Phi = 1\n\\end{align}\n$$ \n\nIf now we assume that the *target* variable $Y_i$ is a **binomial**,\ni.e. a two-valued variable:\\\n\n$$\n\\begin{align}\n & Y_i = binom(n_i,p_i)\\\\\n & mean(Y_i) = n_ip_i\\\\\n & var(Y_i) = n_ip_i(1-p_i)\n\\end{align}\n$$\n\nNow, we wish to model the **proportions** $Y_i/n_i$, as our **target**.\nThen we can state that:\\\n\n$$\n\\begin{align}\nmean(Y_i/n_i) = mean(Y_i/n_i) = p_i \\coloneqq \\mu_i\\\\\nvar(Y_i/n_i) = var(Y_i)/n_i^2 = \\frac{p_i(1-p_i)}{n_i} \\coloneqq \\sigma_i^2\\\\\n\\end{align}\n$$ \n\nInspecting the above, we can write for the **target variable**: \n\n$$\n\\sigma_i^2 = \\frac{\\mu_i(1-\\mu_i)}{n_i}\n$$ \n\nand since the link function needs to map ${[-\\infty, \\infty]}$ to\n${[0,1]}$, we use the `logit` function: \n\n$$\ng(\\mu_i) = logit(\\mu_i) = log(\\frac{\\mu_i}{1-\\mu_i})\n$$\n\n## References\n\n1.  <https://yury-zablotski.netlify.app/post/how-logistic-regression-works/>\n\n2.  <https://uc-r.github.io/logistic_regression>\n\n3.  <https://francisbach.com/self-concordant-analysis-for-logistic-regression/>\n\n4.  <https://statmath.wu.ac.at/courses/heather_turner/glmCourse_001.pdf>\n\n5.  \n\n[^1]: https://statmath.wu.ac.at/courses/heather_turner/glmCourse_001.pdf\n\n[^2]: https://en.wikipedia.org/wiki/Taylor%27s_law\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}