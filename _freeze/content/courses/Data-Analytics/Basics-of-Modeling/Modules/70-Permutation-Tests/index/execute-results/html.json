{
  "hash": "fab7cd55204c5d5a2b6c9a0f63d79316",
  "result": {
    "markdown": "---\ntitle: 'Permutation Tests'\nauthor: \"Arvind Venkatadri\"\nabstract: \"Generating Parallel Worlds\"\ndate: 28/Nov/2022\ndate-modified: \"2023-03-12\"\norder: 70\ntags:\n- Permutation\n- Monte Carlo Simulation\n- Random Number Generation\n- Distributions\n---\n\n::: {.cell hash='index_cache/html/setup_a78d29406c8a0a2bb7075d0279d1e17b'}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = FALSE,message = TRUE,warning = TRUE, fig.align = \"center\")\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(mosaic)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n```\n:::\n\n```{.r .cell-code}\n### Datasets from Chihara and Hesterberg's book (Second Edition)\nlibrary(resampledata)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n```\n:::\n:::\n\n\n## Introduction\n\nWe saw from the diagram created by Allen Downey that *there is only one\ntest*! We will now use this philosophy to develop a technique that\nallows us to mechanize several *Statistical Models* in that way, with\nnearly identical code.\n\nWe will use two packages in R, `mosaic` and the relatively new `infer`\npackage, to develop our intuition for what are called **permutation**\nbased statistical tests.\n\n## Hypothesis Testing using Permutation\n\nFrom Reference #1:\n\n> Hypothesis testing can be thought of as a 4-step process:\n>\n> 1.  State the null and alternative hypotheses.\n>\n> 2.  Compute a test statistic.\n>\n> 3.  Determine the p-value.\n>\n> 4.  Draw a conclusion.\n>\n>     In a traditional introductory statistics course, once this general\n>     framework has been mastered, the main work is in **applying the\n>     correct formula** to compute the standard test statistics in step\n>     2 and using a table or computer to **determine the p-value** based\n>     on the known (usually approximate) **theoretical distribution of\n>     the test statistic** under the null hypothesis.\n>\n>     In a **simulation-based approach**, steps 2 and 3 change. In Step\n>     2, it is no longer required that the test statistic be normalized\n>     to conform with a known, named distribution. Instead, natural test\n>     statistics, like the difference between two sample means $y1 − y2$\n>     can be used.\n>\n>     In Step 3, we use **randomization to approximate the sampling\n>     distribution of the test statistic**. Our lady tasting tea example\n>     demonstrates how this can be done from first principles. More\n>     typically, we will use randomization **to create new simulated\n>     data sets** ( \"*Parallel Worlds*\") that are like our original data\n>     in some ways, but make the null hypothesis true. For each\n>     simulated data set, we calculate our test statistic, just as we\n>     did for the original sample. Together, this collection of test\n>     statistics computed from the simulated samples constitute our\n>     randomization distribution.\n>\n>     When creating a randomization distribution, we will attempt to\n>     satisfy 3 guiding principles.\n>\n> 5.  Be consistent with the null hypothesis. We need to **simulate a\n>     world** in which the null hypothesis is true. If we don't do this,\n>     we won't be testing our null hypothesis.\n>\n> 6.  Use the data in the **original sample**. The original data should\n>     shed light on some aspects of the distribution that are not\n>     determined by null hypothesis. For example, a null hypothesis\n>     about a mean doesn't tell us about the shape of the population\n>     distribution, but the data give us some indication.\n>\n> 7.  Reflect the way the original data were collected.\n\nFrom Chihara and Hesterberg:\n\n> This is the core idea of statistical significance or classical\n> hypothesis testing -- to calculate how often pure random chance would\n> give an effect as large as that observed in the data, in the absence\n> of any real effect. If that probability is small enough, we conclude\n> that the data provide convincing evidence of a real effect.\n\n### Permutations tests using mosaic::`shuffle()`\n\nThe `mosaic` package provides the `shuffle()` function as a synonym for\n`sample()`. When used without additional arguments, this will permute\nits first argument.\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/unnamed-chunk-2_e77737495cf763e8366335357cf0b4a9'}\n\n```{.r .cell-code}\nshuffle(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  4  9  5  7  8  1  3  2  6 10\n```\n:::\n:::\n\n\nApplying shuffle() to an *explanatory variable* in a model allows us to\ntest the null hypothesis that the explanatory variable has, in fact, no\nexplanatory power. This idea can be used to test\n\n-   the equivalence of two or more means,\n-   the equivalence of two or more proportions,\n-   whether a regression parameter is 0. (Correlations between two\n    variables)\n\nWe will now see examples of each of these models using Permutations.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}