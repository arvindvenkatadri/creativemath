[
  {
    "objectID": "content/courses/Analytics/Descriptive/listing.html",
    "href": "content/courses/Analytics/Descriptive/listing.html",
    "title": "Descriptive Analytics",
    "section": "",
    "text": "Title\n\n\n\n\n\n\n\n\n\nüï∂ Science, Human Experience, Experiments, and Data\n\n\n\n\n\n\n\nüìä Descriptive Statistics\n\n\n\n\n\n\n\nüìä Distributions, Densities, Bar Plots, and Boxplots\n\n\n\n\n\n\n\nüìé Correlations\n\n\n\n\n\n\n\nüêâ Visualizing Categorical Data\n\n\n\n\n\n\n\nüêâ Visualizing Survey Data\n\n\n\n\n\n\n\nüïî Time Series\n\n\n\n\n\n\n\nüçï Parts of a Whole\n\n\n\n\n\n\n\nüï∏ Change, Evolution, and Flow\n\n\n\n\n\n\n\nüëå Ratings and Rankings\n\n\n\n\n\n\n\nüó∫ Visualising Spatial Data\n\n\n\n\n\n\n\nüï∏ Networks\n\n\n\n\n\n\n\nüìö Miscellaneous Graphing Tools, and References\n\n\n\n\n\n\n\nEDA Workflow\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics"
    ]
  },
  {
    "objectID": "content/work-related/fsp-portfolio-2022/index.html",
    "href": "content/work-related/fsp-portfolio-2022/index.html",
    "title": "Teaching in this post(?) - Pandemic Year 2021-2022",
    "section": "",
    "text": "This is a short Portfolio of Teaching Initiatives and Student Outcomes during this post(?)-pandemic year, 2021-2022, from Arvind Venkatadri.\n\n\n\n Back to top"
  },
  {
    "objectID": "content/work-related/fsp-manifesto/index.html",
    "href": "content/work-related/fsp-manifesto/index.html",
    "title": "My Teaching Manifesto",
    "section": "",
    "text": "This is a short Statement of Values, Beliefs, and Content in my Teaching.\n\nArvind Venkatadri.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html",
    "title": "Tutorial on Correlations in R",
    "section": "",
    "text": "We will create Tables for Correlations, and graphs for Correlations in R. As always, we will consistently use the Project Mosaic ecosystem of packages in R (mosaic, mosaicData and ggformula)."
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#introduction",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#introduction",
    "title": "Tutorial on Correlations in R",
    "section": "",
    "text": "We will create Tables for Correlations, and graphs for Correlations in R. As always, we will consistently use the Project Mosaic ecosystem of packages in R (mosaic, mosaicData and ggformula)."
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#setting-up-r-packages",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#setting-up-r-packages",
    "title": "Tutorial on Correlations in R",
    "section": "\n Setting up R Packages",
    "text": "Setting up R Packages\n\nlibrary(tidyverse)\nlibrary(mosaic) # package for stats, simulations, and basic plots\nlibrary(ggformula) # package for professional looking plots, that use the formula interface from mosaic\nlibrary(skimr)\nlibrary(GGally)\nlibrary(corrplot) # For Correlogram plots\nlibrary(broom) # to properly format stat test results\n\nlibrary(mosaicData) # package containing datasets\nlibrary(NHANES) # survey data collected by the US National Center for Health Statistics (NCHS)\n\nAll R functions seen in the code are clickable links that take you to online documentation about the function. Try!\n\n\n\n\n\n\nThe Formula interface\n\n\n\nNote the standard method for all commands from the mosaic package:\ngoal( y ~ x | z, data = mydata, ‚Ä¶)\nWith ggformula, one can create any graph/chart using:\ngf_geometry(y ~ x | z, data = mydata)\nOR\nmydata %&gt;% gf_geometry( y ~ x | z )\nThe second method may be preferable, especially if you have done some data manipulation first! More about this later!"
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#case-study-1-galton-dataset-from-mosaicdata",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#case-study-1-galton-dataset-from-mosaicdata",
    "title": "Tutorial on Correlations in R",
    "section": "\n Case Study 1: Galton Dataset from mosaicData\n",
    "text": "Case Study 1: Galton Dataset from mosaicData\n\nLet us inspect what datasets are available in the package mosaicData. Run this command in your Console:\n\n# Run in Console\ndata(package = \"mosaicData\")\n\nThe popup tab shows a lot of datasets we could use. Let us continue to use the famous Galton dataset and inspect it:\n\ndata(\"Galton\")\n\n\n Inspecting the Data\nThe inspect command already gives us a series of statistical measures of different variables of interest. As discussed previously, we can retain the output of inspect and use it in our reports: (there are ways of dressing up these tables too)\n\ngalton_describe &lt;- inspect(Galton)\n\ngalton_describe$categorical\n\n\n  \n\n\ngalton_describe$quantitative\n\n\n  \n\n\n\nTry help(\"Galton\") in your Console. The dataset is described as:\n\nA data frame with 898 observations on the following variables.\n- family a factor with levels for each family\n- father the father‚Äôs height (in inches)\n- mother the mother‚Äôs height (in inches)\n- sex the child‚Äôs sex: F or M\n- height the child‚Äôs height as an adult (in inches)\n- nkids the number of adult children in the family, or, at least, the number whose heights Galton recorded.\n\nThere is a lot of Description generated by the mosaic::inspect() command ! Let us also look at the output of skim:\n\nskimr::skim(Galton)\n\n\nData summary\n\n\nName\nGalton\n\n\nNumber of rows\n898\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nfamily\n0\n1\nFALSE\n197\n185: 15, 166: 11, 66: 11, 130: 10\n\n\nsex\n0\n1\nFALSE\n2\nM: 465, F: 433\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nfather\n0\n1\n69.23\n2.47\n62\n68\n69.0\n71.0\n78.5\n‚ñÅ‚ñÖ‚ñá‚ñÇ‚ñÅ\n\n\nmother\n0\n1\n64.08\n2.31\n58\n63\n64.0\n65.5\n70.5\n‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñÅ\n\n\nheight\n0\n1\n66.76\n3.58\n56\n64\n66.5\n69.7\n79.0\n‚ñÅ‚ñá‚ñá‚ñÖ‚ñÅ\n\n\nnkids\n0\n1\n6.14\n2.69\n1\n4\n6.0\n8.0\n15.0\n‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÅ\n\n\n\n\n\nWhat can we say about the dataset and its variables? How big is the dataset? How many variables? What types are they, Quant or Qual? If they are Qual, what are the levels? Are they ordered levels? Which variables could have relationships with others? Why? Write down these Questions!\n\n Correlations and Plots\nWhat Questions might we have, that we could answer with a Statistical Measure, or Correlation chart?\n\n\n\n\n\n\nQuestions\n\n\n\nHow does children‚Äôs height correlate with that of father and mother? Is this relationship also affected by sex of the child?\nWith this question, height becomes our target variable, which we should always plot on the dependent y-axis.\n\n\n\n# Pulling out the list of Quant variables from NHANES\ngalton_quant &lt;- galton_describe$quantitative\ngalton_quant$name\n\n[1] \"father\" \"mother\" \"height\" \"nkids\" \n\nGGally::ggpairs(\n  Galton,\n  \n  # Choose the variables we want to plot for\n  columns = c(\"father\", \"mother\", \"height\", \"nkids\"),\n  \n  switch = \"both\", # axis labels in more traditional locations\n  progress = FALSE, # no compute progress messages needed\n  \n  # Choose the diagonal graphs (always single variable! Think!)\n  diag = list(continuous = \"barDiag\"), # choosing histogram,not density\n  \n  # Choose lower triangle graphs, two-variable graphs\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.1)),\n  \n  title = \"Galton Data Correlations Plot\"\n) + \n  \n  theme_bw()\n\n\n\n\n\n\n\nWe note that children‚Äôs height is correlated with that of father and mother. The correlations are both positive, and that with father seems to be the larger of the two. ( Look at the slopes of the lines and the values of the correlation scores. )\n\n\n\n\n\n\nQuestion\n\n\n\nWhat if we group the Quant variables based on a Qual variable, like sex of the child?\n\n\n\n# Pulling out the list of Quant variables from NHANES\ngalton_quant &lt;- galton_describe$quantitative\ngalton_quant$name\n\n[1] \"father\" \"mother\" \"height\" \"nkids\" \n\nGGally::ggpairs(\n  Galton,\n  \n  mapping = aes(colour = sex), # Colour by `sex`\n\n  # Choose the variables we want to plot for\n  columns = c(\"father\", \"mother\", \"height\", \"nkids\"),\n  switch = \"both\", # axis labels in more traditional locations\n  progress = FALSE, # no compute progress messages needed\n  \n  diag = list(continuous = \"barDiag\"),\n  \n  # Choose lower triangle graphs, two-variable graphs\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.1)),\n  \n  title = \"Galton Data Correlations Plot\"\n) + \n  \n  theme_bw()\n\n\n\n\n\n\n\nThe split scatter plots are useful, as is the split histogram for height: Clearly the correlation of children‚Äôs height with father and mother is positive for both sex-es. The other plots, and even some of the correlations scores are not all useful! Just shows everything we can compute is not necessarily useful immediately.\nIn later modules we will see how to plot correlations when the number of variables is larger still.\n\n\n\n\n\n\nQuestion\n\n\n\nCan we plot a Correlogram for this dataset?\n\n\n\n#library(corrplot)\n\ngalton_num_var &lt;- Galton %&gt;% select(father, mother, height, nkids)\ngalton_cor &lt;- cor(galton_num_var)\ngalton_cor %&gt;%\n  corrplot(method = \"ellipse\",\n           type = \"lower\",\n           main = \"Correlogram for Galton dataset\")\n\n\n\n\n\n\n\nClearly height is positively correlated to father and mother; interestingly, height is negatively correlated ( slightly) with nkids.\n\n\n\n\n\n\nQuestion\n\n\n\nLet us confirm with a correlation test:\n\n\nWe will use the mosaic function cor_test to get these results:\n\nmosaic::cor_test(height ~ father, data = Galton) %&gt;% \n  broom::tidy() %&gt;% \n  knitr::kable(digits = 2,\n               caption = \"Children vs Fathers\")\n\n\nChildren vs Fathers\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.28\n8.57\n0\n896\n0.21\n0.33\nPearson‚Äôs product-moment correlation\ntwo.sided\n\n\n\n\n\nmosaic::cor_test(height ~ mother, data = Galton) %&gt;% \n  broom::tidy() %&gt;% \n    knitr::kable(digits = 2,\n               caption = \"Children vs Mothers\")\n\n\nChildren vs Mothers\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.2\n6.16\n0\n896\n0.14\n0.26\nPearson‚Äôs product-moment correlation\ntwo.sided\n\n\n\n\n\n\n\n\n\n\nCorrelation Scores and Uncertainty\n\n\n\nNote how the mosaic::cor_test() reports a correlation score estimate and the p-value for the same. There is also a confidence interval reported for the correlation score, an interval within which we are 95% sure that the true correlation value is to be found.\nNote that GGally::ggpairs() too reports the significance of the correlation scores estimates using *** or **. This indicates the p-value in the scores obtained by GGally; Presumably, there is an internal cor_test that is run for each pair of variables and the p-value and confidence levels are also computed internally.\n\n\nIn both cases, we used the formula \\(height \\sim other-variable\\), in keeping with our idea of height being the dependent, target variable..\nWe also see the p.value for the estimateed correlation is negligible, and the conf.low/conf.high interval does not straddle \\(0\\). These attest to the significance of the correlation score.\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does this correlation look when split by sex of Child?\n\n\n\n# For the sons\n\nmosaic::cor_test(height ~ father,\n                 data = Galton %&gt;% filter(sex == \"M\")) %&gt;% \n  broom::tidy() %&gt;% knitr::kable(digits = 2,\n                                 caption = \"Sons vs Fathers\")\ncor_test(height ~ mother, \n         data = Galton %&gt;% filter(sex == \"M\")) %&gt;% \n  broom::tidy() %&gt;% knitr::kable(digits = 2,\n                                 caption = \"Sons vs Mothers\")\n\n# For the daughters\ncor_test(height ~ father, \n         data = Galton %&gt;% filter(sex == \"F\")) %&gt;% \n  broom::tidy() %&gt;% knitr::kable(digits = 2,\n                                 caption = \"Daughters vs Fathers\")\ncor_test(height ~ mother, \n         data = Galton %&gt;% filter(sex == \"F\")) %&gt;% \n  broom::tidy() %&gt;% knitr::kable(digits = 2,\n                                 caption = \"Daughters vs Mothers\")\n\n\nSons vs Fathers\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.39\n9.15\n0\n463\n0.31\n0.47\nPearson‚Äôs product-moment correlation\ntwo.sided\n\n\n\nSons vs Mothers\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.33\n7.63\n0\n463\n0.25\n0.41\nPearson‚Äôs product-moment correlation\ntwo.sided\n\n\n\nDaughters vs Fathers\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.46\n10.72\n0\n431\n0.38\n0.53\nPearson‚Äôs product-moment correlation\ntwo.sided\n\n\n\nDaughters vs Mothers\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.31\n6.86\n0\n431\n0.23\n0.4\nPearson‚Äôs product-moment correlation\ntwo.sided\n\n\n\n\nThe same observation as made above ( p.value and confidence intervals) applies here too and tells us that the estimated correlations are significant.\nVisualizing Uncertainty in Correlation Estimates\nWe can also visualize this uncertainty and the confidence levels in a plot too, using gf_errorbar and a handy set of functions within purrr which is part of the tidyverse. Assuming heights is the target variable we want to correlate every other (quantitative) variable against, we can proceed very quickly as follows: we will first plot correlation uncertainty for one pair of variables to develop the intuition, and then for all variables against the one target variable:\n\nmosaic::cor_test(height ~ mother, data = Galton) %&gt;% \n  broom::tidy() %&gt;% \n\n# We need a graph not a table \n# So comment out this line from the earlier code\n#knitr::kable(digits = 2,caption = \"Children vs Mothers\")\n\nrowid_to_column(var = \"index\") %&gt;% # Need an index to plot with\n  \n  # Uncertainty as error-bars\n  gf_errorbar(conf.high + conf.low ~ index, linewidth = 2) %&gt;% \n  \n  # Estimate as a point\n  gf_point(estimate ~ index, color = \"red\", size = 6) %&gt;% \n  \n  # Labels\n  gf_text(estimate ~ index - 0.2, \n             label = \"Correlation Score = estimate\") %&gt;% \n  gf_text(conf.high*0.98 ~ index - 0.25, \n           label = \"Upper Limit = estimate + conf.high\") %&gt;%   \n  gf_text(conf.low*1.04 ~ index - 0.25, \n           label = \"Lower Limit = estimate - conf.low\") %&gt;% \n  gf_theme(theme_bw())\n\n\n\n\n\n\n\nWe can now do this for all variables against the target variable height, which we identified in our research question. We will use the iteration capabilities offered by the tidyverse package, purrr:\n\nall_corrs &lt;- Galton %&gt;% \n  select(where(is.numeric)) %&gt;% \n  \n  # leave off height to get all the remaining ones\n  select(- height) %&gt;%  \n  \n  # perform a cor.test for all variables against height\n  purrr::map(.x = .,\n             .f = \\(x) cor.test(x, Galton$height)) %&gt;%\n  \n  # tidy up the cor.test outputs into a tidy data frame\n  map_dfr(broom::tidy, .id = \"predictor\") \n\nall_corrs\n\n\n  \n\n\nall_corrs %&gt;% \n  \n  # arrange the predictors in order of their correlation scores\n  # with the target variable (`height`)\n  # Add errorbars to show uncertainty ranges / confidence intervals\n  # Use errorbar width and linewidth fo emphasis\n  gf_errorbar(conf.high + conf.low ~ reorder(predictor, estimate),\n              color = ~ estimate,\n              width = 0.2,\n              linewidth = ~ -log10(p.value)) %&gt;% \n  \n  # All correlation estimates as points\n  gf_point(estimate ~ reorder(predictor, estimate), \n           color = \"black\") %&gt;% \n  \n  # Reference line at zero correlation score\n  gf_hline(yintercept = 0, color = \"grey\", linewidth = 2) %&gt;% \n  \n  # Themes,Titles, and Scales\n  gf_labs(x = NULL, y = \"Correlation with height in Galton\", \n          caption = \"Significance = - log10(p.value)\") %&gt;% \n  \n  gf_refine(\n    \n    # Scale for colour\n scale_colour_distiller(\"Correlation\", type = \"div\", palette = \"RdBu\"),\n            \n    # Scale for dumbbells!!\n    scale_linewidth_continuous(\"significance\",\n                                       range = c(0.5,4))) %&gt;% \n  gf_refine(guides(linewidth = guide_legend(reverse = TRUE))) %&gt;%\n  gf_theme(theme_classic())\n\n\n\n\n\n\n\nWe can clearly see the size of the correlations and the confidence intervals marked in this plot. father has somewhat greater correlation with children‚Äôs height, as compared to mother. nkids seems to matter very little. This kind of plot will be very useful when we pursue linear regression models.\n\n\n\n\n\n\nQuestion\n\n\n\nHow can we show this correlation in a set of Scatter Plots + Regression Lines? Can we recreate Galton‚Äôs famous diagram?\n\n\n# For the sons\ngf_point(height ~ father, \n         data = Galton %&gt;% filter(sex == \"M\"),\n         title = \"Soms and Fathers\") %&gt;%\n  gf_smooth(method = \"lm\") %&gt;%\n  gf_theme(theme_minimal())\ngf_point(height ~ mother, \n         data = Galton %&gt;% filter(sex == \"M\"),\n         title = \"Sons and Mothers\") %&gt;%\n  gf_smooth(method = \"lm\") %&gt;%\n  gf_theme(theme_minimal())\n# For the daughters\ngf_point(height ~ father, \n         data = Galton %&gt;% filter(sex == \"F\"),\n         title = \"Daughters and Fathers\") %&gt;%\n  gf_smooth(method = \"lm\") %&gt;%\n  gf_theme(theme_minimal())\ngf_point(height ~ mother, \n         data = Galton %&gt;% filter(sex == \"F\"),\n         title = \"Daughters and Mothers\") %&gt;%\n  gf_smooth(method = \"lm\") %&gt;% \n  gf_theme(theme_minimal())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn approximation to Galton‚Äôs famous plot1 (see Wikipedia):\n\n\n\n\n\n\n\n\ngf_point(height ~ (father + mother)/2, data = Galton) %&gt;% \n  gf_smooth(method = \"lm\") %&gt;% \n  gf_density_2d(n = 8) %&gt;% \n  gf_abline(slope = 1) %&gt;% \n  gf_theme(theme_minimal())\ngf_point(height ~ (father + mother)/2, data = Galton) %&gt;% \n  gf_smooth(method = \"lm\") %&gt;% \n  gf_ellipse(level = 0.95, color = \"red\") %&gt;% \n    gf_ellipse(level = 0.75, color = \"blue\") %&gt;% \n    gf_ellipse(level = 0.5, color = \"green\") %&gt;% \n  gf_abline(slope = 1) %&gt;% \n  gf_theme(theme_minimal())\n\n\n\n\n\n\n\n\n\n\nHow would you interpret this plot2?"
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#case-study2-dataset-from-nhanes",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#case-study2-dataset-from-nhanes",
    "title": "Tutorial on Correlations in R",
    "section": "\n Case Study#2: Dataset from NHANES\n",
    "text": "Case Study#2: Dataset from NHANES\n\nLet us look at the NHANES dataset from the package NHANES:\n\ndata(\"NHANES\")\n\n\n Inspecting the Data\nNHANES_describe &lt;- inspect(NHANES)\n\nNHANES_describe$categorical\nNHANES_describe$quantitative\nNHANES\nskimr::skim(NHANES)\n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n\n\nData summary\n\n\nName\nNHANES\n\n\nNumber of rows\n10000\n\n\nNumber of columns\n76\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n31\n\n\nnumeric\n45\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nSurveyYr\n0\n1.00\nFALSE\n2\n200: 5000, 201: 5000\n\n\nGender\n0\n1.00\nFALSE\n2\nfem: 5020, mal: 4980\n\n\nAgeDecade\n333\n0.97\nFALSE\n8\n40: 1398, 0-: 1391, 10: 1374, 20: 1356\n\n\nRace1\n0\n1.00\nFALSE\n5\nWhi: 6372, Bla: 1197, Mex: 1015, Oth: 806\n\n\nRace3\n5000\n0.50\nFALSE\n6\nWhi: 3135, Bla: 589, Mex: 480, His: 350\n\n\nEducation\n2779\n0.72\nFALSE\n5\nSom: 2267, Col: 2098, Hig: 1517, 9 -: 888\n\n\nMaritalStatus\n2769\n0.72\nFALSE\n6\nMar: 3945, Nev: 1380, Div: 707, Liv: 560\n\n\nHHIncome\n811\n0.92\nFALSE\n12\nmor: 2220, 750: 1084, 250: 958, 350: 863\n\n\nHomeOwn\n63\n0.99\nFALSE\n3\nOwn: 6425, Ren: 3287, Oth: 225\n\n\nWork\n2229\n0.78\nFALSE\n3\nWor: 4613, Not: 2847, Loo: 311\n\n\nBMICatUnder20yrs\n8726\n0.13\nFALSE\n4\nNor: 805, Obe: 221, Ove: 193, Und: 55\n\n\nBMI_WHO\n397\n0.96\nFALSE\n4\n18.: 2911, 30.: 2751, 25.: 2664, 12.: 1277\n\n\nDiabetes\n142\n0.99\nFALSE\n2\nNo: 9098, Yes: 760\n\n\nHealthGen\n2461\n0.75\nFALSE\n5\nGoo: 2956, Vgo: 2508, Fai: 1010, Exc: 878\n\n\nLittleInterest\n3333\n0.67\nFALSE\n3\nNon: 5103, Sev: 1130, Mos: 434\n\n\nDepressed\n3327\n0.67\nFALSE\n3\nNon: 5246, Sev: 1009, Mos: 418\n\n\nSleepTrouble\n2228\n0.78\nFALSE\n2\nNo: 5799, Yes: 1973\n\n\nPhysActive\n1674\n0.83\nFALSE\n2\nYes: 4649, No: 3677\n\n\nTVHrsDay\n5141\n0.49\nFALSE\n7\n2_h: 1275, 1_h: 884, 3_h: 836, 0_t: 638\n\n\nCompHrsDay\n5137\n0.49\nFALSE\n7\n0_t: 1409, 0_h: 1073, 1_h: 1030, 2_h: 589\n\n\nAlcohol12PlusYr\n3420\n0.66\nFALSE\n2\nYes: 5212, No: 1368\n\n\nSmokeNow\n6789\n0.32\nFALSE\n2\nNo: 1745, Yes: 1466\n\n\nSmoke100\n2765\n0.72\nFALSE\n2\nNo: 4024, Yes: 3211\n\n\nSmoke100n\n2765\n0.72\nFALSE\n2\nNon: 4024, Smo: 3211\n\n\nMarijuana\n5059\n0.49\nFALSE\n2\nYes: 2892, No: 2049\n\n\nRegularMarij\n5059\n0.49\nFALSE\n2\nNo: 3575, Yes: 1366\n\n\nHardDrugs\n4235\n0.58\nFALSE\n2\nNo: 4700, Yes: 1065\n\n\nSexEver\n4233\n0.58\nFALSE\n2\nYes: 5544, No: 223\n\n\nSameSex\n4232\n0.58\nFALSE\n2\nNo: 5353, Yes: 415\n\n\nSexOrientation\n5158\n0.48\nFALSE\n3\nHet: 4638, Bis: 119, Hom: 85\n\n\nPregnantNow\n8304\n0.17\nFALSE\n3\nNo: 1573, Yes: 72, Unk: 51\n\n\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nID\n0\n1.00\n61944.64\n5871.17\n51624.00\n56904.50\n62159.50\n67039.00\n71915.00\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nAge\n0\n1.00\n36.74\n22.40\n0.00\n17.00\n36.00\n54.00\n80.00\n‚ñá‚ñá‚ñá‚ñÜ‚ñÖ\n\n\nAgeMonths\n5038\n0.50\n420.12\n259.04\n0.00\n199.00\n418.00\n624.00\n959.00\n‚ñá‚ñá‚ñá‚ñÜ‚ñÉ\n\n\nHHIncomeMid\n811\n0.92\n57206.17\n33020.28\n2500.00\n30000.00\n50000.00\n87500.00\n100000.00\n‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñá\n\n\nPoverty\n726\n0.93\n2.80\n1.68\n0.00\n1.24\n2.70\n4.71\n5.00\n‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñá\n\n\nHomeRooms\n69\n0.99\n6.25\n2.28\n1.00\n5.00\n6.00\n8.00\n13.00\n‚ñÇ‚ñÜ‚ñá‚ñÇ‚ñÅ\n\n\nWeight\n78\n0.99\n70.98\n29.13\n2.80\n56.10\n72.70\n88.90\n230.70\n‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nLength\n9457\n0.05\n85.02\n13.71\n47.10\n75.70\n87.00\n96.10\n112.20\n‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÉ\n\n\nHeadCirc\n9912\n0.01\n41.18\n2.31\n34.20\n39.58\n41.45\n42.92\n45.40\n‚ñÅ‚ñÇ‚ñá‚ñá‚ñÖ\n\n\nHeight\n353\n0.96\n161.88\n20.19\n83.60\n156.80\n166.00\n174.50\n200.40\n‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÇ\n\n\nBMI\n366\n0.96\n26.66\n7.38\n12.88\n21.58\n25.98\n30.89\n81.25\n‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ\n\n\nPulse\n1437\n0.86\n73.56\n12.16\n40.00\n64.00\n72.00\n82.00\n136.00\n‚ñÇ‚ñá‚ñÉ‚ñÅ‚ñÅ\n\n\nBPSysAve\n1449\n0.86\n118.15\n17.25\n76.00\n106.00\n116.00\n127.00\n226.00\n‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nBPDiaAve\n1449\n0.86\n67.48\n14.35\n0.00\n61.00\n69.00\n76.00\n116.00\n‚ñÅ‚ñÅ‚ñá‚ñá‚ñÅ\n\n\nBPSys1\n1763\n0.82\n119.09\n17.50\n72.00\n106.00\n116.00\n128.00\n232.00\n‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nBPDia1\n1763\n0.82\n68.28\n13.78\n0.00\n62.00\n70.00\n76.00\n118.00\n‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÅ\n\n\nBPSys2\n1647\n0.84\n118.48\n17.49\n76.00\n106.00\n116.00\n128.00\n226.00\n‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nBPDia2\n1647\n0.84\n67.66\n14.42\n0.00\n60.00\n68.00\n76.00\n118.00\n‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÅ\n\n\nBPSys3\n1635\n0.84\n117.93\n17.18\n76.00\n106.00\n116.00\n126.00\n226.00\n‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nBPDia3\n1635\n0.84\n67.30\n14.96\n0.00\n60.00\n68.00\n76.00\n116.00\n‚ñÅ‚ñÅ‚ñá‚ñá‚ñÅ\n\n\nTestosterone\n5874\n0.41\n197.90\n226.50\n0.25\n17.70\n43.82\n362.41\n1795.60\n‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\n\nDirectChol\n1526\n0.85\n1.36\n0.40\n0.39\n1.09\n1.29\n1.58\n4.03\n‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nTotChol\n1526\n0.85\n4.88\n1.08\n1.53\n4.11\n4.78\n5.53\n13.65\n‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ\n\n\nUrineVol1\n987\n0.90\n118.52\n90.34\n0.00\n50.00\n94.00\n164.00\n510.00\n‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ\n\n\nUrineFlow1\n1603\n0.84\n0.98\n0.95\n0.00\n0.40\n0.70\n1.22\n17.17\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nUrineVol2\n8522\n0.15\n119.68\n90.16\n0.00\n52.00\n95.00\n171.75\n409.00\n‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ\n\n\nUrineFlow2\n8524\n0.15\n1.15\n1.07\n0.00\n0.48\n0.76\n1.51\n13.69\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nDiabetesAge\n9371\n0.06\n48.42\n15.68\n1.00\n40.00\n50.00\n58.00\n80.00\n‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÇ\n\n\nDaysPhysHlthBad\n2468\n0.75\n3.33\n7.40\n0.00\n0.00\n0.00\n3.00\n30.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nDaysMentHlthBad\n2466\n0.75\n4.13\n7.83\n0.00\n0.00\n0.00\n4.00\n30.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nnPregnancies\n7396\n0.26\n3.03\n1.80\n1.00\n2.00\n3.00\n4.00\n32.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nnBabies\n7584\n0.24\n2.46\n1.32\n0.00\n2.00\n2.00\n3.00\n12.00\n‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n\n\nAge1stBaby\n8116\n0.19\n22.65\n4.77\n14.00\n19.00\n22.00\n26.00\n39.00\n‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÅ\n\n\nSleepHrsNight\n2245\n0.78\n6.93\n1.35\n2.00\n6.00\n7.00\n8.00\n12.00\n‚ñÅ‚ñÖ‚ñá‚ñÅ‚ñÅ\n\n\nPhysActiveDays\n5337\n0.47\n3.74\n1.84\n1.00\n2.00\n3.00\n5.00\n7.00\n‚ñá‚ñá‚ñÉ‚ñÖ‚ñÖ\n\n\nTVHrsDayChild\n9347\n0.07\n1.94\n1.43\n0.00\n1.00\n2.00\n3.00\n6.00\n‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÇ\n\n\nCompHrsDayChild\n9347\n0.07\n2.20\n2.52\n0.00\n0.00\n1.00\n6.00\n6.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ\n\n\nAlcoholDay\n5086\n0.49\n2.91\n3.18\n1.00\n1.00\n2.00\n3.00\n82.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nAlcoholYear\n4078\n0.59\n75.10\n103.03\n0.00\n3.00\n24.00\n104.00\n364.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nSmokeAge\n6920\n0.31\n17.83\n5.33\n6.00\n15.00\n17.00\n19.00\n72.00\n‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\n\nAgeFirstMarij\n7109\n0.29\n17.02\n3.90\n1.00\n15.00\n16.00\n19.00\n48.00\n‚ñÅ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\nAgeRegMarij\n8634\n0.14\n17.69\n4.81\n5.00\n15.00\n17.00\n19.00\n52.00\n‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ\n\n\nSexAge\n4460\n0.55\n17.43\n3.72\n9.00\n15.00\n17.00\n19.00\n50.00\n‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n\n\nSexNumPartnLife\n4275\n0.57\n15.09\n57.85\n0.00\n2.00\n5.00\n12.00\n2000.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nSexNumPartYear\n5072\n0.49\n1.34\n2.78\n0.00\n1.00\n1.00\n1.00\n69.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\n\nTry help(\"NHANES\") in your Console.\n\nThis is survey data collected by the US National Center for Health Statistics (NCHS) which has conducted a series of health and nutrition surveys since the early 1960‚Äôs. Since 1999 approximately 5,000 individuals of all ages are interviewed in their homes every year and complete the health examination component of the survey. The health examination is conducted in a mobile examination centre (MEC).\n\nThe dataset is described as: A data frame with 100000 observations on 76 variables. Some of these are:\n- Race1 and Race2: factors with 5 and 6 levels respectively\n- Education a factor with 5 levels\n- HHIncomeMid Total annual gross income for the household in US dollars.\n- Age\n- BMI: Body mass index (weight/height2 in kg/m2)\n- Height: Standing height in cm.\n- Weight: Weight in kg &gt; &gt; - Testosterone: Testosterone total (ng/dL) - PhysActiveDays: Number of days in a typical week that participant does moderate or vigorous-intensity activity.\n- CompHrsDay: Number of hours per day on average participant used a computer or gaming device over the past 30 days.\n\n\n\n\n\n\nMissing Data\n\n\n\nWhy do so many of the variables have missing entries? What could be your guess about the Experiment/Survey`?\n\n\nLet us make some counts of the data, since we have so many factors:\n\nNHANES %&gt;% count(Gender)\n\n\n  \n\n\nNHANES %&gt;% count(Race1)\n\n\n  \n\n\nNHANES %&gt;% count(Race3)\n\n\n  \n\n\nNHANES %&gt;% count(Education)\n\n\n  \n\n\nNHANES %&gt;% count(MaritalStatus)\n\n\n  \n\n\n\nThere is a good mix of factors and counts.\nNow we articulate our Research Questions:\n\n\n\n\n\n\nResearch Questions\n\n\n\n\nDoes Testosterone have a relationship with parameters such as BMI, Weight, Height, PhysActiveDays CompHrsDay and Age?\nDoes HHIncomeMid have a relationship with these same parameters? And with Gender?\nAre there any other pairwise correlations that we should note? (This is especially useful in choosing independent variables for multiple regression)\n\n\n\n( Yes we are concerned with men more than with the women, sadly.)\n\n Correlations and Plots\n\nGGally::ggpairs(NHANES, \n                # Choose the variables we want to plot for\n                columns = c(\"HHIncomeMid\", \"Weight\", \"Height\", \n                            \"BMI\", \"Gender\"), \n                \n                # LISTs of graphs needed at different locations\n                # For different combinations of variables \n                diag = list(continuous = \"barDiag\"),\n                lower = list(continuous = wrap(\"smooth\", alpha = 0.01)),\n                upper = list(continuous = \"cor\"),\n                \n                switch = \"both\", # axis labels in more traditional locations\n                progress = FALSE ) + # No compute progress bars needed\n  theme_bw()\n\n\n\n\n\n\n\nWe see that HHIncomeMid is Quantitative, discrete valued variable, since it is based on a set of median incomes for different ranges of income. BMI, Weight, Height are continuous Quant variables.\nHHIncomeMid also seems to be relatively unaffected by Weight; And is only mildly correlated with Height and BMI, as seen both by the correlation score magnitudes and the slopes of the trend lines.\nThere is a difference in the median income by Gender, but we will defer that kind of test for later, when we do Statistical Inference.\nUnsurprisingly, BMI and Weight have a strong relationship, as do Height and Weight; the latter is of course non-linear, since the Height levels off at a point.\n\nGGally::ggpairs(NHANES, \n                columns = c(\"Testosterone\", \"Weight\", \"Height\", \"BMI\"), \n                \n                diag = list(continuous = \"barDiag\"),\n                lower = list(continuous = wrap(\"smooth\", alpha = 0.01)),\n                upper = list(continuous = \"cor\"),\n                \n                switch = \"both\",\n                progress = FALSE ) +\n  theme_bw()\n\n\n\n\n\n\n\nIt is clear that Testosterone has strong relationships with Height and Weight but not so much with BMI.\n\n Visualizing Uncertainty in Correlation Estimates\nSince the pairs plot is fairly clear for both target variables, let us head to visualizing the significance and uncertainty in the correlation estimates.\n\nHHIncome_corrs &lt;- NHANES %&gt;% \n  select(where(is.numeric)) %&gt;% \n  \n  # leave off height to get all the remaining ones\n  select(- HHIncomeMid) %&gt;%  \n  \n  # perform a cor.test for all variables against height\n  purrr::map(.x = .,\n             .f = \\(x) cor.test(x, NHANES$HHIncomeMid)) %&gt;%\n  \n  # tidy up the cor.test outputs into a tidy data frame\n  map_dfr(broom::tidy, .id = \"predictor\") \n\nHHIncome_corrs\n\n\n  \n\n\nHHIncome_corrs %&gt;% \n  \n  # Reference line at zero correlation score\n  gf_hline(yintercept = 0, color = \"grey\", linewidth = 2) %&gt;% \n  \n  # arrange the predictors in order of their correlation scores\n  # with the target variable (`height`)\n  # Add errorbars to show uncertainty ranges / confidence intervals\n  # Use errorbar width and linewidth fo emphasis\n  gf_errorbar(conf.high + conf.low ~ reorder(predictor, estimate),\n              color = ~ estimate,\n              width = 0.2,\n              linewidth = ~ -log10(p.value + 0.001)) %&gt;% \n  \n  # All correlation estimates as points\n  gf_point(estimate ~ reorder(predictor, estimate), \n           color = \"black\") %&gt;% \n  \n  # Themes,Titles, and Scales\n  gf_labs(x = NULL, y = \"Correlations with HouseHold Median Income\", \n          caption = \"Significance = - log10(p.value)\") %&gt;% \n  gf_theme(theme_classic()) %&gt;%\n\n  \n  # Scale for colour\n  gf_refine(guides(linewidth = guide_legend(reverse = TRUE)),\n            scale_colour_distiller(\"Correlation\", type = \"div\", \n                                    palette = \"RdBu\"),\n            \n  # Scale for dumbbells!!\n  scale_linewidth_continuous(\"Significance\", range = c(0.05,2)),\n  \n  theme(axis.text.y = element_text(size = 6, hjust = 1)),\n  coord_flip()) \n\n\n\n\n\n\n\nIf we select just the variables from our Research Question:\n\nHHIncome_corrs_select &lt;- NHANES %&gt;% \n  select(Height, Weight, BMI) %&gt;% # Only change is here!\n  \n  # leave off height to get all the remaining ones\n  #select(- HHIncomeMid) %&gt;%  \n  \n  # perform a cor.test for all variables against height\n  purrr::map(.x = .,\n             .f = \\(x) cor.test(x, NHANES$HHIncomeMid)) %&gt;%\n  \n  # tidy up the cor.test outputs into a tidy data frame\n  map_dfr(broom::tidy, .id = \"predictor\") \n\nHHIncome_corrs_select\n\n\n  \n\n\nHHIncome_corrs_select %&gt;% \n  \n  # arrange the predictors in order of their correlation scores\n  # with the target variable (`height`)\n  # Add errorbars to show uncertainty ranges / confidence intervals\n  # Use errorbar width and linewidth fo emphasis\n  gf_errorbar(conf.high + conf.low ~ reorder(predictor, estimate),\n              color = ~ estimate,\n              width = 0.2,\n              linewidth = ~ -log10(p.value + 0.000001)) %&gt;% \n  \n  # All correlation estimates as points\n  gf_point(estimate ~ reorder(predictor, estimate), \n           color = \"black\") %&gt;% \n  \n  # Reference line at zero correlation score\n  gf_hline(yintercept = 0, color = \"grey\", linewidth = 2) %&gt;% \n  \n  # Themes,Titles, and Scales\n  gf_labs(x = NULL, y = \"Correlations with HouseHold Median Income\", \n          caption = \"Significance = - log10(p.value + 0.000001)\") %&gt;% \n  \n  gf_theme(theme_classic()) %&gt;%\n\n  \n  # Scale for colour\n  gf_refine(guides(linewidth = guide_legend(reverse = TRUE)),\n            scale_colour_distiller(\"Correlation\", type = \"div\", \n                                    palette = \"RdBu\"),\n            \n  # Scale for dumbbells!!\n  scale_linewidth_continuous(\"Significance\", range = c(0.05,2)),\n  \n  theme(axis.text.y = element_text(size = 8, hjust = 1)),\n  coord_flip()) \n\n\n\n\n\n\n\nSo we might say taller people make more money? And fatter people make slightly less money? Well, the magnitude of the correlations (aka effect size) are low so we would not imagine this to be a hypothesis that we can defend.\nLet us look at the Testosterone variable: trying all variables shows some paucity of observations ( due to missing data), so we will stick with our chosen variables:\n\nTestosterone_corrs &lt;- NHANES %&gt;%\n  select(Height, Weight, BMI) %&gt;%\n  \n  # leave off height to get all the remaining ones\n  #select(- Testosterone) %&gt;%\n  \n  # perform a cor.test for all variables against height\n  purrr::map(.x = .,\n             .f = \\(x) cor.test(x, NHANES$Testosterone)) %&gt;%\n  \n  # tidy up the cor.test outputs into a tidy data frame\n  map_dfr(broom::tidy, .id = \"predictor\")\n\nTestosterone_corrs\n\n\n  \n\n\nTestosterone_corrs %&gt;%\n  \n  # Reference line at zero correlation score\n  gf_hline(yintercept = 0,\n           color = \"grey\",\n           linewidth = 2) %&gt;%\n  \n  # arrange the predictors in order of their correlation scores\n  # with the target variable (`height`)\n  # Add errorbars to show uncertainty ranges / confidence intervals\n  # Use errorbar width and linewidth fo emphasis\n  gf_errorbar(\n    conf.high + conf.low ~ reorder(predictor, estimate),\n    color = ~ estimate,\n    width = 0.2,\n    linewidth = ~ -log10(p.value + 0.000001)\n  ) %&gt;%\n  \n  # All correlation estimates as points\n  gf_point(estimate ~ reorder(predictor, estimate),\n           color = \"black\") %&gt;%\n  \n  \n  # Themes,Titles, and Scales\n  gf_labs(x = NULL, y = \"Correlations with Testosterone Levels\",\n          caption = \"Significance = - log10(p.value + 0.000001)\") %&gt;%\n  \n  gf_theme(theme_classic()) %&gt;%\n  \n  \n  # Scale for colour\n  gf_refine(\n    guides(linewidth = guide_legend(reverse = TRUE)),\n    scale_colour_distiller(\"Correlation\", type = \"div\",\n                           palette = \"RdBu\"),\n    \n    # Scale for dumbbells!!\n    scale_linewidth_continuous(\"Significance\", range = c(0.05, 2)),\n    \n    theme(axis.text.y = element_text(size = 8, hjust = 1)),\n    coord_flip()\n  )"
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#conclusion",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#conclusion",
    "title": "Tutorial on Correlations in R",
    "section": "\n Conclusion",
    "text": "Conclusion\nWe have a decent Correlations related workflow in R:\n\nLoad the dataset\n\ninspect/skim/glimpse the dataset, identify Quant and Qual variables\nIdentify a target variable based on your knowledge of the data, how it was gathered, who gathered it and what was their intent\nDevelop Pair-Wise plots + Correlations using GGally::ggpairs()\n\nDevelop Correlogram corrplot::corrplot\n\nCheck everything with a cor_test: effect size,significance, confidence intervals\nUse purrr + cor.test to plot correlations and confidence intervals for multiple Quant predictor variables against the target variable\nPlot scatter plots using gf_point.\nAdd extra lines using gf_abline() to compare hypotheses that you may have."
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#references",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#references",
    "title": "Tutorial on Correlations in R",
    "section": "\n References",
    "text": "References\n\n\n R Package Citations\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\ncorrplot\n0.92\nWei and Simko (2021)\n\n\nGGally\n2.2.0\nSchloerke et al. (2023)\n\n\nggformula\n0.12.0\nKaplan and Pruim (2023)\n\n\nmosaic\n1.9.0\nPruim, Kaplan, and Horton (2017)\n\n\nmosaicData\n0.20.4\nPruim, Kaplan, and Horton (2023)\n\n\nNHANES\n2.1.0\nPruim (2015)\n\n\nTeachHist\n0.2.1\nLange (2023)\n\n\nTeachingDemos\n2.12\nSnow (2020)\n\n\n\n\n\n\nKaplan, Daniel, and Randall Pruim. 2023. ggformula: Formula Interface to the Grammar of Graphics. https://CRAN.R-project.org/package=ggformula.\n\n\nLange, Carsten. 2023. TeachHist: A Collection of Amended Histograms Designed for Teaching Statistics. https://CRAN.R-project.org/package=TeachHist.\n\n\nPruim, Randall. 2015. NHANES: Data from the US National Health and Nutrition Examination Study. https://CRAN.R-project.org/package=NHANES.\n\n\nPruim, Randall, Daniel T Kaplan, and Nicholas J Horton. 2017. ‚ÄúThe Mosaic Package: Helping Students to ‚ÄòThink with Data‚Äô Using r.‚Äù The R Journal 9 (1): 77‚Äì102. https://journal.r-project.org/archive/2017/RJ-2017-024/index.html.\n\n\nPruim, Randall, Daniel Kaplan, and Nicholas Horton. 2023. mosaicData: Project MOSAIC Data Sets. https://CRAN.R-project.org/package=mosaicData.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2023. GGally: Extension to ‚Äúggplot2‚Äù. https://CRAN.R-project.org/package=GGally.\n\n\nSnow, Greg. 2020. TeachingDemos: Demonstrations for Teaching and Learning. https://CRAN.R-project.org/package=TeachingDemos.\n\n\nWei, Taiyun, and Viliam Simko. 2021. R Package ‚Äúcorrplot‚Äù: Visualization of a Correlation Matrix. https://github.com/taiyun/corrplot."
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#footnotes",
    "href": "content/courses/Analytics/Descriptive/Modules/30-Correlations/files/correlations.html#footnotes",
    "title": "Tutorial on Correlations in R",
    "section": "Footnotes",
    "text": "Footnotes\n\nhttp://euclid.psych.yorku.ca/SCS/Gallery/images/galton-corr.jpg&gt;‚Ü©Ô∏é\nhttps://www.researchgate.net/figure/Galtons-smoothed-correlation-diagram-for-the-data-on-heights-of-parents-and-children_fig15_226400313‚Ü©Ô∏é"
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html",
    "title": "üçï Parts of a Whole",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mosaic)\nlibrary(ggformula)\nlibrary(plotrix) # Fan, Pyramid Chart\nlibrary(ggparliament) # Parliament Chart\nlibrary(ggpol) # Parliament, Arc-Bar and other interesting charts\nlibrary(data.tree) # Many plots related to heirarchical data\n# install.packages(\"waffle\", repos = \"https://cinc.rud.is\")\nlibrary(waffle)\nlibrary(tidygraph) # Trees, Dendros, and Circle Packings\nlibrary(ggraph) # Trees, Dendros, and Circle Packings\nlibrary(echarts4r) # Interactive Charts\n\nlibrary(patchwork) # Arrange your plots",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#setting-up-the-packages",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#setting-up-the-packages",
    "title": "üçï Parts of a Whole",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mosaic)\nlibrary(ggformula)\nlibrary(plotrix) # Fan, Pyramid Chart\nlibrary(ggparliament) # Parliament Chart\nlibrary(ggpol) # Parliament, Arc-Bar and other interesting charts\nlibrary(data.tree) # Many plots related to heirarchical data\n# install.packages(\"waffle\", repos = \"https://cinc.rud.is\")\nlibrary(waffle)\nlibrary(tidygraph) # Trees, Dendros, and Circle Packings\nlibrary(ggraph) # Trees, Dendros, and Circle Packings\nlibrary(echarts4r) # Interactive Charts\n\nlibrary(patchwork) # Arrange your plots",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#what-graphs-will-we-see-today",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#what-graphs-will-we-see-today",
    "title": "üçï Parts of a Whole",
    "section": "\n What Graphs will we see today?",
    "text": "What Graphs will we see today?\nThere are a good few charts available to depict things that constitute other bigger things. We will discuss a few of these: Pie, Fan, and Donuts; Waffle and Parliament charts; Trees, Dendrograms, and Circle Packings. (The last three visuals we will explore along with network diagrams in a later module.)",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#pies-and-fans",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#pies-and-fans",
    "title": "üçï Parts of a Whole",
    "section": "\n Pies and Fans",
    "text": "Pies and Fans\nSo let us start with ‚Äúeating humble pie‚Äù: discussing a Pie chart first.\nA pie chart is a circle divided into sectors that each represent a proportion of the whole. It is often used to show percentage, where the sum of the sectors equals 100%.\nThe problem is that humans are pretty bad at reading angles. This ubiquitous chart is much vilified in the industry and bar charts that we have seen earlier, are viewed as better options. On the other hand, pie charts are ubiquitous in business circles, and are very much accepted! Do also read this spirited defense of pie charts here. https://speakingppt.com/why-tufte-is-flat-out-wrong-about-pie-charts/\nAnd we will also see that there is an attractive, and similar-looking alternative, called a fan chart which we will explore here.\n\n\nUsing Base R\nUsing ggformula\nUsing echarts4r\n\n\n\nBase R has a simple pie command that does the job. Let‚Äôs create some toy data first:\npie_data &lt;- tibble(\n  sales = c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12), \n  \n  # Labels MUST be character entries for `pie` to work\n  labels = c(\"Blueberry\",\"Cherry\",\"Apple\",\"Boston Cream\",\n             \"Other\",\"Vanilla Cream\")\n  )\npie_data\npie(\n  x = pie_data$sales,\n  labels = pie_data$labels, # Character Vector is a MUST\n\n  # Pie is within a square of 1 X 1 units\n  # Reduce radius if needed to see labels properly\n  radius = 0.95,\n  \n  init.angle = 90, # First slice starts at 12 o'clock position\n  \n  # Change the default colours. Comment this and see what happens. \n  col =  grDevices::hcl.colors(palette = \"Plasma\", n = 6)\n  )\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nWe create a bar chart or a column chart as appropriate, with bars filled by category. The width parameter is set to 1 so that the bars touch. The bars have a fixed width along the x-axis; the height of the bar varies based on the number we wish to show. Then the coord_polar(theta = \"y\") converts the bar plot into a pie.\n# Using gf_col since we have a count/value column already\npie_data %&gt;%\n  gf_col(sales ~ 1, fill = ~ labels, width = 1) \npie_data %&gt;%\n  gf_col(sales ~ 1, fill = ~ labels, width = 1)  %&gt;%\n  gf_refine(coord_polar(theta = \"y\"))\n# Using gf_bar since we don't have ready made counts\ngf_bar(data = mpg,\n       ~ 1,\n       fill = ~ drv,\n       color = \"black\", # border for the bars/slices\n       width =  1)\ngf_bar(data = mpg,\n       ~ 0.5,\n       fill = ~ drv,\n       color = \"black\", # border for the bars/slices\n       width =  1) %&gt;%\n  gf_theme(theme_minimal()) %&gt;%\n  gf_theme(theme(axis.line.y = element_blank(),\n                 axis.text.y = element_blank(),\n                 axis.title.y = element_blank())) %&gt;%\n  gf_refine(coord_polar(theta = \"y\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is a basic interactive pie chart withecharts4r:\n\npie_data &lt;- tibble(\n  sales = c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12), \n\n  labels = c(\"Blueberry\",\"Cherry\",\"Apple\",\"Boston Cream\",\"Other\",\n             \"Vanilla Cream\"))\npie_data %&gt;% \n  e_charts(x = labels) %&gt;% \n  e_pie(serie = sales, clockwise = TRUE, \n        startAngle = 90) %&gt;% \n  e_legend(list(orient = \"vertical\",\n                      left = \"right\")) %&gt;% \n  e_tooltip()\n\n\n\n\n\nWe can add more bells and whistles to the humble-pie chart, and make a Nightingale rosechart out of it:\npie_data &lt;- tibble(\n  sales = c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12), \n\n  labels = c(\"Blueberry\",\"Cherry\",\"Apple\",\"Boston Cream\",\"Other\",\n             \"Vanilla Cream\"))\npie_data %&gt;% \n  e_charts(x = labels) %&gt;% \n  e_pie(serie = sales, clockwise = TRUE, \n        startAngle = 90, \n        roseType = \"area\") %&gt;% # try \"radius\"\n  \n  # Lets move the legend\n  e_legend(left = \"right\", orient = \"vertical\") %&gt;% \n  e_tooltip()\npie_data %&gt;% \n  e_charts(x = labels) %&gt;% \n  e_pie(serie = sales, clockwise = TRUE, \n        startAngle = 90, \n        roseType = \"radius\") %&gt;% \n  \n  # Lets move the legend\n  e_legend(left = \"right\", orient = \"vertical\") %&gt;% \n  e_tooltip()\n\n\n\n\n\n\n\n\n\n\n\n\nFor more information and customization look at https://echarts.apache.org/en/option.html#series-pie\n\n\n\nThe fan Plot\nThe fan plot (from the plotrix package) displays numerical values as arcs of overlapping sectors. This allows for more effective comparison:\n\nplotrix::fan.plot(\n  x = pie_data$sales,\n  labels = pie_data$labels,\n  \n  col = grDevices::hcl.colors(palette = \"Plasma\", n = 6),\n  shrink = 0.03,\n  # How much to shrink each successive sector\n\n  label.radius = 1.15,\n  main = \"Fan Plot of Ice Cream Flavours\",\n  # ticks = 360,\n  # if we want tick marks on the circumference\n  \n  max.span = pi\n)\n\n\n\n\n\n\n\nThere is no fan plot possible with echarts4r, as far as I know.\nThe Donut Chart\nThe donut chart suffers from the same defects as the pie, so should be used with discretion. The donut chart is essentially a gf_rect from ggformula, plotted on a polar coordinate set of of axes:\n\n\nUsing ggformula\nUsing echarts4r\n\n\n\nLet us make some toy data:\n# Data\ndf &lt;- tibble(group = LETTERS[1:3],\n                 value = c(25, 20, 35))\n\ndf &lt;-\n  df %&gt;% \n  dplyr::mutate(fraction = value / sum(value), # percentages\n    ymax = cumsum(fraction), # cumulative percentages\n    ymin = lag(ymax, 1, default = 0),\n    # bottom edge of each\n    label = paste0(group, \"\\n value: \", value),\n    labelPosition = (ymax + ymin) / 2 # labels midway on arcs\n  )\n\ndf\ndf %&gt;%  \n  # gf_rect() formula: ymin + ymax ~ xmin + xmax\n  # Bars with varying thickness (y) proportional to data\n  # Fixed length x (2 to 4)\n  gf_rect(ymin + ymax ~ 2 + 4,\n          fill = ~ group, colour = \"black\") %&gt;%\n  \n  gf_label(labelPosition ~ 3.5, \n           label = ~ label,\n           size = 4) %&gt;%\n\n# When switching to polar coords:\n# x maps to radius\n# y maps to angle theta\n# so we create a \"hole\" in the radius, in x \n  gf_refine(coord_polar(theta = \"y\", \n                        direction = 1)) %&gt;% \n            # Up to here will give us a pie chart\n  \n  # Now to create the hole\n  # try to play with the \"0\"\n  # Recall x = [2,4]\n  gf_refine(xlim(c(-2, 5))) %&gt;% \n\n  \n  gf_theme(theme = theme_void()) %&gt;% \n  gf_theme(legend.position = \"none\")\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nThe donut chart is simply a variant of the pie chart in echarts4r:\ndf &lt;- tibble(group = LETTERS[1:3],\n                 value = c(25, 20, 35))\n\ndf &lt;-\n  df %&gt;% \n  dplyr::mutate(fraction = value / sum(value), # percentages\n    ymax = cumsum(fraction), # cumulative percentages\n    ymin = lag(ymax, 1, default = 0),\n    # bottom edge of each\n    label = paste0(group, \"\\n value: \", value),\n    labelPosition = (ymax + ymin) / 2 # labels midway on arcs\n  )\ndf\ndf %&gt;% \n  e_charts(x = group, width = 400) %&gt;% \n  e_pie(serie = value, \n        clockwise = TRUE, \n        startAngle = 90,\n        \n        radius = c(\"50%\", \"70%\")\n        ) %&gt;% \n  \n  e_legend(left = \"right\", orient = \"vertical\") %&gt;% \n  e_tooltip()",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#waffle-charts",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#waffle-charts",
    "title": "üçï Parts of a Whole",
    "section": "\n Waffle Charts",
    "text": "Waffle Charts\nWaffle charts are often called ‚Äúsquare pie charts‚Äù !\nHere we will need to step outside of ggformula and get into ggplot itself momentarily. (Always remember that ggformula is a simplified and intuitive method that runs on top of ggplot.) We will use the waffle package.\n\n# install.packages(\"waffle\", repos = \"https://cinc.rud.is\")\nlibrary(waffle)\n\n# Data\ndf &lt;- tibble(group = LETTERS[1:3],\n                 value = c(25, 20, 35))\ndf\n\n\n  \n\n\n# Waffle plot\n# Using ggplot, sadly not yet ggformula\nggplot(df, aes(fill = group, values = value)) +\n  geom_waffle(\n    n_rows = 8,\n    size = 0.33,\n    colour = \"white\",\n    na.rm = TRUE\n  ) +\n  scale_fill_manual(\n    name = NULL,\n    values = c(\"#BA182A\", \"#FF8288\", \"#FFDBDD\"),\n    labels = c(\"A\", \"B\", \"C\")\n  ) +\n  coord_equal() +\n  theme_void()",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#parliament-charts",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#parliament-charts",
    "title": "üçï Parts of a Whole",
    "section": "\n Parliament Charts",
    "text": "Parliament Charts\nThe package ggpol offers an interesting visualization in the shape of a array of ‚Äúseats‚Äù in a parliament. (There is also a package called ggparliament which in my opinion is a bit cumbersome, having a two step procedure to convert data into ‚Äúparliament form‚Äù etc. )\n\ndf &lt;- tibble(group = LETTERS[1:3],\n                 value = c(25, 20, 35))\n\n# Parliament Plot\nggplot(df) +\n  ggpol::geom_parliament(aes(seats = value, \n                             fill = group),\n                         r0 = 2, # inner radius\n                         r1 = 4 # Outer radius\n  ) + \n  scale_fill_manual(name = NULL,\n                    values = c(\"#BA182A\", \"#FF8288\", \"#FFDBDD\"),\n                    labels = c(\"A\", \"B\", \"C\")) +\n  coord_equal() +\n  theme_void()",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#trees-dendrograms-and-circle-packings",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#trees-dendrograms-and-circle-packings",
    "title": "üçï Parts of a Whole",
    "section": "Trees, Dendrograms, and Circle Packings",
    "text": "Trees, Dendrograms, and Circle Packings\nThere are still more esoteric plots to explore, if you are hell-bent on startling people ! There is an R package called ggraph, that can do these charts, and many more:\n\nggraph is an extension of ggplot2 aimed at supporting relational data structures such as networks, graphs, and trees. While it builds upon the foundation of ggplot2 and its API it comes with its own self-contained set of geoms, facets, etc., as well as adding the concept of layouts to the grammar.\n\nWe will explore these charts when we examine network diagrams. For now, we can quickly see what these diagrams look like. Although the R-code is visible to you, it may not make sense at the moment!\n\n Dendrograms\nFrom the R Graph Gallery Website :\n\nDendrograms can be built from:\n\nHierarchical dataset: think about a CEO managing team leads managing employees and so on.\nClustering result: clustering divides a set of individuals in group according to their similarity. Its result can be visualized as a tree.\n\n\n\n# create an edge list data frame giving the hierarchical structure of your individuals\nd1 &lt;- tibble(from = \"origin\", to = paste(\"group\", seq(1,5), sep = \"\"))\nd2 &lt;- tibble(from = rep(d1$to, each=5), to = paste(\"subgroup\", seq(1,25), sep=\"_\"))\nedges &lt;- rbind(d1, d2)\nedges\n\n\n  \n\n\n# Create a graph object \nmygraph1 &lt;- tidygraph::as_tbl_graph( edges )\n \n# Basic tree\np1 &lt;- ggraph(mygraph1, layout = 'dendrogram', circular = TRUE) + \n  geom_edge_diagonal() +\n  geom_node_point() +\n  theme_void()\n\n\n# create a data frame \ndata &lt;- tibble(\n  level1=\"CEO\",\n  level2=c( rep(\"boss1\",4), rep(\"boss2\",4)),\n  level3=paste0(\"mister_\", letters[1:8])\n)\n \n# transform it to a edge list!\nedges_level1_2 &lt;- data %&gt;% \n  select(level1, level2) %&gt;% unique %&gt;% rename(from=level1, to=level2)\n\nedges_level2_3 &lt;- data %&gt;% \n  select(level2, level3) %&gt;% unique %&gt;% rename(from=level2, to=level3)\n\nedge_list &lt;- rbind(edges_level1_2, edges_level2_3)\nedge_list\n\n\n  \n\n\n# Now we can plot that\nmygraph2 &lt;- as_tbl_graph(edge_list)\np2 &lt;- ggraph(mygraph2, layout = 'dendrogram', circular = FALSE) + \n  geom_edge_diagonal() +\n  geom_node_point() +\n  theme_void()\n\n\np1 + p2 + theme(aspect.ratio = 1)\n\n\n\n\n\n\n\nCircle Packing\n\nlibrary(tidygraph)\nlibrary(ggraph)\ngraph &lt;- tbl_graph(flare$vertices, flare$edges)\nset.seed(1)\nggraph(graph, 'circlepack', weight = size) + \n  geom_node_circle(aes(fill = as_factor(depth)), size = 0.25, n = 50) + \n  coord_fixed() +\n  scale_fill_discrete(name = \"Depth\") +\n  theme_void()",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#your-turn",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#your-turn",
    "title": "üçï Parts of a Whole",
    "section": "\n Your Turn",
    "text": "Your Turn\n\nUse the penguins dataset from the palmerpenguins package and plot pies, fans, and donuts as appropriate.\nLook at the whigs and highschool datasets in the package ggraph. Plot Pies, Fans and if you are feeling confident, Trees, Dendrograms, and Circle Packings as appropriate for these.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#references",
    "href": "content/courses/Analytics/Descriptive/Modules/60-PartWhole/part-whole.html#references",
    "title": "üçï Parts of a Whole",
    "section": "\n References",
    "text": "References\n\nIaroslava.2020. A Parliament Diagram in R, https://datavizstory.com/a-parliament-diagram-in-r/\nVenn Diagrams in R, Venn diagram in ggplot2 | R CHARTS (r-charts.com)\nGenerate icon-array charts without code! https://iconarray.com\n\n\n R Package Citations\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\ndata.tree\n1.1.0\nGlur (2023)\n\n\necharts4r\n0.4.5\nCoene (2023)\n\n\nggparliament\n2.0.0\nHickman, Meers, and Leeper (2018)\n\n\nggpol\n0.0.7\nTiedemann (2020)\n\n\nggraph\n2.2.0\nPedersen (2024a)\n\n\nplotrix\n3.8.4\nJ (2006)\n\n\ntidygraph\n1.3.1\nPedersen (2024b)\n\n\nwaffle\n1.0.2\nRudis and Gandy (2023)\n\n\n\n\n\n\nCoene, John. 2023. Echarts4r: Create Interactive Graphs with ‚ÄúEcharts JavaScript‚Äù Version 5. https://CRAN.R-project.org/package=echarts4r.\n\n\nGlur, Christoph. 2023. data.tree: General Purpose Hierarchical Data Structure. https://CRAN.R-project.org/package=data.tree.\n\n\nHickman, Robert, Zoe Meers, and Thomas J. Leeper. 2018. ggparliament: Parliament Plots. https://CRAN.R-project.org/package=ggparliament.\n\n\nJ, Lemon. 2006. ‚ÄúPlotrix: A Package in the Red Light District of r.‚Äù R-News 6 (4): 8‚Äì12.\n\n\nPedersen, Thomas Lin. 2024a. ggraph: An Implementation of Grammar of Graphics for Graphs and Networks. https://CRAN.R-project.org/package=ggraph.\n\n\n‚Äî‚Äî‚Äî. 2024b. tidygraph: A Tidy API for Graph Manipulation. https://CRAN.R-project.org/package=tidygraph.\n\n\nRudis, Bob, and Dave Gandy. 2023. waffle: Create Waffle Chart Visualizations. https://CRAN.R-project.org/package=waffle.\n\n\nTiedemann, Frederik. 2020. ggpol: Visualizing Social Science Data with ‚Äúggplot2‚Äù. https://CRAN.R-project.org/package=ggpol.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üçï Parts of a Whole"
    ]
  },
  {
    "objectID": "content/work-related/DSU/A1.html#instructions",
    "href": "content/work-related/DSU/A1.html#instructions",
    "title": "A1",
    "section": "Instructions",
    "text": "Instructions\n\nEach Question in this Assignment is a chart.\nEach Chart is accompanied by a set of short questions.\nYour responses to these can be R-code, or text.\nPlease number your answers as 1.a, 1.b, 1.c‚Ä¶..2.a, 2.b‚Ä¶on your Answer Sheet.\nAll aboard? Let‚Äôs go!"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-1",
    "href": "content/work-related/DSU/A1.html#question-1",
    "title": "A1",
    "section": "Question 1",
    "text": "Question 1\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-1-1",
    "href": "content/work-related/DSU/A1.html#question-1-1",
    "title": "A1",
    "section": "Question 1",
    "text": "Question 1\n\n\n\nWhat is the ggplot geometry used in this graph?\nWhat do the colours mean?"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-2",
    "href": "content/work-related/DSU/A1.html#question-2",
    "title": "A1",
    "section": "Question 2",
    "text": "Question 2\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-3",
    "href": "content/work-related/DSU/A1.html#question-3",
    "title": "A1",
    "section": "Question 3",
    "text": "Question 3\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-4",
    "href": "content/work-related/DSU/A1.html#question-4",
    "title": "A1",
    "section": "Question 4",
    "text": "Question 4\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-5",
    "href": "content/work-related/DSU/A1.html#question-5",
    "title": "A1",
    "section": "Question 5",
    "text": "Question 5\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-6",
    "href": "content/work-related/DSU/A1.html#question-6",
    "title": "A1",
    "section": "Question 6",
    "text": "Question 6\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-7",
    "href": "content/work-related/DSU/A1.html#question-7",
    "title": "A1",
    "section": "Question 7",
    "text": "Question 7\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-8",
    "href": "content/work-related/DSU/A1.html#question-8",
    "title": "A1",
    "section": "Question 8",
    "text": "Question 8\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-9",
    "href": "content/work-related/DSU/A1.html#question-9",
    "title": "A1",
    "section": "Question 9",
    "text": "Question 9\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-10",
    "href": "content/work-related/DSU/A1.html#question-10",
    "title": "A1",
    "section": "Question 10",
    "text": "Question 10\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-11",
    "href": "content/work-related/DSU/A1.html#question-11",
    "title": "A1",
    "section": "Question 11",
    "text": "Question 11\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-12",
    "href": "content/work-related/DSU/A1.html#question-12",
    "title": "A1",
    "section": "Question 12",
    "text": "Question 12\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-13",
    "href": "content/work-related/DSU/A1.html#question-13",
    "title": "A1",
    "section": "Question 13",
    "text": "Question 13\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-14",
    "href": "content/work-related/DSU/A1.html#question-14",
    "title": "A1",
    "section": "Question 14",
    "text": "Question 14\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)"
  },
  {
    "objectID": "content/work-related/DSU/A1.html#question-15",
    "href": "content/work-related/DSU/A1.html#question-15",
    "title": "A1",
    "section": "Question 15",
    "text": "Question 15\n\n\n\nList the variables are used in this graph?\nIdentify their types. (Quantitative, Qualitative)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment#1-IA-EMBA-T4-2023, Arvind Venkatadri"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Applied Metaphors: Learning TRIZ, Complexity, Data/Stats/ML using Metaphors",
    "section": "",
    "text": "Preparatory Work to moving my full website to Quarto!"
  },
  {
    "objectID": "readme.html#get-started-with-quarto",
    "href": "readme.html#get-started-with-quarto",
    "title": "Applied Metaphors: Learning TRIZ, Complexity, Data/Stats/ML using Metaphors",
    "section": "",
    "text": "Preparatory Work to moving my full website to Quarto!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I‚Äôm Arvind Venkatadri.",
    "section": "",
    "text": "Hi, I‚Äôm Arvind Venkatadri.\nI‚Äôm an Adjunct Professor at the School of Commerce and Management Studies, DSU, and an external Faculty Member at the Srishti Manipal Institute of Art, Design, and Technology (SMI), in Bangalore, INDIA. I am passionate about working on R, Data Visualization, Complexity Science, and Creative Thinking and Problem Solving with TRIZ. On this website, I share my course materials and methods. I also blog about TRIZ and Data Science on occasion.\nTo get started, you can check out my courses on this website.\nMy other teaching websites are:\n- Teaching R to Artists and Designers\n- Foundation Courses at Srishti\n\nMy student portfolios are here:\nhttps://we-r-us.netlify.app/portfolio/\nhttps://form-and-structure.netlify.app/portfolio/\n\nYou can find me on Twitter, or GitHub, and on LinkedIn! Feel free to reach out to me via mail too!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/courses/Analytics/listing.html",
    "href": "content/courses/Analytics/listing.html",
    "title": "Data Analytics",
    "section": "",
    "text": "This Course takes Business Practitioners on a journey of Business Analytics: using data to derive insights, make predictions, and decide on plans of action that can be communicated and actualized in a Business context.\n\n‚ÄúBusiness analytics, or simply analytics, is the use of data, information technology, statistical analysis, quantitative methods, and mathematical or computer-based models to help managers gain improved insight about their business operations and make better, fact-based decisions. Business analytics is‚Äùa process of transforming data into actions through analysis and insights in the context of organizational decision making and problem solving.‚Äù\n\n-Libertore and Luo, 2010\n\n\n The Course starts with Descriptive Analytics: Datasets from various domains of Business enterprise and activity are introduced. The datasets are motivated from the point of view of the types of information they contain: students will relate the Data Variables (Qualitative and Quantitative) to various types of Data/Information Visualizations.\nStatistical Concepts such as Sampling, Hypothesis Tests, Simulation / Modelling, and Uncertainty will be introduced.\nPredictive Analytics will take us into looking at Data and training standard ML algorithms to make predictions with new Data. Regression, Clustering, and Classification will be covered.\nPrescriptive Analytics will deal with coming to terms with the uncertainty in Predictions, and using tools such as both ML, Linear/non-Linear Programming, and Decision-Making to make Business Decisions, with an assessment of the Risks involved.\nThe Course will culminate in a full Business Analytics Workflow that includes Data Gathering and Cleaning, Descriptive and Predictive Analytics, Prescriptive Analytics and Decision Making, and Communication resulting in a publication-worthy documents.(HTML / PDF/ Word)",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#abstract",
    "href": "content/courses/Analytics/listing.html#abstract",
    "title": "Data Analytics",
    "section": "",
    "text": "This Course takes Business Practitioners on a journey of Business Analytics: using data to derive insights, make predictions, and decide on plans of action that can be communicated and actualized in a Business context.\n\n‚ÄúBusiness analytics, or simply analytics, is the use of data, information technology, statistical analysis, quantitative methods, and mathematical or computer-based models to help managers gain improved insight about their business operations and make better, fact-based decisions. Business analytics is‚Äùa process of transforming data into actions through analysis and insights in the context of organizational decision making and problem solving.‚Äù\n\n-Libertore and Luo, 2010\n\n\n The Course starts with Descriptive Analytics: Datasets from various domains of Business enterprise and activity are introduced. The datasets are motivated from the point of view of the types of information they contain: students will relate the Data Variables (Qualitative and Quantitative) to various types of Data/Information Visualizations.\nStatistical Concepts such as Sampling, Hypothesis Tests, Simulation / Modelling, and Uncertainty will be introduced.\nPredictive Analytics will take us into looking at Data and training standard ML algorithms to make predictions with new Data. Regression, Clustering, and Classification will be covered.\nPrescriptive Analytics will deal with coming to terms with the uncertainty in Predictions, and using tools such as both ML, Linear/non-Linear Programming, and Decision-Making to make Business Decisions, with an assessment of the Risks involved.\nThe Course will culminate in a full Business Analytics Workflow that includes Data Gathering and Cleaning, Descriptive and Predictive Analytics, Prescriptive Analytics and Decision Making, and Communication resulting in a publication-worthy documents.(HTML / PDF/ Word)",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#what-you-will-learn",
    "href": "content/courses/Analytics/listing.html#what-you-will-learn",
    "title": "Data Analytics",
    "section": "What you will learn",
    "text": "What you will learn\n\nData Basics: What does data look like and why should we care?\nRapidly and intuitively creating Graphs and Data Visualizations to explore data for insights\nUse Statistical Tests, Procedures, Models, and Simulations and to answer Business Questions\nUsing ML algorithms such Regression, Classification, and Clustering to develop Business Insights\nUse Linear Programming to make Business Decisions\nCreate crisp and readable Reports that can be shared in a Business Context",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#texts",
    "href": "content/courses/Analytics/listing.html#texts",
    "title": "Data Analytics",
    "section": "Texts",
    "text": "Texts\n\nJames R Evans, Business Analytics: Methods, Models, and Decisions, Pearson Education, 2021.",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#references",
    "href": "content/courses/Analytics/listing.html#references",
    "title": "Data Analytics",
    "section": "References",
    "text": "References\n\nRobert Kabacoff. Modern Data Visualization with R. https://rkabacoff.github.io/datavis/. Available free Online.\nJack Dougherty and Ilya Ilyankou, Hands-On Data Visualization: Interactive Storytelling from Spreadsheets to Code, https://handsondataviz.org/. Available free Online.\nClaus O. Wilke, Fundamentals of Data Visualization, https://clauswilke.com/dataviz/. Available free Online.\nJonathan Schwabish, Better Data Visualizations: A Guide for Scholars, Researchers, and Wonks, Columbia University Press, 2021.\nAlberto Cairo, The Functional Art:An introduction to information graphics and visualization, New Riders. 2013. ISBN-9780133041361.\nCole Nussbaumer Knaflic, Storytelling With Data: A Data Visualization Guide for Business Professionals, Wiley 2015. ISBN-9781119002253.\nJudd, C.M., McClelland, G.H., & Ryan, C.S. (2017). Data Analysis: A Model Comparison Approach To Regression, ANOVA, and Beyond, Third Edition (3rd ed.). Routledge. https://doi.org/10.4324/9781315744131\nThomas Maydon, The 4 Types of Data Analytics, https://www.kdnuggets.com/2017/07/4-types-data-analytics.html\nDimitris Bertsimas, Robert Freund, Data, Models, and Decisions: the Fundamentals of Management Science, Dynamic Ideas Press, 2004.\nCliff T. Ragsdale, Spreadsheet Modeling & Decision Analysis: A Practical Introduction to Management Science, South Western, Cengage Learning, Mason, OH, 2012.",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#pedagogical-notes",
    "href": "content/courses/Analytics/listing.html#pedagogical-notes",
    "title": "Data Analytics",
    "section": "Pedagogical Notes",
    "text": "Pedagogical Notes",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#our-tools",
    "href": "content/courses/Analytics/listing.html#our-tools",
    "title": "Data Analytics",
    "section": "Our Tools",
    "text": "Our Tools\nThis is eventually meant to be a three-in-one course, during which we will gain exposure to the following free and open source tools:\n\nR https://cran.r-project.org/ and RStudio https://posit.co/\nR is a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques: linear and nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc. RStudio is an integrated development environment (IDE) for R and Python.\nOrange Data Mining https://orangedatamining.com/\nOrange is a FOSS visual point-and-click software for Data Mining and ML, developed at the University of Slovenia, Ljubljana.\n\n\n\n\nRadiant ‚Äì Business analytics using R and Shiny https://radiant-rstats.github.io/docs/index.html\n\nRadiant is a FOSS platform-independent browser-based interface for business analytics in R, developed at the University of San Diego. The application is based on the Shiny package and can be run using R, or in your browser with no installation required. The tool automatically installs a version of R and adds a Shiny-based GUI that removes the need to write R-code. Radiant can also be installed on top of an existing installation of R and invoked from within RStudio.",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/listing.html#modules",
    "href": "content/courses/Analytics/listing.html#modules",
    "title": "Data Analytics",
    "section": "Modules",
    "text": "Modules",
    "crumbs": [
      "Teaching",
      "Data Analytics"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Inference/listing.html",
    "href": "content/courses/Analytics/Inference/listing.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "Important\n\n\n\nStatistical inference is the process of drawing conclusions about the entire population based on the information in a sample.\n\n\nIn this Section we will examine samples from populations and find procedures for estimating parameters such as means and sd. We will also devise procedures for comparing means and variances across more than one population. The conditions that make these procedures possible and accurate will also be studied and we will find alternative methods when those assumptions breakdown.\nBased on our ideas of data and types of variables, here is a table of what we may infer, based on the underlying data:\n\nData Types and Inference\n\n\n\n\n\n\n\n\nVariable(s)\nEstimating What?\nPopulation Parameter\nSample Statistic\n\n\n\n\nSingle Qual variable\nProportion\np\n\\(\\hat{p}\\)\n\n\nSingle Quant variable\nMean\n\\(\\mu\\)\n\\(\\bar{x}\\)\n\n\nTwo Qual Variables\nDifference in Proportions\n\\(p_1 -p_2\\)\n\\(\\hat{p_1} - \\hat{p_2}\\)\n\n\nOne Qual, one Quant\nDifference in Means\n\\(\\mu_1 - \\mu_2\\)\n\\(\\bar{x_1}-\\bar{x_2}\\)\n\n\nTwo Quant variables\nCorrelation\n\\(\\rho\\)\nr\n\n\n\nWe will examine inference procedures for all these cases.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Statistical Inference"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Inference/listing.html#what-is-inference",
    "href": "content/courses/Analytics/Inference/listing.html#what-is-inference",
    "title": "Statistical Inference",
    "section": "",
    "text": "Important\n\n\n\nStatistical inference is the process of drawing conclusions about the entire population based on the information in a sample.\n\n\nIn this Section we will examine samples from populations and find procedures for estimating parameters such as means and sd. We will also devise procedures for comparing means and variances across more than one population. The conditions that make these procedures possible and accurate will also be studied and we will find alternative methods when those assumptions breakdown.\nBased on our ideas of data and types of variables, here is a table of what we may infer, based on the underlying data:\n\nData Types and Inference\n\n\n\n\n\n\n\n\nVariable(s)\nEstimating What?\nPopulation Parameter\nSample Statistic\n\n\n\n\nSingle Qual variable\nProportion\np\n\\(\\hat{p}\\)\n\n\nSingle Quant variable\nMean\n\\(\\mu\\)\n\\(\\bar{x}\\)\n\n\nTwo Qual Variables\nDifference in Proportions\n\\(p_1 -p_2\\)\n\\(\\hat{p_1} - \\hat{p_2}\\)\n\n\nOne Qual, one Quant\nDifference in Means\n\\(\\mu_1 - \\mu_2\\)\n\\(\\bar{x_1}-\\bar{x_2}\\)\n\n\nTwo Quant variables\nCorrelation\n\\(\\rho\\)\nr\n\n\n\nWe will examine inference procedures for all these cases.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Statistical Inference"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Inference/listing.html#an-idea-to-encourage-you-stats-lessons-from-sholay",
    "href": "content/courses/Analytics/Inference/listing.html#an-idea-to-encourage-you-stats-lessons-from-sholay",
    "title": "Statistical Inference",
    "section": "An Idea to Encourage You: Stats Lessons from Sholay!!",
    "text": "An Idea to Encourage You: Stats Lessons from Sholay!!\n\nGabbar: ‚ÄúKitne Aadmi thay?\nStats Teacher: How many observations do you have? n &lt; 30 is a joke.\n\nGabbar: Kya Samajh kar aaye thay? Gabbar khus hoga? Sabaasi dega kya?\nStats Teacher: What are the levels in your Factors? Are they binary? Don‚Äôt do ANOVA just yet!\n\nGabbar: (Fires off three rounds ) Haan, ab theek hai!\nStats Teacher: Yes, now the dataset is balanced wrt the factor (Treatment and Control).\n\nGabbar: Is pistol mein teen zindagi aur teen maut bandh hai. Dekhte hain kisko kya milega.\nStats Teacher: This is our Research Question, for which we will Design an Experiment.\n\nGabbar: (Twirls the chambers of his revolver) ‚ÄúHume kuchh nahi pataa!‚Äù\nStats Teacher: Let us perform a non-parametric Permutation Test for this Factor!\n\nGabbar: ‚ÄúKamaal ho gaya!‚Äù\nStats Teacher: Fantastic! Our p-value is so small that we can reject the NULL Hypothesis!!\n\nGo and like this post at: https://www.linkedin.com/pulse/stat-lessons-from-sholay-arvind-venkatadri-wgtrf/?trackingId=c0b4UCTLRea6U%2Bj%2Bm4TCtw%3D%3D",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Statistical Inference"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html",
    "title": "üêâ Visualizing Survey Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mosaic) # Our trusted friend\nlibrary(skimr)\nlibrary(vcd) # Michael Friendly's package, Visualizing Categorical Data\nlibrary(vcdExtra) # Categorical Data Sets\nlibrary(ggmosaic) # Mosaic Plots\nlibrary(resampledata) # More datasets\n\nlibrary(sjPlot) # Likert Scale Plots\nlibrary(sjlabelled) # Creating Labelled Data for Likert Plots\n\nlibrary(ggpubr) # Colours, Themes and new geometries in ggplot\nlibrary(ca) # Correspondence Analysis, for use some day\n\n## Making Tables\nlibrary(kableExtra) # html styled tables",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#sec-setting-up-r-packages",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#sec-setting-up-r-packages",
    "title": "üêâ Visualizing Survey Data",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mosaic) # Our trusted friend\nlibrary(skimr)\nlibrary(vcd) # Michael Friendly's package, Visualizing Categorical Data\nlibrary(vcdExtra) # Categorical Data Sets\nlibrary(ggmosaic) # Mosaic Plots\nlibrary(resampledata) # More datasets\n\nlibrary(sjPlot) # Likert Scale Plots\nlibrary(sjlabelled) # Creating Labelled Data for Likert Plots\n\nlibrary(ggpubr) # Colours, Themes and new geometries in ggplot\nlibrary(ca) # Correspondence Analysis, for use some day\n\n## Making Tables\nlibrary(kableExtra) # html styled tables",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#introduction",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#introduction",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Introduction",
    "text": "Introduction\nIn many business situations, we perform say customer surveys to get Likert Scale data, where several respondents rate a product or a service on a scale of Very much like, somewhat like, neutral, Dislike and Very much dislike, for example.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#plots-for-survey-data",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#plots-for-survey-data",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Plots for Survey Data",
    "text": "Plots for Survey Data\nHow does this data look like, and how does one plot it? Let us consider a fictitious example, followed by a real world dataset.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#case-study-1-a-fictitious-app-survey-dataset",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#case-study-1-a-fictitious-app-survey-dataset",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Case Study-1: A fictitious app Survey dataset",
    "text": "Case Study-1: A fictitious app Survey dataset\n\n\n\n\n\n\nA fictitious QuickEZ app\n\n\n\nWe are a start-up that has an app called QuickEZ for delivery of groceries. We conduct a survey of 200 people at a local store, with the following questions,\n\n‚ÄúHave your heard of the QuickEZ app?‚Äù\n‚ÄúDo you use the QuickEZ app?‚Äù\n‚ÄúDo you find it easy to use the QuickEZ app?‚Äù\n‚ÄúWill you continue to use the QuickEZ app?‚Äù\n\nwhere each questions is to be answered on a scale of : ‚Äúalways‚Äù, ‚Äúoften‚Äù, ‚Äúsometimes‚Äù,‚Äúnever‚Äù.\n\n\nSuch data may look for example as follows:\n\n\n\n\n\n\n\n  \n\n\n\ntibble [200 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ q1: int [1:200] 4 4 3 2 1 1 2 3 1 2 ...\n  ..- attr(*, \"label\")= Named chr \"Have your heard of the QuickEZ app?\"\n  .. ..- attr(*, \"names\")= chr \"q1\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"always\" \"often\" \"sometimes\" \"never\"\n $ q2: int [1:200] 2 3 2 3 1 3 4 3 1 1 ...\n  ..- attr(*, \"label\")= Named chr \"Do you use the QuickEZ app?\"\n  .. ..- attr(*, \"names\")= chr \"q2\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"always\" \"often\" \"sometimes\" \"never\"\n $ q3: int [1:200] 4 4 1 4 3 4 2 4 4 4 ...\n  ..- attr(*, \"label\")= Named chr \"Do you find it easy to use the QuickEZ app?\"\n  .. ..- attr(*, \"names\")= chr \"q3\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"always\" \"often\" \"sometimes\" \"never\"\n $ q4: int [1:200] 4 1 2 1 4 4 2 1 4 4 ...\n  ..- attr(*, \"label\")= Named chr \"Will you continue to use the QuickEZ app?\"\n  .. ..- attr(*, \"names\")= chr \"q4\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"always\" \"often\" \"sometimes\" \"never\"\n\n\n\nThe columns here correspond to the 4 questions (q1-q4) and the rows contain the 200 responses, which have been coded as (1:4). Such data is also a form of Categorical data and we need to count and plot counts for each of the survey questions. Such a plot is called a Likert plot and it looks like this:\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\nBased on this chart, since it looks like about half the survey respondents have not heard of our app, we need more publicity, and many do not find it easy to use üòø, so we have serious re-design and user testing to do !! But at least those who have managed to get past the hurdles are stating they will continue to use the app, so it does the job, but we can make it easier to use.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#case-study-2-eurofam-survey-dataset",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#case-study-2-eurofam-survey-dataset",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Case Study-2: EUROFAM Survey dataset",
    "text": "Case Study-2: EUROFAM Survey dataset\nHere is another example of Likert data from the healthcare industry.\nefc is a German data set from a European study titled EUROFAM study, on family care of older people. Following a common protocol, data were collected from national samples of approximately 1,000 family carers (i.e.¬†caregivers) per country and clustered into comparable subgroups to facilitate cross-national analysis. The research questions in this EUROFAM study were:\n\n\nTo what extent do family carers of older people use support services or receive financial allowances across Europe? What kind of supports and allowances do they mainly use?\nWhat are the main difficulties carers experience accessing the services used? What prevents carers from accessing unused supports that they need? What causes them to stop using still-needed services?\nIn order to improve support provision, what can be understood about the service characteristics considered crucial by carers, and how far are these needs met? and,\nWhich channels or actors can provide the greatest help in underpinning future policy efforts to improve access to services/supports?\n\n\nWe will select the variables from the efc data set that related to coping (on part of care-givers) and plot their responses after inspecting them:\n```{r}\n#| label: efc_data\n#| layout-nrow: 2\n#| column: body-outset-right\ndata(efc,package = \"sjPlot\")\n\nefc %&gt;% \n  select(dplyr::contains(\"cop\")) %&gt;% \n  head(20)\nefc %&gt;% \n  select(dplyr::contains(\"cop\")) %&gt;% \n  str()\n```\n\n\n\n\n  \n\n\n\n\n\n'data.frame':   908 obs. of  9 variables:\n $ c82cop1: num  3 3 2 4 3 2 4 3 3 3 ...\n  ..- attr(*, \"label\")= chr \"do you feel you cope well as caregiver?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n $ c83cop2: num  2 3 2 1 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"do you find caregiving too demanding?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Never\" \"Sometimes\" \"Often\" \"Always\"\n $ c84cop3: num  2 3 1 3 1 3 4 2 3 1 ...\n  ..- attr(*, \"label\")= chr \"does caregiving cause difficulties in your relationship with your friends?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Never\" \"Sometimes\" \"Often\" \"Always\"\n $ c85cop4: num  2 3 4 1 2 3 1 1 2 2 ...\n  ..- attr(*, \"label\")= chr \"does caregiving have negative effect on your physical health?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Never\" \"Sometimes\" \"Often\" \"Always\"\n $ c86cop5: num  1 4 1 1 2 3 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"does caregiving cause difficulties in your relationship with your family?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Never\" \"Sometimes\" \"Often\" \"Always\"\n $ c87cop6: num  1 1 1 1 2 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"does caregiving cause financial difficulties?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Never\" \"Sometimes\" \"Often\" \"Always\"\n $ c88cop7: num  2 3 1 1 1 2 4 2 3 1 ...\n  ..- attr(*, \"label\")= chr \"do you feel trapped in your role as caregiver?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"Never\" \"Sometimes\" \"Often\" \"Always\"\n $ c89cop8: num  3 2 4 2 4 1 1 3 1 1 ...\n  ..- attr(*, \"label\")= chr \"do you feel supported by friends/neighbours?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n $ c90cop9: num  3 2 3 4 4 1 4 3 3 3 ...\n  ..- attr(*, \"label\")= chr \"do you feel caregiving worthwhile?\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n\n\n\nThe coping related variables have responses on the Likert Scale (1,2,3,4) which correspond to (never, sometimes, often, always), and each variable also has a label defining each variable. The labels are actually ( and perhaps usually ) the questions in the survey.\nWe can plot this data using the plot_likert function from package sjPlot:\n\nefc %&gt;% \n  select(dplyr::contains(\"cop\")) %&gt;% \n  sjPlot::plot_likert(title = \"Caregiver Survey from EUROFAM\") \n\n\n\n\n\n\n\nMany questions here have strong negative responses. This may indicate that policy and publicity related efforts may be required.\n\n\n\n\n\n\nColours and Orientation in the Likert Plot\n\n\n\nOne could prefer (as I do) that ‚Äúoften‚Äù and ‚Äúalways‚Äù scores should be toward the right and ‚Äúsometimes‚Äù and ‚Äúnever‚Äù scores towards the left. One can do this within the plot_likert command using:\nplot_likert(..., reverse.scale = TRUE)\nIf you want the colours to be reversed, then‚Ä¶\nplot_likert(..., reverse.colors = TRUE)\nTry these options now in your Console! (Note the American spelling color)",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#labelled-data",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#labelled-data",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Labelled Data",
    "text": "Labelled Data\nNote how the y-axis has been populated with Survey Questions: this is an example of a labelled dataset, where not only do the variables have names i.e.¬†column names, but also have longish text labels that add information to the data variables. The data values ( i.e scores) in the columns is also labelled as per the the Likert scale (Like/Dislike/Strongly Dislike OR never/sometimes/often/always) etc. These Likert scores are usually a set of contiguous integers.\n\n\n\n\n\n\nVariable Labels and Value Labels\n\n\n\nVariable label is human readable description of the variable. R supports rather long variable names and these names can contain even spaces and punctuation but short variables names make coding easier. Variable label can give a nice, long description of variable. With this description it is easier to remember what those variable names refer to.\nValue labels are similar to variable labels, but value labels are descriptions of the values a variable can take. Labeling values means we don‚Äôt have to remember if 1=Extremely poor and 7=Excellent or vice-versa. We can easily get dataset description and variables summary with info function.\n\n\nLet us manually create one such dataset, since this is a common-enough situation1 that we have survey data and then have to label the variables and the values before plotting. We will use the R package sjlabelled to label our data.2.\n#library(sjlabelled)\n\nvariable_labels &lt;- c(\"Do you practice Analytics?\",\n                     \"Do you code in R?\",\n                     \"Have you published your R Code?\",\n                     \"Do you use Quarto as your Workflow in R?\",\n                     \"Will you use R at Work?\")\nvalue_labels = c(\"never\", \"sometimes\",\"often\",\"always\") #numerically 1:4\n\nmy_survey_data &lt;- \n  # Create toy survey data\n  # 200 responses to 5 questions\n  # responses on Likert Scale\n  # 1:4 = \"never\", \"sometimes\",\"often\",\"always\")\n\n  tibble(q1 = mosaic::sample(1:4, replace = TRUE, size = 200,\n                             prob = c(0.2, 0.2, 0.5, 0.1)),\n         q2 = mosaic::sample(1:4, replace = TRUE, size = 200,\n                             prob = c(0.3, 0.3, 0.3, 0.1)),\n         q3 = mosaic::sample(1:4, replace = TRUE, size = 200,\n                             prob = c(0.2, 0.1, 0.1, 0.6)),\n         q4 = mosaic::sample(1:4, replace = TRUE, size = 200,\n                             prob = c(0.4, 0.2, 0.1, 0.3)),\n         q5 = mosaic::sample(1:4, replace = TRUE, size = 200,\n                             prob = c(0.1, 0.2, 0.5, 0.2))) %&gt;%\n  \n  # Set VARIABLE labels\n  sjlabelled::set_label(x = .,\n                        label = variable_labels) %&gt;%\n  \n  # Now set VALUE labels\n  sjlabelled::set_labels(x = ., labels = value_labels)\n\nstr(my_survey_data)\nplot_likert(my_survey_data, \n            title = \"Summary of Analytics Questionnaire\",\n            reverse.scale = TRUE,# Reverse score values on plot\n            reverse.colors = FALSE, # let the colors be\n            show.prc.sign = TRUE, # Show percentage sign\n            legend.pos = \"bottom\")\n\n\n\ntibble [200 √ó 5] (S3: tbl_df/tbl/data.frame)\n $ q1: int [1:200] 3 1 3 3 1 3 4 3 1 2 ...\n  ..- attr(*, \"label\")= Named chr \"Do you practice Analytics?\"\n  .. ..- attr(*, \"names\")= chr \"q1\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n $ q2: int [1:200] 1 3 2 1 2 3 3 1 1 1 ...\n  ..- attr(*, \"label\")= Named chr \"Do you code in R?\"\n  .. ..- attr(*, \"names\")= chr \"q2\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n $ q3: int [1:200] 2 1 4 4 1 2 2 4 4 3 ...\n  ..- attr(*, \"label\")= Named chr \"Have you published your R Code?\"\n  .. ..- attr(*, \"names\")= chr \"q3\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n $ q4: int [1:200] 1 1 4 1 4 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= Named chr \"Do you use Quarto as your Workflow in R?\"\n  .. ..- attr(*, \"names\")= chr \"q4\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n $ q5: int [1:200] 4 3 1 3 2 3 3 3 1 4 ...\n  ..- attr(*, \"label\")= Named chr \"Will you use R at Work?\"\n  .. ..- attr(*, \"names\")= chr \"q5\"\n  ..- attr(*, \"labels\")= Named num [1:4] 1 2 3 4\n  .. ..- attr(*, \"names\")= chr [1:4] \"never\" \"sometimes\" \"often\" \"always\"\n\n\n\n\n\n\n\n\nIt seems many people in the survey plan to use R at work!! And have published R code as well. But Quarto seems to have mixed results! But of course this is a toy dataset!!\nSo there we are with Survey data analysis and plots!\nThere are a few other plots with this type of data, which are useful in very specialized circumstances. One example of this is the agreement plot which captures the agreement between two (sets) of evaluators, on ratings given on a shared ordinal scale to a set of items. An example from the field of medical diagnosis is the opinions of two specialists on a common set of patients. However, that is for a more advanced course!",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#conclusion",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#conclusion",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Conclusion",
    "text": "Conclusion\nHow are the Likert Plots for Survey data different from Bar Plots? Not very much inherently; we can view the Likert Charts as a set of stacked bar charts, based on Likert-scale response counts. At a pinch we can make a Likert Plot with vanilla bar graphs, but the elegance and power of the packages sjPlot and sjlabelled is undeniable.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#your-turn",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#your-turn",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n Your Turn",
    "text": "Your Turn\n\nTake some of the categorical datasets from the vcd and vcdExtra packages and recreate the plots from this module. Go to https://vincentarelbundock.github.io/Rdatasets/articles/data.html and type ‚Äúvcd‚Äù in the search box. You can directly load CSV files from there, using read_csv(\"url-to-csv\").\nIncluding Edible Insects in our Diet!\n\n Download the Edible Insects Dataset \nThere are several questions here for each ‚Äúarea‚Äù of preference for edible insects: experience, fear, concern for the environment, etc. Take all the columns marked as average as your data for your Likert Plot.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#references",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#references",
    "title": "üêâ Visualizing Survey Data",
    "section": "\n References",
    "text": "References\n\nMine Cetinkaya-Rundel and Johanna Hardin. An Introduction to Modern Statistics, Chapter 4. https://openintro-ims.netlify.app/explore-categorical.html\nUsing the strcplot command from vcd, https://cran.r-project.org/web/packages/vcd/vignettes/strucplot.pdf\nCreating Frequency Tables with vcd, https://cran.r-project.org/web/packages/vcdExtra/vignettes/A_creating.html\nCreating mosaic plots with vcd, https://cran.r-project.org/web/packages/vcdExtra/vignettes/D_mosaics.html\nMichael Friendly, Corrgrams: Exploratory displays for correlation matrices. The American Statistician August 19, 2002 (v1.5). https://www.datavis.ca/papers/corrgram.pdf\nVisualizing Categorical Data in R\nH. Riedwyl & M. Sch√ºpbach (1994), Parquet diagram to plot contingency tables. In F. Faulbaum (ed.), Softstat ‚Äô93: Advances in Statistical Software, 293‚Äì299. Gustav Fischer, New York.\n\n\n\n R Package Citations\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\nggmosaic\n0.3.3\nJeppson, Hofmann, and Cook (2021)\n\n\nggpubr\n0.6.0\nKassambara (2023)\n\n\njanitor\n2.2.0\nFirke (2023)\n\n\nkableExtra\n1.4.0\nZhu (2024)\n\n\nresampledata\n0.3.1\nChihara and Hesterberg (2018)\n\n\nsjlabelled\n1.2.0\nL√ºdecke (2022)\n\n\nsjPlot\n2.8.15\nL√ºdecke (2023)\n\n\nvcd\n1.4.12\n\nMeyer, Zeileis, and Hornik (2006); Zeileis, Meyer, and Hornik (2007); Meyer et al. (2023)\n\n\n\nvcdExtra\n0.8.5\nFriendly (2023)\n\n\n\n\n\n\nChihara, Laura M., and Tim C. Hesterberg. 2018. Mathematical Statistics with Resampling and r. 2nd ed. Hoboken, NJ: John Wiley & Sons. https://sites.google.com/site/chiharahesterberg/home.\n\n\nFirke, Sam. 2023. janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.\n\n\nFriendly, Michael. 2023. vcdExtra: ‚Äúvcd‚Äù Extensions and Additions. https://CRAN.R-project.org/package=vcdExtra.\n\n\nJeppson, Haley, Heike Hofmann, and Di Cook. 2021. ggmosaic: Mosaic Plots in the ‚Äúggplot2‚Äù Framework. https://CRAN.R-project.org/package=ggmosaic.\n\n\nKassambara, Alboukadel. 2023. ggpubr: ‚Äúggplot2‚Äù Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr.\n\n\nL√ºdecke, Daniel. 2022. sjlabelled: Labelled Data Utility Functions (Version 1.2.0). https://doi.org/10.5281/zenodo.1249215.\n\n\n‚Äî‚Äî‚Äî. 2023. sjPlot: Data Visualization for Statistics in Social Science. https://CRAN.R-project.org/package=sjPlot.\n\n\nMeyer, David, Achim Zeileis, and Kurt Hornik. 2006. ‚ÄúThe Strucplot Framework: Visualizing Multi-Way Contingency Tables with Vcd.‚Äù Journal of Statistical Software 17 (3): 1‚Äì48. https://doi.org/10.18637/jss.v017.i03.\n\n\nMeyer, David, Achim Zeileis, Kurt Hornik, and Michael Friendly. 2023. vcd: Visualizing Categorical Data. https://CRAN.R-project.org/package=vcd.\n\n\nZeileis, Achim, David Meyer, and Kurt Hornik. 2007. ‚ÄúResidual-Based Shadings for Visualizing (Conditional) Independence.‚Äù Journal of Computational and Graphical Statistics 16 (3): 507‚Äì25. https://doi.org/10.1198/106186007X237856.\n\n\nZhu, Hao. 2024. kableExtra: Construct Complex Table with ‚Äúkable‚Äù and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra.\n\n\n\n\n\n\nFigure¬†1:",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#footnotes",
    "href": "content/courses/Analytics/Descriptive/Modules/45-SurveyData/index.html#footnotes",
    "title": "üêâ Visualizing Survey Data",
    "section": "Footnotes",
    "text": "Footnotes\n\nPiping Hot Data: Leveraging Labelled Data in R, https://www.pipinghotdata.com/posts/2020-12-23-leveraging-labelled-data-in-r/&gt;‚Ü©Ô∏é\nLabel Support in R:https://cran.r-project.org/web/packages/sjlabelled/index.html‚Ü©Ô∏é",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üêâ Visualizing Survey Data"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html",
    "title": "üïî Time Series",
    "section": "",
    "text": "TimeSeries Wrangling¬†¬†\n\n  Time Series Analysis-WIP",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#sec-slides-and-tutorials",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#sec-slides-and-tutorials",
    "title": "üïî Time Series",
    "section": "",
    "text": "TimeSeries Wrangling¬†¬†\n\n  Time Series Analysis-WIP",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#using-web-r",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#using-web-r",
    "title": "üïî Time Series",
    "section": "\n Using web-R",
    "text": "Using web-R\nThis tutorial uses web-r that allows you to run all code within your browser, on all devices. Most code chunks herein are formatted in a tabbed structure (like in an old-fashioned library), with duplicated code. The tabs in front have regular R code that will work when copy-pasted in your RStudio session. The tab ‚Äúbehind‚Äù has the web-R code that can work directly in your browser, and can be modified as well. The R code is also there to make sure you have original code to go back to, when you have made several modifications to the code on the web-r tabs and need to compare your code with the original!\nKeyboard Shortcuts\n\nRun selected code using either:\n\nmacOS: ‚åò + ‚Ü©Ô∏é/Return\n\nWindows/Linux: Ctrl + ‚Ü©Ô∏é/Enter\n\n\n\nRun the entire code by clicking the ‚ÄúRun code‚Äù button or pressing Shift+‚Ü©Ô∏é.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#setting-up-r-packages",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#setting-up-r-packages",
    "title": "üïî Time Series",
    "section": "\n Setting up R Packages",
    "text": "Setting up R Packages\n\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(ggformula) # Our Formula based graphing package\nlibrary(skimr)\nlibrary(fpp3)\n\n# Wrangling\n# library(lubridate)  # Deal with dates. Loads with tidyverse\n# library(tsibble) # loads with ffp3\n# library(tsibbledata) # loads with fpp3\n\n# devtools::install_github(\"FinYang/tsdl\")\nlibrary(tsdl)\nlibrary(TSstudio)\nlibrary(timetk)\n\nlibrary(gghighlight) # Highlight specific parts of charts\n\nThe fpp3 packages loads a good few other packages:\n\n\n [1] \"cli\"         \"crayon\"      \"dplyr\"       \"fable\"       \"fabletools\" \n [6] \"feasts\"      \"ggplot2\"     \"lubridate\"   \"magrittr\"    \"purrr\"      \n[11] \"rstudioapi\"  \"tibble\"      \"tidyr\"       \"tsibble\"     \"tsibbledata\"\n\n\n\n\n\n\n\n\nmosaic and ggformula command template\n\n\n\nNote the standard method for all commands from the mosaic and ggformula packages: goal( y ~ x | z, data = ___)\nWith ggformula, one can create any graph/chart using: gf_***(y ~ x | z, data =___ )\nIn practice, we often use: dataframe %&gt;% gf_***(y ~ x | z) which has cool benefits such as ‚Äúautocompletion‚Äù of variable names, as we shall see. The ‚Äú***‚Äù indicates what kind of graph you desire: histogram, bar, scatter, density; the ‚Äú___‚Äù is the name of your dataset that you want to plot with.\n\n\n\n\n\n\n\n\nggplot command template\n\n\n\nThe ggplot2 template is used to identify the dataframe, identify the x and y axis, and define visualized layers:\nggplot(data = ‚Äî, mapping = aes(x = ‚Äî, y = ‚Äî)) + geom_‚Äî-()\nNote: ‚Äî- is meant to imply text you supply. e.g.¬†function names, data frame names, variable names.\nIt is helpful to see the argument mapping, above. In practice, rather than typing the formal arguments, code is typically shorthanded to this:\ndataframe %&gt;% ggplot(aes(xvar, yvar)) + geom_‚Äî-()",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#introduction",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#introduction",
    "title": "üïî Time Series",
    "section": "\n Introduction",
    "text": "Introduction\nAny metric that is measured over regular time intervals forms a time series. Analysis of Time Series is commercially important because of industrial need and relevance, especially with respect to Forecasting (Weather data, sports scores, population growth figures, stock prices, demand, sales, supply‚Ä¶). For example, in the graph shown below are the temperatures over time in two US cities:\n\n\nWhat can we do with Time Series? As with other datasets, we have to begin by answering fundamental questions, such as:\n\nWhat are the types of time series?\nHow do we visualize time series?\nHow might we summarize time series to get aggregate numbers, say by week, month, quarter or year?\nHow do we decompose the time series into level, trend, and seasonal components?\nHow might we make a model of the underlying process that creates these time series?\nHow do we make useful forecasts with the data we have?\n\nWe will first look at the multiple data formats for time series in R. Alongside we will look at the R packages that work with these formats and create graphs and measures using those objects. Then we examine data wrangling of time series, where we look at packages that offer dplyr-like ability to group and summarize time series using the time variable. We will finally look at obtaining the components of the time series and try our hand at modelling and forecasting.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#time-series-formats-conversion-and-plotting",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#time-series-formats-conversion-and-plotting",
    "title": "üïî Time Series",
    "section": "\n Time Series Formats, Conversion, and Plotting",
    "text": "Time Series Formats, Conversion, and Plotting\nThere are multiple formats for time series data. The ones that we are likely to encounter most are:\n\nThe ts format: We may simply have a single series of measurements that are made over time, stored as a numerical vector. The stats::ts() function will convert a numeric vector into an R time series ts object, which is the most basic time series object in R. The base-R ts object is used by established packages forecast and is also supported by newer packages such as tsbox.\nThe tibble format: the simplest and most familiar data format is of course the standard tibble/data frame, with or without an explicit time column/variable to indicate that the other variables vary with time. The standard tibble object is used by many packages, e.g.¬†timetk & modeltime.\nThe tsibble format: this is a new format for time series analysis. The special tsibble object (‚Äútime series tibble‚Äù) is used by fable, feasts and others from the tidyverts set of packages.\n\nThere are many other time-oriented data formats too‚Ä¶probably too many, such a tibbletime and TimeSeries objects. For now the best way to deal with these, should you encounter them, is to convert them (Using the package tsbox) to a tibble or a tsibble and work with these.\n\n\n\n\n\nStandards\n\nTo start, we will use simple ts data first, and then do another with a ‚Äúvanilla‚Äù tibble format that we can plot as is. We will then look at a tibbledata that does have a time-oriented variable. We will then perform conversion to tsibble format to plot it, and then a final example with a ground-up tsibble dataset.\n\n Base-R ts format data\nThere are a few datasets in base R that are in ts format already.\n\n\n R\n web-r\n\n\n\n\nAirPassengers\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\nstr(AirPassengers)\n\n Time-Series [1:144] from 1949 to 1961: 112 118 132 129 121 135 148 148 136 119 ...\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThis can be easily plotted using base R:\n\n\n R\n web-r\n\n\n\n\n# Base R\nplot(AirPassengers)\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nOne can see that there is an upward trend and also seasonal variations that also increase over time. This is an example of a multiplicative time series, which we will discuss later.\nLet us take data that is ‚Äútime oriented‚Äù but not in ts format. We use the command ts to convert a numeric vector to ts format: the syntax of ts() is:\nSyntax: objectName &lt;- ts(data, start, end, frequency), where,\n\n\ndata : represents the data vector\n\nstart : represents the first observation in time series\n\nend : represents the last observation in time series\n\nfrequency : represents number of observations per unit time. For example 1=annual, 4=quarterly, 12=monthly, 7=weekly, etc.\n\nWe will pick simple numerical vector data ( i.e.¬†not a time series ) ChickWeight:\n\n\n R\n web-r\n\n\n\n\nChickWeight %&gt;% head()\n\n\n  \n\n\n# Filter for Chick #1 and for Diet #1\nChickWeight_ts &lt;- ChickWeight %&gt;% \n  dplyr::filter(Chick == 1, Diet ==1) %&gt;% \n  dplyr::select(weight, Time)\n\n# stats::ts does not accept pipe format\nChickWeight_ts &lt;- stats::ts(ChickWeight_ts$weight, \n                            frequency = 2) \nstr(ChickWeight_ts)\n\n Time-Series [1:12] from 1 to 6.5: 42 51 59 64 76 93 106 125 149 171 ...\n\nplot(ChickWeight_ts) # Using base-R\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWe see that the weights of a young chick specimen #1 increases over time.\n\ntibble data\nThe ts data format can handle only one time series; in the above example, we could not have plotted the weight of two chicks, if we had wanted to. If we want to plot/analyze multiple time series, based on say Qualitative variables, (e.g.¬†sales figures over time across multiple products and locations) we need other data formats. Using the familiar tibble structure opens up new possibilities.\n\nWe can have multiple time series within a tibble (think of numerical time-series data like GDP, Population, Imports, Exports for multiple countries as with the gapminder1data we saw earlier).\nIt also allows for data processing with dplyr such as filtering and summarizing.\n\n\n\ngapminder data\n\n\n\n  \n\n\n\nLet us read and inspect in the US births data from 2000 to 2014. Download this data by clicking on the icon below, and saving the downloaded file in a sub-folder called data inside your project.\n Download the US Births data \nRead this data in and inspect it.\n\n\n R\n web-r\n\n\n\n\nbirths_2000_2014 &lt;- read_csv(\"data/US_births_2000-2014_SSA.csv\")\nglimpse(births_2000_2014)\n\nRows: 5,479\nColumns: 5\n$ year          &lt;dbl&gt; 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 20‚Ä¶\n$ month         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ date_of_month &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1‚Ä¶\n$ day_of_week   &lt;dbl&gt; 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3,‚Ä¶\n$ births        &lt;dbl&gt; 9083, 8006, 11363, 13032, 12558, 12466, 12516, 8934, 794‚Ä¶\n\ninspect(births_2000_2014)\n\n\nquantitative variables:  \n           name   class  min   Q1 median    Q3   max         mean          sd\n1          year numeric 2000 2003   2007  2011  2014  2006.999270    4.321085\n2         month numeric    1    4      7    10    12     6.522723    3.449075\n3 date_of_month numeric    1    8     16    23    31    15.730243    8.801151\n4   day_of_week numeric    1    2      4     6     7     3.999817    2.000502\n5        births numeric 5728 8740  12343 13082 16081 11350.068261 2325.821049\n     n missing\n1 5479       0\n2 5479       0\n3 5479       0\n4 5479       0\n5 5479       0\n\nskim(births_2000_2014)\n\n\nData summary\n\n\nName\nbirths_2000_2014\n\n\nNumber of rows\n5479\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nyear\n0\n1\n2007.00\n4.32\n2000\n2003\n2007\n2011\n2014\n‚ñá‚ñá‚ñá‚ñá‚ñá\n\n\nmonth\n0\n1\n6.52\n3.45\n1\n4\n7\n10\n12\n‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá\n\n\ndate_of_month\n0\n1\n15.73\n8.80\n1\n8\n16\n23\n31\n‚ñá‚ñá‚ñá‚ñá‚ñÜ\n\n\nday_of_week\n0\n1\n4.00\n2.00\n1\n2\n4\n6\n7\n‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñá\n\n\nbirths\n0\n1\n11350.07\n2325.82\n5728\n8740\n12343\n13082\n16081\n‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÅ\n\n\n\n\nbirths_2000_2014\n\n\n  \n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThis is just a tibble containing a single data variable births that varies over time. All other variables, although depicting time, are numerical columns and not explicitly time columns. There are no Qualitative variables (yet!).\nPlotting tibble-oriented time data\n\n\nUsing ggformula\nUsing ggplot\n\n\n\nWe will now plot this using ggformula. Using the separate year/month/week and day_of_week / day_of_month columns, we can plot births over time, colouring by day_of_week, for example:\n# grouping by day_of_week\nbirths_2000_2014 %&gt;% \n  gf_line(births ~ year, \n          group = ~ day_of_week, \n          color = ~ day_of_week) %&gt;% \n  gf_point(title = \"Births, By Day of Week\", \n           subtitle = \"Over the Years\") %&gt;% \n  gf_theme(scale_colour_distiller(palette = \"Paired\")) \n# Grouping by date_of_month\nbirths_2000_2014 %&gt;% \n  gf_line(births ~ year, \n          group = ~ date_of_month, \n          color = ~ date_of_month) %&gt;% \n  gf_point(title = \"Births, By Date of Month\",\n           subtitle = \"Over the Years\") %&gt;% \n  gf_theme(scale_colour_distiller(palette = \"Paired\")) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot particularly illuminating. This is because the data is daily and we have considerable variation over time, and here we have too much data to visualize.\nSummaries will help, so we could calculate the the mean births per month in each year and plot that:\nbirths_2000_2014_monthly &lt;- births_2000_2014 %&gt;% \n  \n# Convert month to factor/Qual variable!\n# So that we can have discrete colours for each month\n# Using base::factor()\n# Could use forcats::as_factor() also\n\n  mutate(month = base::factor(month, labels = month.abb)) %&gt;%\n\n# `month.abb` is a built-in dataset containing names of months.\n\n  group_by(year, month) %&gt;% \n  summarise(mean_monthly_births = mean(births, na.rm = TRUE))\nbirths_2000_2014_monthly\n####\nbirths_2000_2014_monthly %&gt;% \n##\n  gf_line(mean_monthly_births ~ year, \n          group = ~ month, \n          colour = ~ month, linewidth = 1) %&gt;% \n##\n  gf_point(size = 1.5, \n           title = \"Summaries of Monthly Births over the years\") %&gt;% \n  \n## palette for 12 colours\n  gf_theme(scale_colour_brewer(palette = \"Paired\")) \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThese are graphs for the same month each year: we have a January graph and a February graph and so on. So‚Ä¶average births per month were higher in all months during 2005 to 2007 and have dropped since.\n\n\nWe can do similar graphs using day_of_week as our basis for grouping, instead of month:\nbirths_2000_2014_weekly &lt;- births_2000_2014 %&gt;% \n  mutate(day_of_week = base::factor(day_of_week,\n          levels = c(1,2,3,4,5,6,7), \n          labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))) %&gt;% \n  group_by(year, day_of_week) %&gt;% \n  summarise(mean_daily_births = mean(births, na.rm = TRUE))\n##\nbirths_2000_2014_weekly\n##\nbirths_2000_2014_weekly %&gt;%   \n  gf_line(mean_daily_births ~ year, \n          group = ~ day_of_week, \n          colour = ~ day_of_week, \n          linewidth = 1,\n          data = .) %&gt;% \n  gf_point(size = 2, title = \"Births over the Years by Day of Week\") %&gt;% \n  # palette for 12 colours\n  gf_theme(scale_colour_brewer(palette = \"Paired\")) \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nWe will now plot this using ggplot for completeness. Using the separate year/month/week and day_of_week / day_of_month columns, we can plot births over time, colouring by day_of_week, for example:\n# grouping by day_of_week\nbirths_2000_2014 %&gt;% \n  ggplot(aes(year, births,\n             group = day_of_week, \n             color = day_of_week)) + \n  geom_line() +  \n  geom_point() +\n  labs(title = \"Births, By Day of Week\",\n       subtitle = \"Over the Years\") + \n  scale_colour_distiller(palette = \"Paired\")\n##\n\n# Grouping by date_of_month\nbirths_2000_2014 %&gt;% \n  ggplot(aes(year,births,color = date_of_month,\n             group = date_of_month)) + \n  geom_line() + \n  geom_point() + \n  labs(title = \"Births, By Date of Month\",\n       subtitle = \"Over the Years\") + \n  scale_colour_distiller(palette = \"Paired\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbirths_2000_2014_monthly &lt;- births_2000_2014 %&gt;% \n  \n# Convert month to factor/Qual variable!\n# So that we can have discrete colours for each month\n# Using base::factor()\n# Could use forcats::as_factor() also\n  mutate(month = base::factor(month, labels = month.abb)) %&gt;%\n# `month.abb` is a built-in dataset containing names of months.\n\n  group_by(year, month) %&gt;% \n  summarise(mean_monthly_births = mean(births, na.rm = TRUE))\nbirths_2000_2014_monthly\nbirths_2000_2014_monthly %&gt;% \n  ggplot(aes(year, mean_monthly_births,\n             group = month, \n             colour = month)) + \n  geom_line(linewidth = 1) + \n  geom_point(size = 1.5) + \n  labs(title = \"Summaries of Monthly Births over the years\") + \n    \n  # palette for 12 colours\n  scale_colour_brewer(palette = \"Paired\") \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nbirths_2000_2014_weekly &lt;- births_2000_2014 %&gt;% \n  mutate(day_of_week = base::factor(day_of_week,\n          levels = c(1,2,3,4,5,6,7), \n          labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))) %&gt;% \n  group_by(year, day_of_week) %&gt;% \n  summarise(mean_daily_births = mean(births, na.rm = TRUE))\nbirths_2000_2014_weekly\nbirths_2000_2014_weekly %&gt;%\n  ggplot(aes(year, mean_daily_births, \n             group = day_of_week,\n             colour = day_of_week)) + \n  geom_line(linewidth = 1) + \n  geom_point(size = 2) + \n    \n  # palette for 12 colours\n  scale_colour_brewer(palette = \"Paired\") +  \n  labs(title = \"Births over the Years by Day of Week\")\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Small Multiples using gghighlight\nInstead of looking at multiple overlapping time series graphs, we could split these up into small multiples or facets and still retain the overall picture that is offered by the overlapping graphs. The trick here is the highlight one of the graphs at a time, while keeping all other graphs in the background. We can do this with the gghighlight package.\n#library(gghighlight)\n#ggplot2::theme_set(new = theme_classic(base_size = 14, \n#                                       base_family = \"sans\"))\n###\nbirths_2000_2014_monthly\n###\nbirths_2000_2014_monthly %&gt;% ggplot() + \n  geom_line(aes(y = mean_monthly_births,x = year, group = month)) +\n  labs(x = \"Year\", y  =\"Mean Monthly Births over the Years\", \n       title = \"Mean Births by Month\", \n       caption = \"Using gghighlight package\") +\n\n  ## Add highlighting\n  gghighlight(\n    use_direct_label = F,\n    unhighlighted_params = list(colour = alpha(\"grey85\", 1))) +\n  \n# Add faceting\n  facet_wrap(vars(month))\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n# ggplot2::theme_set(new = theme_classic(base_size = 14, \n#                                        base_family = \"sans\"))\n###\nbirths_2000_2014_weekly\n###\nbirths_2000_2014_weekly %&gt;% ggplot() + \n  geom_line(aes(y = mean_daily_births, x = year, group = day_of_week)) +\n  labs(x = \"Year\", y  =\"Mean Daily Births over the Years\", \n       title = \"Mean Births by Day of Week\", \n       caption = \"Using gghighlight package\") +\n\n  ## Add highlighting\n  gghighlight(\n    use_direct_label = F,\n    unhighlighted_params = list(colour = alpha(\"grey85\", 1))) +\n  \n# Add faceting\n  facet_wrap(vars(day_of_week))\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy are fewer babies born on weekends?\n\n\n\nLooks like an interesting story here‚Ä¶there are significantly fewer births on average on Sat and Sun, over the years! Why? Should we watch Grey‚Äôs Anatomy ?\nAnd more births in September? That should be a no-brainer!! üòÜ\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that this is still using just tibble data, without converting it into a time series format. So far we are simply treating the year/month/day variables are simple variables and using dplyr to group and summarize. We have not created an explicit time or date variable.\n\n\n\nPlotting tibble time-series\nNow, we can convert the time-oriented columns in this dataset into a single date variable, giving us a proper tibble time-series:\n\nbirths_tibble_timeseries &lt;- \n  births_2000_2014 %&gt;%\n  mutate(date = lubridate::make_date( year, month, date_of_month)) %&gt;%\n\n## Drop off the individual columns ( year, month, day_of_month)\n  select(date, births)\n\nbirths_tibble_timeseries\n\n\n  \n\n\n\nNote that we have a proper date formatted column, as desired. This is a single time series, but if we had other Qualitative variables such as say city, we could easily have had multiple series here. We can plot this with ggformula/ggplot as we have done before, and with now with timetk:\n\nbirths_tibble_timeseries %&gt;%\n  gf_line(births ~ date)\n\nbirths_tibble_timeseries %&gt;%\n  ggplot(aes(date, births)) + geom_line()\n\n\nbirths_tibble_timeseries %&gt;%\n  timetk::plot_time_series(.date_var = date, \n                           .value = births, \n                           .interactive = FALSE, \n                           .title = \"Births over Time\",\n                           .x_lab = \"Time\",\n                           .y_lab = \"Births\")\n\n\n\n\n\n\n\n\ntsibble data\nFinally, we have tsibble (‚Äútime series tibble‚Äù) format data, which contains three main components:\n\nan index variable that defines time;\na set of key variables, usually categorical, that define sets of observations, over time. This allows for each combination of the categorical variables to define a separate time series.\na set of quantitative variables, that represent the quantities that vary with time (i.e index)\n\nHere is Robert Hyndman‚Äôs video introducing tsibbles:\n\nThe package tsibbledata contains several ready made tsibble format data.  Let us try PBS, which is a dataset containing Monthly Medicare prescription data in Australia.Run data(package = \"tsibbledata\") in your Console to find out about these.\n\ndata(PBS, package = \"tsibbledata\")\nPBS\n\n\n  \n\n\nglimpse(PBS)\n\nRows: 67,596\nColumns: 9\nKey: Concession, Type, ATC1, ATC2 [336]\n$ Month      &lt;mth&gt; 1991 Jul, 1991 Aug, 1991 Sep, 1991 Oct, 1991 Nov, 1991 Dec,‚Ä¶\n$ Concession &lt;chr&gt; \"Concessional\", \"Concessional\", \"Concessional\", \"Concession‚Ä¶\n$ Type       &lt;chr&gt; \"Co-payments\", \"Co-payments\", \"Co-payments\", \"Co-payments\",‚Ä¶\n$ ATC1       &lt;chr&gt; \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\",‚Ä¶\n$ ATC1_desc  &lt;chr&gt; \"Alimentary tract and metabolism\", \"Alimentary tract and me‚Ä¶\n$ ATC2       &lt;chr&gt; \"A01\", \"A01\", \"A01\", \"A01\", \"A01\", \"A01\", \"A01\", \"A01\", \"A0‚Ä¶\n$ ATC2_desc  &lt;chr&gt; \"STOMATOLOGICAL PREPARATIONS\", \"STOMATOLOGICAL PREPARATIONS‚Ä¶\n$ Scripts    &lt;dbl&gt; 18228, 15327, 14775, 15380, 14371, 15028, 11040, 15165, 168‚Ä¶\n$ Cost       &lt;dbl&gt; 67877.00, 57011.00, 55020.00, 57222.00, 52120.00, 54299.00,‚Ä¶\n\n\nData Description: This is a large-ish dataset:Run PBS in your console\n\n67K observations\n336 combinations of key variables (Concession, Type, ATC1, ATC2) which are categorical, as foreseen.\nData appears to be monthly, as indicated by the 1M.\nthe time index variable is called Month, formatted as yearmonth, a new type of variable introduced in the tsibble package.\n\nNote that there are multiple Quantitative variables (Scripts,Cost), each sliced into 336 time-series, a feature which is not supported in the ts format, but is supported in a tsibble. The Qualitative Variables are described below. Type help(\"PBS\") in your Console.\nThe data is dis-aggregated/grouped using four keys:\n- Concession: Concessional scripts are given to pensioners, unemployed, dependents, and other card holders\n- Type: Co-payments are made until an individual‚Äôs script expenditure hits a threshold ($290.00 for concession, $1141.80 otherwise). Safety net subsidies are provided to individuals exceeding this amount.\n- ATC1: Anatomical Therapeutic Chemical index (level 1). 15 types\n- ATC2: Anatomical Therapeutic Chemical index (level 2). 84 types, nested inside ATC1.\nLet us simply plot Cost over time:\n\n\nUsing ggformula\nUsing ggplot\nUsing timetk\n\n\n\n\nPBS %&gt;%\n  gf_point(Cost ~ Month, data = .) %&gt;% \n  gf_line(title = \"PBS Costs vs time\", caption = \"ggformula\") \n\n\n\n\n\n\n\n\n\n\nPBS %&gt;% \n  ggplot(aes(Month, Cost)) + \n  geom_point() + \n  geom_line() + \n  labs(title = \"PBS Costs vs time\", caption = \"ggplot\")\n\n\n\n\n\n\n\n\n\n\nPBS %&gt;%\n  timetk::plot_time_series(.date_var = Month, .value = Cost, \n                           .interactive = FALSE,\n                           .smooth = FALSE)\n\n\n\n\n\n\n\n\n\n\nThis basic plot is quite messy. Other than an overall rising trend and more vigorous variations pointing to a multiplicative process, we cannot say more. There is simply too much happening here and it is now time (sic!) for us to look at summaries of the data using dplyr-like verbs.\nWe will do that in the Section¬†1.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#time-series-heatmaps",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#time-series-heatmaps",
    "title": "üïî Time Series",
    "section": "\n Time Series Heatmaps",
    "text": "Time Series Heatmaps\nHow about a heatmap? We can cook up a categorical variable based on the number of births (low, fine, high) and use that to create a heatmap:\n\nbirths_2000_2014 %&gt;%\n  mutate(birthrate = case_when(births &gt;= 10000 ~ \"high\",\n                               births &lt;= 8000 ~ \"low\",\n                               TRUE ~ \"fine\")) %&gt;%\n  mutate(birthrate = base::factor(birthrate, \n                                  labels = c(\"high\", \"fine\", \"low\"), \n                                  ordered = TRUE)) %&gt;%\n  \n  gf_tile(\n    data = .,\n    year ~ month,\n    fill = ~ birthrate,\n    color = \"black\"\n  ) %&gt;%\n  \n  gf_theme(scale_x_time(\n    breaks = 1:12,\n    labels = c(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\n               \"May\",\"Jun\",\"Jul\",\"Aug\",\n               \"Sep\",\"Oct\",\"Nov\",\"Dec\")\n  )) %&gt;%\n  \n  gf_theme(scale_fill_brewer(type = \"qual\", palette = \"OrRd\", direction = -1))",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#conclusion",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#conclusion",
    "title": "üïî Time Series",
    "section": "\n Conclusion",
    "text": "Conclusion\nWe have seen a good few data formats for time series, and how to work with them and plot them.\nIn the Tutorial Section¬†1, we will explore:\n\nwrangling with Time series to produce grouped and filtered aggregates/summaries and plots with these\nhow to decompose time series into periodic and aperiodic components, which can be used to make business decisions.\nProducing Interactive Plots for Time Series\n\nmodelling and forecasting of time series.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#your-turn",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#your-turn",
    "title": "üïî Time Series",
    "section": "\n Your Turn",
    "text": "Your Turn\n\nChoose some of the datasets in the tsdl and in the tsibbledata packages. (Install and load them first! )Plot basic, filtered and model-based graphs for these and interpret.",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#references",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#references",
    "title": "üïî Time Series",
    "section": "\n References",
    "text": "References\n\nRobert Hyndman, Forecasting: Principles and Practice (Third Edition).available online\n\n\nTime Series Analysis at Our Coding Club\n\n\nThe Nuclear Threat‚ÄîThe Shadow Peace, part 1\n\n\n11 Ways to Visualize Changes Over Time ‚Äì A Guide\n\n\nWhat is seasonal adjustment and why is it used?\n\n\nThe start-at-zero rule\n\n\n\n\n R Package Citations\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\nfpp3\n0.5\nHyndman (2023)\n\n\ngghighlight\n0.4.1\nYutani (2023)\n\n\ntimetk\n2.9.0\nDancho and Vaughan (2023)\n\n\ntsbox\n0.4.1\nSax (2021)\n\n\ntsdl\n0.1.0\nHyndman and Yang (2023)\n\n\ntsibble\n1.1.4\nWang, Cook, and Hyndman (2020)\n\n\ntsibbledata\n0.4.1\nO‚ÄôHara-Wild et al. (2022)\n\n\nTSstudio\n0.1.7\nKrispin (2023)\n\n\n\n\n\n\nDancho, Matt, and Davis Vaughan. 2023. timetk: A Tool Kit for Working with Time Series. https://CRAN.R-project.org/package=timetk.\n\n\nHyndman, Rob. 2023. Fpp3: Data for ‚ÄúForecasting: Principles and Practice‚Äù (3rd Edition). https://CRAN.R-project.org/package=fpp3.\n\n\nHyndman, Rob, and Yangzhuoran Yang. 2023. tsdl: Time Series Data Library. https://finyang.github.io/tsdl/.\n\n\nKrispin, Rami. 2023. TSstudio: Functions for Time Series Analysis and Forecasting. https://CRAN.R-project.org/package=TSstudio.\n\n\nO‚ÄôHara-Wild, Mitchell, Rob Hyndman, Earo Wang, and Rakshitha Godahewa. 2022. tsibbledata: Diverse Datasets for ‚Äútsibble‚Äù. https://CRAN.R-project.org/package=tsibbledata.\n\n\nSax, Christoph. 2021. tsbox: Class-Agnostic Time Series in in R. https://docs.ropensci.org/tsbox/.\n\n\nWang, Earo, Dianne Cook, and Rob J Hyndman. 2020. ‚ÄúA New Tidy Data Structure to Support Exploration and Modeling of Temporal Data.‚Äù Journal of Computational and Graphical Statistics 29 (3): 466‚Äì78. https://doi.org/10.1080/10618600.2019.1695624.\n\n\nYutani, Hiroaki. 2023. gghighlight: Highlight Lines and Points in ‚Äúggplot2‚Äù. https://CRAN.R-project.org/package=gghighlight.\n\n\n\n\n\n\nStandards",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  },
  {
    "objectID": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#footnotes",
    "href": "content/courses/Analytics/Descriptive/Modules/50-Time/time-v2.html#footnotes",
    "title": "üïî Time Series",
    "section": "Footnotes",
    "text": "Footnotes\n\nhttps://www.gapminder.org/data/‚Ü©Ô∏é",
    "crumbs": [
      "Teaching",
      "Data Analytics",
      "Descriptive Analytics",
      "üïî Time Series"
    ]
  }
]