---
date: 23/Nov/2024
date-modified: "`r Sys.Date()`"
title: "MLPs and Backpropagation"
order: 40
summary: 
tags:
- Neural Nets
- Back Propagation
- Gradient

---


```{r setup, include=FALSE}
library(blogdown)
library(tidyverse)
library(ggformula)
library(mosaicCalc) # Analytic Calculus
library(neuralnet) # Backpropagation training
library(plot3D) # 3D plots for explanation

## Markdown boiler plate stuff!!
# ![An Elephant](elephant.png){#fig-elephant}
# This is illustrated well by @fig-elephant.
# 
# ### Figure Panel Divs
#     ::: {#fig-elephants layout-ncol=2}
#     ![Surus](surus.png){#fig-surus}
#     ![Hanno](hanno.png){#fig-hanno}
#      Famous Elephants
#     :::
#     Adding download buttons
#     data that has been read in
#     {{< downloadthis ../../../../materials/Data/housing_train.csv dname="house_prices" label="Download the House Prices Dataset" icon="database-fill-down" type="info" >}}
#    existing file
#    {{< downloadthis Orange/grouped-summaries.ows dname="grouped_summaries" label="Download the Orange Workflow" icon="database-fill-down" type="info" >}} 

```

```{r}
#| label: Extra Pedagogical Packages
#| echo: false
#| message: false

library(checkdown)
library(epoxy)
library(grateful)
library(MKdescr)
library(shinylive) # To create a Shiny app in a Quarto HTML doc
# Will not work if webr is also used in the SAME Quarto doc!
library(sysfonts)
library(gfonts)
library(kableExtra)
# library(conflicted)
# conflicted::conflicts_prefer(dplyr::filter, dplyr::count, dplyr::last, dplyr::glimpse, base::max)
library(downloadthis)
#devtools::install_github("mccarthy-m-g/embedr")
library(embedr) # Embed multimedia in HTML files
```

```{r}
#| label: Plot Sizing and theming
#| echo: false
#| message: false
#| results: hide

# https://stackoverflow.com/questions/74491138/ggplot-custom-fonts-not-working-in-quarto

# Chunk options
knitr::opts_chunk$set(
 fig.width = 7,
 fig.asp = 0.618, # Golden Ratio
 #out.width = "80%",
 fig.align = "center"
)
### Ggplot Theme
### https://rpubs.com/mclaire19/ggplot2-custom-themes

theme_custom <- function(){ 
    font <- "Roboto Condensed"   #assign font family up front
    
    theme_classic(base_size = 14) %+replace%    #replace elements we want to change
    
    theme(
      panel.grid.minor = element_blank(),    #strip minor gridlines
      text = element_text(family = font),
      #text elements
      plot.title = element_text(             #title
                   family = font,            #set font family
                   #size = 20,               #set font size
                   face = 'bold',            #bold typeface
                   hjust = 0,                #left align
                   #vjust = 2                #raise slightly
                   margin=margin(0,0,10,0)
),               
      
      plot.subtitle = element_text(          #subtitle
                   family = font,            #font family
                   #size = 14,                #font size
                   hjust = 0,
                   margin=margin(2,0,5,0)
),               
      
      plot.caption = element_text(           #caption
                   family = font,            #font family
                   size = 8,                 #font size
                   hjust = 1),               #right align
      
      axis.title = element_text(             #axis titles
                   family = font,            #font family
                   size = 10                 #font size
),
      
      axis.text = element_text(              #axis text
                   family = font,            #axis family
                   size = 8)               #font size
    )
}

# Set graph theme
theme_set(new = theme_custom())
#
```


```{r,echo = FALSE, eval = FALSE, fig.alt="Petr Slováček on Unsplash", fig.align='center'}
knitr::include_graphics("featured.jpg")

```

## {{< iconify icons8 idea >}} How does an MLP Learn?


- **Training Set**: Training is over several known input-output pairs ("training data")
- **Training Epoch**: For each input, the signals propagate forward until we have an output
- **Error Calculation**: Output is compared with **desired output**, to calculate *error*
- **Backpropagation**: Errors need to be *sent backward from the output* to input, where we unravel the error from layer $l$ to layer $l-1$. (like apportioning blame !!). 
- **Error-to-Cost**: How does error at a given neuron relate to overall Cost?
- **Differentiate**: Evaluate the *effect* of each weight/bias on ~~the (apportioned) error~~ overall Cost. (Slope!!)
- **Gradient Descent**: Adapt the weights/biases with a small step in the **opposite direction** to the slope


### Assumptions

1. **Training Error**: We can calculate overall training Cost as the average Cost taken over all input samples.
$$
C = \frac{1}{n}*\Sum_{x}C_x
$$

2. **Cost Function**: We will minimize the Cost function which is assumed to be a function of (all) outputs of a NN.

3. **Global Minimum**: Cost function has a global minimum! (Bowl shaped surface which we can descend)


## Here Comes the ~~Rain~~ Maths Again!

1. Rosenblatt-Nielsen's Demon: 
  - messes/perturbs with input to the sigmoid function at a neuron. (Weighted Sum)
  - Error = Slope * perturbation; 
  - However, **Error ~= Slope** when we allow that the perturbation is a fixed amplitude.
  - Still a product of slopes ;-O
  
$$
{\delta_j}^L = \frac{\delta C}{\delta {a_j}^L} * \sigma ({z_j}^L)
$${#eq-bp1}

:::: {.columns}

::: {.column width="48%"}
{{< video https://youtu.be/Ilg3gGewQ5U?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi >}}
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
{{< video https://youtu.be/tIeHLnjs5U8?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi >}}
:::
::::

## Neural Nets in Code

::: {.panel-tabset .nav-pills style="background: whitesmoke;"}

### Using p5.js


### Using R
Using `torch`.

:::


## References

1. Tariq Rashid. *Make your own Neural Network*. [PDF Online](https://github.com/harshitkgupta/StudyMaterial/blob/master/Make%20Your%20Own%20Neural%20Network%20(Tariq%20Rashid)%20-%20%7BCHB%20Books%7D.pdf)
1. Mathoverflow. *Intuitive Crutches for Higher Dimensional Thinking*. <https://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking>

