---
date: 23/Nov/2024
date-modified: "`r Sys.Date()`"
title: "MLPs and Backpropagation"
order: 40
summary: 
tags:
- Neural Nets
- Back Propagation
- Gradient
filters:
  - d2
d2:
  layout: elk
  theme: "CoolClassics"
  sketch: true

---


```{r setup, include=FALSE}
library(blogdown)
library(tidyverse)
library(ggformula)
library(mosaicCalc) # Analytic Calculus
library(neuralnet) # Backpropagation training
library(plot3D) # 3D plots for explanation
library(DiagrammeR)
library(DiagrammeRsvg)
##
#pak::pkg_install("elipousson/d2r")
library(d2r)

## Markdown boiler plate stuff!!
# ![An Elephant](elephant.png){#fig-elephant}
# This is illustrated well by @fig-elephant.
# 
# ### Figure Panel Divs
#     ::: {#fig-elephants layout-ncol=2}
#     ![Surus](surus.png){#fig-surus}
#     ![Hanno](hanno.png){#fig-hanno}
#      Famous Elephants
#     :::
#     Adding download buttons
#     data that has been read in
#     {{< downloadthis ../../../../materials/Data/housing_train.csv dname="house_prices" label="Download the House Prices Dataset" icon="database-fill-down" type="info" >}}
#    existing file
#    {{< downloadthis Orange/grouped-summaries.ows dname="grouped_summaries" label="Download the Orange Workflow" icon="database-fill-down" type="info" >}} 

```

```{r}
#| label: Extra Pedagogical Packages
#| echo: false
#| message: false

library(checkdown)
library(epoxy)
library(grateful)
library(MKdescr)
library(shinylive) # To create a Shiny app in a Quarto HTML doc
# Will not work if webr is also used in the SAME Quarto doc!
library(sysfonts)
library(gfonts)
library(kableExtra)
# library(conflicted)
# conflicted::conflicts_prefer(dplyr::filter, dplyr::count, dplyr::last, dplyr::glimpse, base::max)
library(downloadthis)
#devtools::install_github("mccarthy-m-g/embedr")
library(embedr) # Embed multimedia in HTML files
```

```{r}
#| label: Plot Sizing and theming
#| echo: false
#| message: false
#| results: hide

# https://stackoverflow.com/questions/74491138/ggplot-custom-fonts-not-working-in-quarto

# Chunk options
knitr::opts_chunk$set(
 fig.width = 7,
 fig.asp = 0.618, # Golden Ratio
 #out.width = "80%",
 fig.align = "center"
)
### Ggplot Theme
### https://rpubs.com/mclaire19/ggplot2-custom-themes

theme_custom <- function(){ 
    font <- "Roboto Condensed"   #assign font family up front
    
    theme_classic(base_size = 14) %+replace%    #replace elements we want to change
    
    theme(
      panel.grid.minor = element_blank(),    #strip minor gridlines
      text = element_text(family = font),
      #text elements
      plot.title = element_text(             #title
                   family = font,            #set font family
                   #size = 20,               #set font size
                   face = 'bold',            #bold typeface
                   hjust = 0,                #left align
                   #vjust = 2                #raise slightly
                   margin=margin(0,0,10,0)
),               
      
      plot.subtitle = element_text(          #subtitle
                   family = font,            #font family
                   #size = 14,                #font size
                   hjust = 0,
                   margin=margin(2,0,5,0)
),               
      
      plot.caption = element_text(           #caption
                   family = font,            #font family
                   size = 8,                 #font size
                   hjust = 1),               #right align
      
      axis.title = element_text(             #axis titles
                   family = font,            #font family
                   size = 10                 #font size
),
      
      axis.text = element_text(              #axis text
                   family = font,            #axis family
                   size = 8)               #font size
    )
}

# Set graph theme
theme_set(new = theme_custom())
#
```


```{r,echo = FALSE, eval = FALSE, fig.alt="Petr Slováček on Unsplash", fig.align='center'}
knitr::include_graphics("featured.jpg")

```


### How does an MLP Learn?

We saw how each layer works:

$$
\begin{bmatrix}
a_{12}\\
a_{22}\\
a_{32}\\
\end{bmatrix} = 
sigmoid~\Bigg(
\begin{bmatrix}
\color{red}{W^2_{11}} & \color{skyblue}{W^2_{21}} & \color{forestgreen}{W^2_{31}}\\
W^2_{12} & W^2_{22} & W^2_{32}\\
W^2_{13} & W^2_{23} & W^2_{33}\\
\end{bmatrix} * 
\begin{bmatrix}
\color{red}{a_{11}}\\
\color{skyblue}{a_{21}}\\
\color{forestgreen}{a_{31}}\\
\end{bmatrix} +
\begin{bmatrix}
b_{12}\\
b_{22}\\
b_{32}\\
\end{bmatrix}
\Bigg)
$$  {#eq-fwd-prop-1}



and:

$$
A^l = \sigma\Bigg(W^lA^{l-1} + B^l\Bigg)
$$ {#eq-fwd-prop-2}



See how the connections between neurons are marked by **weights**: these multiply the signal from the previous neuron. The multiplied/weighted products are added up in the neuron, and the sum is given to the activation block therein. 

So learning?

The only controllable variables in a neural network are these weights! So ***learning involves adapting these weights so that they can perform a useful function***. 

## What is the Learning Process?

The process of *adapting the weights* of a neural network can be described in the following steps:

- **Training Set**: Training is over several known input-output pairs ("training data")
- **Training Epoch**: For each input, the signals propagate forward until we have an output
- **Error Calculation**: Output is compared with **desired output**, to calculate *error*
- **Backpropagation**: Each neuron (and its weights) need to be told what is their share of the error! Errors therefore need to be *sent backward from the output* to input, unravelling them from layer $l$ to layer $l-1$. (like apportioning blame !!). 
- **Error-to-Cost**: How does error at *any* given neuron relate to the idea of an **overall Cost** function? Is the Cost function also **apportioned** in the same way?
- **Differentiate**: Evaluate the *effect* of each weight/bias on ~~the (apportioned) error~~ overall Cost. (Slope!!)
- **Gradient Descent**: Adapt the weights/biases with a small step in the **opposite direction** to the slope.

There.

### What is the Output Error?

If $d(k)$ are the desired outputs of the NN (over an entire training set), and $y(k)$ are the outputs of the ***output layer***, then we calculate the error **at the outputs** of the NN as:

$$
e(k) = a(k) - d(k)
$${#eq-error-function}

This error is calculated at *each output* for each training epoch/sample/batch. (More about the batch-mode in a bit.)

### What is the Cost Function?

We define the **cost** or **objective** function as the *squared error averaged over all neurons*:

$$
\begin{align}
C(W, b) &= \frac{1}{2n}\sum^{n ~ neurons}_{i=1}e^2(i)\\
\\
&= \frac{1}{2n}\sum^{n~neurons}_{k=1}(a_i - d_i)^2
\end{align}
$${#eq-cost-function}


The $a_i$s are the outputs of $n$ neurons and $d_i$ are the desired outputs for each of the training samples.

[The Cost Function is of course dependent upon the *Weights* and the *biases*]{.bg-light-red .black }, and is to be minimized by adapting these. Using the sum of *squared errors*, along with the *linear* operations in the NN guarantees that the Cost Function (usually) has one global, minimum. 

```{r}
#| label: quad-surface
#| eval: false
#| echo: false
#| message: false
#| warn: false


library(plotly)

df <- tibble(x = seq(1,100,1), 
             y = seq(1,100,1), 
             z = (x^2 + y^2)/1000 + 0.5)

df %>% plot_ly(x = ~x, y = ~y, z = ~z, color = ~z, 
               type = "surface") %>% 
  add_markers()

```

### What is Backpropagation of Error?

As we stated earlier, error is calculated at the output. In order to adapt **all weights**, we need to *send error proportionately back along the network*, towards the input. This proportional error will enable will give us a basis to adapt the individual weights anywhere in the network. 

What does "proportional" mean here? Consider the diagram below:


```{d2}
title: Error Backpropagated from e12 {
  shape: text
  near: top-center
  style: {
    font-size: 60
    italic: true
  }
}
direction: right
grid-columns: 3
grid-gap: 400

layer-1: {
  grid-columns: 1
  grid-gap: 100
  1 {shape: circle
     style: {
      font-size: 45
    }}
  2 {shape: circle
     style: {
      font-size: 45
    }}
  3 {shape: circle
     style: {
      font-size: 45
    }}
}
layer-2: {
  grid-columns: 1
  grid-gap: 100
  h1 {shape: circle
     style: {
      font-size: 45
    }}
  h2 {shape: circle
     style: {
      font-size: 45
    }}
  h3 {shape: circle
     style: {
      font-size: 45
    }}
}

layer-3: {
  grid-columns: 1
  grid-gap: 100
  style: {
    opacity: 0
  }
    e12: "e12" {shape: circle
     style: {
      font-size: 45
      stroke: white
      fill: white
    }}
    e22: "e22" {shape: circle
     style: {
      font-size: 45
      stroke: white
      fill: white
    }}
    e32: "e32" {shape: circle
     style: {
      font-size: 45
      stroke: white
      fill: white
     }
     }
}
layer-1.1 <-> layer-2.h1: W11 {
  source-arrowhead: e11
  style: {
    font-size: 45
    fill: LightBlue
    stroke: FireBrick
    stroke-width: 9
    animated: true
  }
}
layer-1.1 -> layer-2.h2
layer-1.1 -> layer-2.h3
layer-1.2 <-> layer-2.h1: W21 {
  source-arrowhead.label: e21
  style: {
    font-size: 45
    fill: LightBlue
    stroke: FireBrick
    stroke-width: 9
    animated: true
  }
}
layer-1.2 -> layer-2.h2
layer-1.2 -> layer-2.h3
layer-1.3 <-> layer-2.h1: W31 {
  source-arrowhead.label: e31
  style: {
    font-size: 45
    fill: LightBlue
    stroke: FireBrick
    stroke-width: 9
    animated: true
  }
}
layer-1.3 -> layer-2.h2
layer-1.3 -> layer-2.h3

layer-2.h1 <-> layer-3.e12 { style: {stroke-width: 9
         stroke: FireBrick}}
layer-2.h2 -> layer-3.e22
layer-2.h3 -> layer-3.e32

```

:::: {.columns}
::: {.column width=48%}

$$
\begin{align}
e_{11} ~~\pmb\sim~~ ~ e_{12} * \frac{W_{11}}{Sum~of~Weights~to~{\color{magenta}{\pmb{h_1}}}}\\
e_{21} ~~\pmb\sim~~ ~ e_{12} * \frac{W_{21}}{Sum~of~Weights~to~{\color{magenta}{\pmb{h_1}}}} \\
e_{31}~~\pmb\sim~~ ~ e_{12} * \frac{W_{31}}{Sum~of~Weights~to~\color{magenta}{\pmb{h_1}}} \\
\end{align}
$$
:::
::: {.column width=4%}
:::
::: {.column width=48%}

$$
\begin{align}
e_{11} ~~\pmb\sim~~ ~ e_{12} * \frac{W_{11}}{\pmb{\color{magenta}{W_{11} + W_{21} + W_{31}}}} \\
e_{21} ~~\pmb\sim~~ ~ e_{12} *\frac{W_{21}}{\pmb{\color{magenta}{W_{11} + W_{21} + W_{31}}}} \\
e_{31} ~~\pmb\sim~~ ~ e_{12} *\frac{W_{31}}{\pmb{\color{magenta}{W_{11} + W_{21} + W_{31}}}}  \\
\end{align}
$$
:::
::::

These are the contributions of the error $e_{12}$ to each of the previous neurons. 

Another way of looking at this:


```{d2}
title: Total Error at e11 {
  shape: text
  near: top-center
  style: {
    font-size: 60
    italic: true
  }
}
direction: right
grid-columns: 3
grid-gap: 400

layer-1: {
  grid-columns: 1
  grid-gap: 100
  1 {shape: circle
     style: {
      font-size: 45
    }}
  2 {shape: circle
     style: {
      font-size: 45
    }}
  3 {shape: circle
     style: {
      font-size: 45
    }}
}
layer-2: {
  grid-columns: 1
  grid-gap: 100
  h1 {shape: circle
     style: {
      font-size: 45
    }}
  h2 {shape: circle
     style: {
      font-size: 45
    }}
  h3 {shape: circle
     style: {
      font-size: 45
    }}
}

layer-3: {
  grid-columns: 1
  grid-gap: 100
  style: {
    opacity: 0
  }
    e12: "e12" {shape: circle
     style: {
      font-size: 45
      stroke: white
      fill: white
    }}
    e22: "e22" {shape: circle
     style: {
      font-size: 45
      stroke: white
      fill: white
    }}
    e32: "e32" {shape: circle
     style: {
      font-size: 45
      stroke: white
      fill: white
     }
     }
}
layer-1.1 <-> layer-2.h1: W11 {
  source-arrowhead.label: e11
  style: {
    font-size: 45
    fill: LightBlue
    stroke: FireBrick
    stroke-width: 9
    animated: true
  }
}
layer-1.1 <-> layer-2.h2: W12 {
  style: {
    font-size: 45
    fill: LightBlue
    stroke: FireBrick
    stroke-width: 9
    animated: true
  }
}
layer-1.1 <-> layer-2.h3: W13 {
  style: {
    font-size: 45
    fill: LightBlue
    stroke: FireBrick
    stroke-width: 9
    animated: true
  }
}
layer-1.2 -> layer-2.h1
layer-1.2 -> layer-2.h2{
  source-arrowhead.label: e21
  style: {
    font-size: 45
  }
}
layer-1.2 -> layer-2.h3
layer-1.3 -> layer-2.h1{
  source-arrowhead.label: e31
  style: {
    font-size: 45
  }
}
layer-1.3 -> layer-2.h2
layer-1.3 -> layer-2.h3

layer-2.h1 -> layer-3.e12 { style: {stroke-width:9 
         stroke: FireBrick}}
layer-2.h2 ->layer-3.e22  { style: {stroke-width:9
         stroke: FireBrick}}
layer-2.h3 ->layer-3.e32  { style: {stroke-width:9
         stroke: FireBrick}}

```

:::: {.columns}
::: {.column width=48%}
$$
\begin{align}
e_{11} =~ e_{12} * \frac{W_{11}}{Sum~of~weights~to~{\color{orange}{\pmb {h_1}}}}\\
+ ~ e_{22} * \frac{W_{21}}{Sum~of~Weights~to~\color{pink}{\pmb{h_2}}} \\
+ ~ e_{32} * \frac{W_{31}}{Sum~of~Weights~to~\color{teal}{\pmb{h_3}}}  \\
\end{align}
$$
:::
::: {.column width=4%}
:::
::: {.column width=48%}
$$
\begin{align}
e_{11} = ~ e_{12} * \frac{W_{11}}{\pmb{\color{orange}{W_{11} + W_{21} + W_{31}}}}\\
+ ~e_{22} * \frac{W_{12}}{\pmb{\color{pink}{W_{12} + W_{22} + W_{32}}}} \\
+ ~e_{32} * \frac{W_{13}}{\pmb{\color{teal}{W_{13} + W_{23} + W_{33}}}}  \\
\end{align}
$$


$$
\begin{align}
e_{21} = similar~expression!!\\
\
e_{31} = similar~expression!!\\
\end{align}
$$
:::
::::

[Equation corrected by Gayatri Jadhav, April 2025]{.aside}

This is the ***total error*** at $e_{11}$ from all the three output errors. So:

- We have taken each output error, $e_{*2}$ and parcelled it back to the preceding neurons ***in proportion to the connecting Weight***. This makes intuitive sense; we are making those neurons put their money where their mouth is. As [Nassim Nicholas Taleb](https://philosophiatopics.wordpress.com/wp-content/uploads/2018/10/skin-in-the-game-nassim-nicholas-taleb.pdf) says, people (and neurons!) need to pay for their opinions, especially when things go wrong!
- The *accumulated error* at each neuron in layer $l-1$ is the weighted sum of back-propagated error contributions from all layer $l$ neurons to which we are connected. 
- So we can compactly write the relationships above as:

$$
\begin{bmatrix}
e_{11}\\
e_{21}\\
e_{31}\\
\end{bmatrix} = 
\Bigg(
\begin{bmatrix}
\frac{W_{11}}{D_{11}} & \frac{W_{12}}{D_{12}} & \frac{W_{13}}{D_{13}}\\
\frac{W_{21}}{D_{21}} & \frac{W_{22}}{D_{22}} & \frac{W_{23}}{D_{23}}\\
\frac{W_{31}}{D_{31}} & \frac{W_{32}}{D_{32}} & \frac{W_{33}}{D_{33}}\\
\end{bmatrix} * 
\begin{bmatrix}
{e_{12}}\\
{e_{22}}\\
{e_{32}}\\
\end{bmatrix}
\Bigg)
$$

The denominators make things look complicated! But if we are able to [simply ignore them]{.black .bg-light-red} for a moment, then we see a very interesting thing:

$$
\begin{bmatrix}
e_{11}\\
e_{21}\\
e_{31}\\
\end{bmatrix} \pmb{\sim}
\begin{bmatrix}
W_{11} & W_{12} & W_{13} \\
W_{21} & W_{22}  & W_{23} \\
W_{31} & W_{32} & W_{33} \\
\end{bmatrix} * 
\begin{bmatrix}
{e_{12}}\\
{e_{22}}\\
{e_{32}}\\
\end{bmatrix}
$$

[This new *approximate* matrix is the **tranpose** of our original Weight matrix]{.black .bg-light-red} from @eq-fwd-prop-1! The rows there have become columns here!! That makes intuitive sense: in the forward information direction, we were accounting for information from the point of view of the ***destinations***; in the reverse error backpropagation direction, we are accounting for information from the point of view of the ***sources***.

Writing this equation in a compact way:

$$
\Large{e^{l-1} ~ \pmb{\sim} ~ {W^l}^{\pmb{\color{red}{T}}}* e^{l}}
$${#eq-Back-Prop}

This is our equation for backpropagation of error. 

Why is ignoring all those *individual* denominators justified? Let us park that question until we have understood the one last step in NN training, the [Gradient Descent.](../50-GradientDescent/index.qmd)


::: {.content-hidden}
## Backpropagation Numerically Demonstrated

```{d2}
direction: right
grid-columns: 6
grid-rows: 3
###
in1.style.opacity: 0
in2.style.opacity: 0
in3.style.opacity: 0
1.shape: circle
2.shape: circle
3.shape: circle
h1.shape: circle
h2.shape: circle
h3.shape: circle
o1.shape: circle
# o1 {
#   icon: https://icons.terrastruct.com/infra/019-network.svg
# }
o2.shape: circle
o3.shape: circle
out1.style.opacity: 0
out2.style.opacity: 0
out3.style.opacity: 0
###
in1 -> 1
in2 -> 2
in3 -> 3
1 -> h1: w21 {
  style: {
    stroke: deepskyblue}
}
1 -> h2: W21 {
  style: {
  fill: LightBlue
  stroke: FireBrick
  stroke-width: 2
  animated: true
  }
}
1 -> h3
2 -> h1
2 -> h2
2 -> h3
3 -> h1
3 -> h2
3 -> h3
h1 -> o1
h2 -> o1
h3 -> o1
h1 -> o2
h2 -> o2
h3 -> o2
h1 -> o3
h2 -> o3
h3 -> o3

o1 -> out1
o2 -> out2
o3 -> out3

```
:::


## Here Comes the ~~Rain~~ Maths Again!

Now, we are ready (maybe?) to watch these two very beautifully made videos on Backpropagation. One is of course from Dan Shiffman, and the other from Grant Sanderson a.ka. 3Blue1Brown.

:::: {.columns}

::: {.column width="48%"}
{{< video https://youtu.be/QJoa0JYaX1I?list=PLRqwX-V7Uu6Y7MdSCaIfsxc561QI0U0Tb >}}
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
{{< video https://youtu.be/tIeHLnjs5U8?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi >}}
:::
::::

## Backpropagation in Code

::: {.panel-tabset .nav-pills style="background: whitesmoke "}

### Using p5.js


### Using R
Using `torch`.

:::


## References

1. Tariq Rashid. *Make your own Neural Network*. [PDF Online](https://github.com/harshitkgupta/StudyMaterial/blob/master/Make%20Your%20Own%20Neural%20Network%20(Tariq%20Rashid)%20-%20%7BCHB%20Books%7D.pdf)
1. Mathoverflow. *Intuitive Crutches for Higher Dimensional Thinking*. <https://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking>
1. Interactive Backpropagation Explainer <https://xnought.github.io/backprop-explainer/>

