---
title: "\U0001F0CF Inference for Comparing Two Paired Means"
author: "Arvind Venkatadri"
date: 10/Nov/2022
subtitle: ""
date-modified: "`r Sys.Date()`"
order: 120
tags:
- Permutation
- Monte Carlo Simulation
- Random Number Generation
- Distributions
- Generating Parallel Worlds
---

## {{< iconify noto-v1 package >}} Setting up R Packages

```{r}
#| label: setup
#| include: true

knitr::opts_chunk$set(echo = FALSE,message = TRUE, warning = TRUE, fig.align = "center")
library(tidyverse)
library(mosaic)
library(broom)

### Datasets from Chihara and Hesterberg's book (Second Edition)
library(resampledata)
library(nomnoml)
```

## {{< iconify fluent pair-24-filled >}} What is Paired Data?

## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction to Inference for Paired Data

```{mermaid}
flowchart TD
    A[Inference for Paire Means] -->|Check Assumptions| B[Normality: Shapiro-Wilk Test shapiro.test\n Variances: Fisher F-test var.test]
    B --> C{OK?}
    C -->|Yes, both\n Parametric| D[t.test]
    D <-->F[Linear Model\n Method] 
    C -->|Yes, but not variance\n Parametric| W[t.test with\n Welch Correction]
    W<-->F
    C -->|No\n Non-Parametric| E[wilcox.test]
    E <--> G[Linear Model\n with\n Signed-Ranks]
    C -->|No\n Non-Parametric| P[Bootstrap\n or\n Permutation]
    P <--> Q[Linear Model\n with Signed-Rank\n with Permutation]
 
```

We will now use a couple to case studies to traverse all the possible
pathways in the Workflow above.

## {{< iconify pajamas issue-type-test-case >}} Case Study #1: Results from a Diving Championship

Sometimes the data is collected on the same set of individual
categories, e.g. scores by sport persons in two separate tournaments, or
sales of identical items in two separate locations of a chain store.
Here we have swimming records across a Semi-Final and a Final:

### {{< iconify carbon chart-3d >}} Inspecting and Charting Data

```{r}
#| layout-nrow: 2
data("Diving2017")
Diving2017
inspect(Diving2017)

```

The data is made up of **paired** observations per swimmer, one for the
*semi-final* and one for the *final* race. There are 12 swimmers and
therefore 12 paired records. How can we quickly visualize this data?

First, histograms and densities of the two variables at hand:

```{r}
#| layout-ncol: 3
Diving2017 %>% 
  gf_density(~ Semifinal, fill = "red", alpha = 0.3, 
                title = "Semifinal Scores") %>% 
  gf_fitdistr() %>% gf_theme(theme_classic())

Diving2017 %>% 
  gf_density(~ Final, fill = "green", alpha = 0.3, 
                title = "Final Scores") %>% 
  gf_fitdistr() %>% gf_theme(theme_classic())


Diving2017 %>% 
  gf_col(fct_reorder(Name, Semifinal) ~ Semifinal, fill = "red") %>% 
  gf_col(fct_reorder(Name, Semifinal) ~ -Final, fill = "green",
         xlab = "Scores",
         ylab = "Name",
         title = "Diving Scores",
         subtitle = "Green = Final, Red = Semifinal") %>% 
  gf_theme(theme_classic())

```

We see that:\
- The data are not normally distributed. With just such few readings (n
\< 30) it was quite unlikely. We will verify this aspect formally very
shortly.Â  - There is no immediately identifiable **trend** in score
changes from one race to the other.\

A. {{< iconify mdi chart-bell-curve >}} Check for Normality Let us also
complete a check for normality:

```{r}
#| layout-ncol: 2
shapiro.test(Diving2017$Final)
shapiro.test(Diving2017$Semifinal)

```

Hmmm....the Shapiro-Wilk test suggests that `Final` scores **are**
normally distributed, while `Semifinal` scores are not.

B. Check for Variances Let us check if the two variables have similar
variances:

```{r}
var.test(Diving2017$Semifinal, Diving2017$Final)
```

The variances are not equal.

### {{< iconify academicons hypothesis >}} Hypothesis

Based on the graph, how would we formulate our Hypothesis? We wish to
infer whether there is any change in performance, **per swimmer**
between the two races. So accordingly:

$$
H_0: \mu_{semifinal} = \mu_{final}\\
$$

$$
H_a: \mu_{semifinal} \ne \mu_{final}\
$$

What is the difference in the means between the two groups of scores? In
order to ensure that the records are `paired`, we use the argument
`only.2=FALSE` in the `diffmean` function:

```{r}
#| layout: [[40,10,10]]
Diving2017
Diving2017 %>% 
  diffmean(data = ., Final ~ Semifinal, only.2 = FALSE) %>% 
  as_tibble() %>% 
  rename("difference" = value)

obs_diff_swim <- mean(~ Final - Semifinal, data = Diving2017)
obs_diff_swim

```

### Inference

::: panel-tabset
#### Using *paired* `t.test`

Since at least one of the data variables satisfies the assumption of
being *normally distributed*, and though the variances are not equal,
but not terribly far apart, we may attempt the classical `t.test` with
paired data. (we will the `mosaic` variant)[Type `help(t.test)` in your
Console]{.aside}

```{r}
mosaic::t.test(x = Diving2017$Semifinal, y = Diving2017$Final,
               paired = TRUE)
```

The `confidence interval` spans the zero value, and the `p.value` is a
high $0.259$, so there is no reason to accept alternative hypothesis
that the means are different. Hence we say that there is no evidence of
a difference between `SemiFinal` and `Final` scores.

#### Using non-parametric *paired* Wilcoxon test

Well, at least one of the variable does not meet the normality criteria.
So we would be well-advised to attempt a non-parametric Wilcoxon test,
that uses rank-sign data, instead of the data itself. Our model would
be:

$$
rank(y_i) = \beta_0 + \beta_1 * rank(x_i) \\
where \\
x_i= \left\{\begin{matrix}
1\ when\ x\ \in\ Group 1\\ 
0\ when\ x\ \in\ Group2
\end{matrix}\right.
\\
H_0 : \beta_1 = 0
\\
H_a: \beta_1 \ne 0
$$

```{r}
wilcox.test(x = Diving2017$Semifinal, y = Diving2017$Final,
               paired = TRUE)
```

Here also with the `p.value` being $0.3804$, we have no reason to accept
the Alternative Hypothesis.

#### Using the Linear Model Method

```{r}
#| layout-ncol: 2
linmod <- lm(Semifinal ~ Final, data = Diving2017)
summary(linmod)

# Create a sign-rank function
signed_rank <- function(x) {sign(x) * rank(abs(x))}

linmod_ranks <- lm(signed_rank(Semifinal) ~ signed_rank(Final), data = Diving2017)
summary(linmod_ranks)

```

#### Using Permutation Tests

We saw from the diagram created by Allen Downey that *there is only one
test*! We will now use this philosophy to develop a technique that
allows us to mechanize several *Statistical Models* in that way, with
nearly identical code.We will use two packages in R, `mosaic` and the
relatively new `infer`package, to develop our intuition for what are
called **permutation** based statistical tests. For the specific data at
hand, we need to take the difference between the two swim records for
*each* swimmer and then shuffle the records between `Semifinal` and
`Final` on a per Swimmer basis.Another way to look at this is to take
the differences between `Semifinal` and `Final` scores and *shuffle the
differences to either polarity*.

```{r}
#| layout-ncol: 2
polarity <- c(rep(1, 6), rep(-1, 6)) 
# 12 +/- 1s, 
# 6 each to make sure there is equal probability
polarity

null_dist_swim <- do(100000) *
  mean(data = Diving2017,
       ~ (Final - Semifinal) * mosaic::resample(polarity, replace = TRUE))

null_dist_swim

```

Let us plot the NULL distribution and compare it with the actual
`observed differences` in the race times:

```{r}
#| layout-ncol: 2
gf_histogram(data = null_dist_swim, ~ mean) %>%
  gf_vline(xintercept = obs_diff_swim, colour = "red") %>% 
  gf_theme(theme_classic())

gf_ecdf(data = null_dist_swim, ~ mean) %>%
  gf_vline(xintercept = obs_diff_swim, colour = "red")  %>% 
  gf_theme(theme_classic())


prop1(~ mean >= obs_diff_swim, data = null_dist_swim)


```

Hmm...so by generating 100000 shufflings of score differences, with
polarities, it does appear that we can not only obtain the current
observed difference but even surpass it frequently. So it does seem that
there is no difference in means between Semi-Final and Final swimming
scores.
:::

## {{< iconify pajamas issue-type-test-case >}} Case Study #2: Walmart vs Target

Is there a difference in the price of Groceries sold by the two
retailers Target and Walmart? The data set `Groceries` contains a sample
of grocery items and their prices advertised on their respective web
sites on one specific day.

a)  Inspect the data set, then explain why this is an example of matched
    pairs data.
b)  Compute summary statistics of the prices for each store.
c)  Conduct a permutation test to determine whether or not there is a
    difference in the mean prices.
d)  Create a ~~histogram~~ bar-chart of the difference in prices. What
    is unusual about Quaker Oats Life cereal?
e)  Redo the hypothesis test without this observation. Do you reach the
    same conclusion?

### {{< iconify carbon chart-3d >}} Inspecting and Charting Data

```{r}
data("Groceries")
Groceries <- Groceries %>% 
  mutate(Product = stringr::str_squish(Product))
Groceries
inspect(Groceries)

```

There are just 30 prices for each vendor....just barely enough to get an
idea of what the distribution might be. Let us plot histograms/densities
of the two variables that we wish to compare. We will also overlay a
Gaussian distribution for comparison:

```{r}
#| layout-ncol: 2
#| layout-nrow: 2
Groceries %>% 
  gf_dhistogram(~ Walmart, fill = "red", alpha = 0.3, title = "Walmart Grocery Prices") %>% 
  gf_fitdistr(dist = "dnorm") %>% 
  gf_theme(theme_classic())

Groceries %>% 
  gf_dhistogram(~ Target, fill = "green", alpha = 0.3, title = "Target Grocery Prices") %>% 
  gf_fitdistr(dist = "dnorm") %>% 
  gf_theme(theme_classic())


Groceries %>% 
  gf_density(~ Walmart, fill = "red", alpha = 0.3, title = "Walmart Grocery Prices") %>% 
  gf_fitdistr(dist = "dnorm") %>% 
  gf_theme(theme_classic())

Groceries %>% 
  gf_density(~ Target, fill = "green", alpha = 0.3, title = "Target Grocery Prices") %>% 
  gf_fitdistr(dist = "dnorm") %>% 
  gf_theme(theme_classic())

```

Not close to the Gaussian...there is clearly some skew to the right,
with some items being very costly compared to the rest. More when we
check the assumptions on data for the tests.

How about price differences, what we are interested in? We see that the
comparison is to be made between two prices for the *same* product, and
hence this is one more example of `paired data`. Let us plot the prices
for the products:

```{r}

gf_col(data = Groceries,
       Target ~ Product,
       fill = "#0073C299",
       width = 0.5, title = "Grocery Prices at Walmart and Target",
       subtitle = "Gold = Walmart, Blue = Target") %>% 
  gf_col(data = Groceries,
         -Walmart ~ Product,
         fill = "#EFC00099",
         ylab = "Prices",
         width = 0.5
       ) %>% 
  gf_col(data = Groceries %>% filter(Product == "Quaker Oats Life Cereal Original"), 
         -Walmart ~ Product,
         fill = "red", 
         width = 0.5) %>% 
  gf_theme(theme_classic()) %>%
  gf_theme(ggplot2::theme(axis.text.x = element_text(
    size = 8,
    face = "bold",
    vjust = 0,
    hjust = 1
  ))) %>% gf_theme(ggplot2::coord_flip())

```

We see that the price difference between Walmart and Target prices is
highest for the `Product` named `Quaker Oats Life Cereal Original`. Let
us check the mean difference in prices:

```{r}
#| layout: [[75, 25]]
diffmean(data = Groceries, Walmart ~ Target, only.2 = FALSE) %>% 
  as_tibble() %>% 
  rename("Difference" = value)
obs_diff_price <-  mean( ~ Walmart - Target, data = Groceries)
obs_diff_price

```

### {{< iconify academicons hypothesis >}} Hypothesis

Based on the graph, how would we formulate our Hypothesis? We wish to
infer whether there is any change in prices, **per product** between the
two Store chains. So accordingly:

$$
H_0: \mu_{Walmart} = \mu_{Target}\\
\\
H_a: \mu_{Walmart} \ne \mu_{Target}\
$$

### Testing for Assumptions on the Data

There are a few checks we need to make of our data, to decide what test
procedure to use.

A. Test for Normality of Data

```{r}
shapiro.test(Groceries$Walmart)
shapiro.test(Groceries$Target)

```

For both tests, we see that the `p.value` is very small, indicating that
the data are unlikely to be normally distributed. This means we cannot
apply a standard `paired t.test` and need to use other non-parametric
tests, that do no rely on the assumption of normality.

### {{< iconify fluent-mdl2 insights >}} Inference

::: panel-tabset
#### Using *paired* `t.test`

#### Using non-parametric *paired* Wilcoxon test

#### Using Permutation Tests

Let us perform the pair-wise permutation test on prices, by shuffling
the two store names:

```{r}

polarity <- c(rep(1, 15), rep(-1,15))
polarity
null_dist_price <- do(100000) * mean(data = Groceries, 
                                    ~(Walmart-Target) * resample(polarity,
                                                    replace = TRUE))
null_dist_price %>% head()
gf_histogram(data = null_dist_price, ~mean) %>% 
  gf_vline(xintercept = obs_diff_price, colour = "red")

2*(sum(null_dist_price >= obs_diff_price + 1)/(100000+1)) #P-value

```

Does not seem to be any significant difference in prices...

Suppose we knock off the `Quaker Cereal` data item...

```{r}

which(Groceries$Product == "Quaker Oats Life Cereal Original")
Groceries_less <- Groceries[-2,]
Groceries_less


obs_diff_price_less = mean( ~ Walmart - Target, data = Groceries_less)
obs_diff_price_less
polarity_less <- c(rep(1, 15), rep(-1,14)) # Due to resampling this small bias makes no difference
null_dist_price_less <- do(100000) * mean(data = Groceries_less, 
                                    ~(Walmart-Target) * resample(polarity_less,
                                                    replace = TRUE))
null_dist_price_less %>% head()
gf_histogram(data = null_dist_price_less, ~mean) %>% 
  gf_vline(xintercept = obs_diff_price_less, colour = "red")

1- mean(null_dist_price_less >= obs_diff_price_less) #P-value

```

Comments:
:::

## {{< iconify fluent-mdl2 decision-solid >}} Conclusion

It should be fairly clear now that we can test for the equivalence of
two paired means, using a very simple permutation tests. Given computing
power, we can always mechanize this test very quickly to get our
results. And that performing this test yields reliable results without
having to rely on any assumption relating to underlying distributions
and so on.

## {{< iconify ooui references-ltr >}} References

1.  Randall Pruim, Nicholas J. Horton, Daniel T. Kaplan, [*Start
    Teaching with
    R*](https://github.com/ProjectMOSAIC/LittleBooks/raw/master/Starting/MOSAIC-StartTeaching.pdf)
2.  <https://bcs.wiley.com/he-bcs/Books?action=index&itemId=111941654X&bcsId=11307>
