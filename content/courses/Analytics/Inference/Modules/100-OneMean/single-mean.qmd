---
title: "\U0001F0CF Inference for a Single Mean"
subtitle: "“The more I love humanity in general, the less I love man in particular. ― Fyodor Dostoyevsky, The Brothers Karamazov"
date: 10/Nov/2022
date-modified: "`r Sys.Date()`"
abstract: "Inference Tests to check the significance of a single Mean"
order: 100
categories:
- t.test
- Linear Model
- Inference
- Bootstrap
- Null Distributions
- Generating Parallel Worlds
bibliography: 
  - grateful-refs.bib
citation: true
#suppress-bibliography: true
---

## {{< iconify noto-v1 package >}} Setting up R packages

```{r}
#| label: setup
#| include: true
#| message: false
#| warning: false
knitr::opts_chunk$set(echo = TRUE,message = TRUE,warning = TRUE, fig.align = "center")
options(digits=2)
library(tidyverse)
library(mosaic)
library(infer)
### Dataset from Chihara and Hesterberg's book (Second Edition)
library(resampledata)
library(openintro) # datasets
library(explore) # New, Easy package for Stats Test and Viz, and other things

```


```{r}
#| label: Extra Pedagogical Packages
#| echo: false
#| message: false

library(checkdown)
library(epoxy)
library(TeachHist)
library(TeachingDemos)
library(grateful)

```

```{r}
#| label: Plot Sizing and theming
#| echo: false
#| message: false
#| results: hide

# https://stackoverflow.com/questions/74491138/ggplot-custom-fonts-not-working-in-quarto

# Chunk options
knitr::opts_chunk$set(
 fig.width = 7,
 fig.asp = 0.618, # Golden Ratio
 #out.width = "80%",
 fig.align = "center"
)
### Ggplot Theme
### https://rpubs.com/mclaire19/ggplot2-custom-themes

theme_custom <- function(){ 
    font <- "Roboto Condensed"   #assign font family up front
    
    theme_classic(base_size = 14) %+replace%    #replace elements we want to change
    
    theme(
      panel.grid.minor = element_blank(),    #strip minor gridlines
      text = element_text(family = font),
      #text elements
      plot.title = element_text(             #title
                   family = font,            #set font family
                   #size = 20,               #set font size
                   face = 'bold',            #bold typeface
                   hjust = 0,                #left align
                   #vjust = 2                #raise slightly
                   margin=margin(0,0,10,0)
),               
      
      plot.subtitle = element_text(          #subtitle
                   family = font,            #font family
                   #size = 14,                #font size
                   hjust = 0,
                   margin=margin(2,0,5,0)
),               
      
      plot.caption = element_text(           #caption
                   family = font,            #font family
                   size = 8,                 #font size
                   hjust = 1),               #right align
      
      axis.title = element_text(             #axis titles
                   family = font,            #font family
                   size = 10                 #font size
),
      
      axis.text = element_text(              #axis text
                   family = font,            #axis family
                   size = 8)               #font size
    )
}

# Set graph theme
theme_set(new = theme_custom())
#
```


## Introduction

We saw from the diagram created by Allen Downey that *there is only one
test* [^1]! We will now use this philosophy to develop a technique that
allows us to mechanize several *Statistical Models* in that way, with
nearly identical code.

We will use two packages in R, `mosaic` to develop our intuition for
what are called **bootstrap randomization** based statistical tests.
(There is also a more recent package called `infer` in R which can do
pretty much all of this, including visualization. In my opinion, the
code is a little too high-level and does not offer quite the detailed
insight that the `mosaic` package does).

## {{< iconify pajamas issue-type-test-case >}} Case Study #1: Toy data

First we will use a toy dataset with three "imaginary" samples,
$x, y, y2$. Each is normally distributed and made up of 50 observations.

We start by creating a function that will allow us to produce samples of
a given size (N) with a specified mean (mu) and standard deviation (sd).

```{r data_genr}
rnorm_fixed  <- function(N, mu = 0, sd = 1) {
  scale(rnorm(N))* sd + mu
}
```

We create three variables: x ( explanatory) and y, y2 ( dependent ).

```{r toy_data}
#| layout-ncol: 3
#| column: body-outset-right
set.seed(40) # for replication

# Data as vectors ( for t.tests etc)
x <- rnorm_fixed(50, mu = 0.0, sd = 1) #explanatory
y <- rnorm_fixed(50, mu = 0.3, sd = 2) # dependent #1
y2 <- rnorm_fixed(50, mu = 0.5, sd = 1.5) # dependent #2

# Make a tibble with all variables
mydata_wide <- tibble(x = x, y = y, y2 = y2)

# Long form data
mydata_long <- 
  mydata_wide %>%
  pivot_longer(., cols = c(x,y,y2), 
               names_to = "group", 
               values_to = "value")

# Long form data with only dependent variables
mydata_long_y <- 
  mydata_wide %>% 
  select(-x) %>% 
  pivot_longer(., cols = c(y,y2), 
               names_to = "group", 
               values_to = "value")
mydata_wide
mydata_long
mydata_long_y
```

## "Signed Rank" Values

Most statistical tests use the **actual values** of the data variables.
However, in some *non-parametric* statistical tests, the data are used
in **rank-transformed** sense/order. In some cases the **signed-rank**
of the data values is used instead of the data itself.

Signed Rank is calculated as follows:\
1. Take the absolute value of each observation in a sample\
2. Place the <u>*ranks*</u> in order of (absolute magnitude). The
smallest number has *rank = 1* and so on.\
3. Give each of the ranks the sign of the original observation ( + or -
)

```{r signed_rank_function}
signed_rank <- function(x) {sign(x) * rank(abs(x))}
```

## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction to Inference for a Single Mean

A series of tests deal with one mean value of a sample. The idea is to
evaluate whether that mean is representative of the mean of the
underlying population. Depending upon the nature of the (single)
variable, the test that can be used are as follows:

```{mermaid}
%%| echo: false
flowchart TD
    A[Inference for Single Mean] -->|Check Assumptions| B[Normality: Shapiro-Wilk Test shapiro.test\n]
    B --> C{OK?}
    C -->|Yes\n Parametric| D[t.test]
    D <-->F[Linear Model\n with Data] 
    C -->|No\n Non-Parametric| E[wilcox.test]
    E <--> G[Linear Model\n with\n Signed-Ranks of Data]
    C -->|No\n Non-Parametric| P[Bootstrap]
    P <--> Q[Linear Model\n with Signed-Rank\n with Bootstrap]
 
```

## {{< iconify carbon chart-3d >}} Inspecting and Charting Data

### Testing Assumptions in the Data

### Inference

::: {.panel-tabset .nav-pills style="background: whitesmoke;"}

#### The Student's t-test with one sample {.tabset}

A. Model

A single number predicts y:

$$ 
y = \beta_0 + \beta_1*x \\
$$ $$
\\and\ further \\
$$ $$
y = \beta_0\
$$

and the second term vanishes, since "there is no x": all the x-values
are made equal to zero in the linear model for a **single variable** !!
The NULL Hypothesis therefore is:

$$
\ H_0: \beta_0 = 0
$$

Note that if we **want** the NULL hypothesis to be that the mean is
other than zero, we can use

$$
H_0:\ \beta_0 = \mu \ne 0
$$ the `lm(...., mu = some_number, ..)` parameter in the command in the
code.

B. Code

If we compare the `t.test` with the appropriate `lm` model:

```{r t_test_one_mean}
# t-test
t1 <- t.test(y, mu = 0, alternative = "two.sided")
print(t1)

```

So even though y has a mean of 0.3, the confidence intervals straddle
zero, and hence we cannot reject the NULL hypothesis that the true
population, of which y is a sample, could have mean=0.

#### Wilcoxon's Signed-Rank Test

Since we are dealing with the **mean**, the *sign* of the rank becomes
important to use, in the case of a non-parametric single mean test.

A. Model

$$
signed\_rank(y) = \beta_0 \\
H_0: \beta_0 = 0
$$

B. Code

```{r Wilcoxon_Signed_Rank_test_One_Mean}
# Standard Wilcoxon Signed_Rank Test
w1 <- wilcox.test(y)
w1
# Wilcoxon test with lm
w2 <- lm(signed_rank(y) ~ 1 , data = mydata_wide)
w2

# t-test with signed_rank data
w3 <- t.test(signed_rank(y))
w3
```

#### Linear Model

```{r}

# linear model
lm1 <- lm(y ~ 1, data = mydata_wide)
lm1 %>% summary()
lm1 %>% confint()
```

The confidence intervals for both the `t.test` and the `lm` model are
identical.

t-test confidence intervals: `r t1$conf.int`\
linear model confidence intervals: `r confint(lm1)`

#### Using bootstrap

#### Plots

We can plot the y data both original and ranked to see where the mean
lies in each case. The approximation to the true $\beta_0$ ( is good
when the number of observations $n >=50$. Lindoloev has a <u>[simulation on
this.](https://lindeloev.github.io/tests-as-linear/simulations/simulate_wilcoxon.html)</u>.
We can also plot the model using *lm* for both the original data and the
sign-ranked data.

```{r Mean_Related_Plots}

# Set graph theme
theme_set(new = theme_custom())
#
p1 <- ggplot(mydata_wide, aes( x = 0, y = y)) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = t1$estimate, 
                   yend = t1$estimate, 
                   x = -0.2, xend = 0.2)) + 
  labs(title = "Student's\n t-Test")

# t-test using linear model
p2 <- ggplot(mydata_wide, aes( x = 0, y = y)) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = lm(y ~ 1)$coefficient, 
                   yend = lm(y ~ 1)$coefficient, 
                   x = -0.2, xend = 0.2)) + 
  labs(title = "Student's\n t-Test \n using lm")

# Wilcoxon test, using signed-ranks of data
p3 <- ggplot(mydata_wide, aes( x = 0, y = signed_rank(y))) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = mean(signed_rank(y)), yend = mean(signed_rank(y)), x = -0.2, xend = 0.2)) + 
  labs(title = "Wilcoxon \nSigned-Rank\n Test")

# Wilcoxon test, using signed-ranks of data, and lm
p4 <- ggplot(mydata_wide, aes( x = 0, y = signed_rank(y))) +
  geom_point(alpha = 0.4) +
  geom_segment(aes(y = lm(signed_rank(y) ~1)$coefficient, 
                   yend = lm(signed_rank(y) ~1)$coefficient, 
                   x = -0.2, xend = 0.2)) + 
  labs(title = "Wilcoxon \n Signed-Rank \n Test with lm")


patchwork::wrap_plots(p1,p2,p3,p4, nrow = 1, guides = "collect")

```
:::

## {{< iconify pajamas issue-type-test-case >}} Case Study #2: Exam data

Let us now choose a dataset from the `openintro` package:

```{r}
data("exam_grades")
exam_grades
```

### {{< iconify carbon chart-3d >}} Inspecting and Charting Data

### Testing Assumptions in the Data

### Inference

::: {.panel-tabset .nav-pills style="background: whitesmoke;"}

#### t.test

#### Wilcoxon test

#### Linear Model

#### Using Bootstrap

#### Plots

:::

## {{< iconify fluent-mdl2 decision-solid >}} Conclusion
TBW

## {{< iconify ooui references-rtl >}} References {#sec-references}

1. OpenIntro Modern Statistics, [Chapter #17](https://openintro-ims.netlify.app/inference-one-prop.html)

::: {#refs style="font-size: 60%;"}
###### {{< iconify lucide package-check >}} R Package Citations
```{r}
#| echo: false
#scan_packages()
cite_packages(
  output = "table",
  out.dir = ".",
  out.format = "html",
  pkgs = c("explore", "resampledata", "openintro", "infer", "TeachHist",
           "TeachingDemos")
) %>%
  knitr::kable(format = "simple")

```


:::

[^1]: <https://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html>


