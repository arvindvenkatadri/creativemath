---
title: "Tutorial: Multiple Linear Regression with Forward Selection"
author: "Arvind Venkatadri"
date: 13/May/2023
date-modified: "`r Sys.Date()`"
categories: 
  - Linear Regression
  - Quantitative Predictor
  - Quantitative Response
  - Sum of Squares
  - Residuals
abstract: "Using Multiple Regression to predict Quantitative Target Variables"
---

## {{< iconify noto-v1 package >}} Setting up R Packages

```{r}
#| label: setup
#| message: true
#| warning: false
options(scipen = 1, digits = 3) #set to three decimal 
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE) 
library(tidyverse)
library(ggformula)
library(mosaic)
library(infer)

library(nycflights13)

```

```{r}
#| label: plot theme
# Let us set a plot theme for Data visualisation

my_theme <- function(){  # Creating a function
  theme_classic() +  # Using pre-defined theme as base
  theme(axis.text.x = element_text(size = 12, face = "bold"),  # Customizing axes text      
        axis.text.y = element_text(size = 12, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),  # Customizing axis title
        panel.grid = element_blank(),  # Taking off the default grid
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , "cm"),
        legend.text = element_text(size = 12, face = "italic"),  # Customizing legend text
        legend.title = element_text(size = 12, face = "bold"),  # Customizing legend title
        legend.position = "right",  # Customizing legend position
        plot.caption = element_text(size = 12))  # Customizing plot caption
}   

```

In this tutorial, we will use the ~~Boston housing~~ `nycflights13`
dataset**(s)**. Our research question is:

::: callout-note
## Research Question

How do we predict the ~~price of a house in Boston~~ flight departure
delay from airports in New York, based on other **Quantitative**
parameters such as ~~area, location, rooms, and crime-rate in the
neighbourhood~~ date, time, and weather?

And how do we choose the "best" model, based on a trade-off between
Model Complexity and Model Accuracy?
:::

## {{< iconify flat-color-icons:workflow >}} Workflow Plan

Our target variable is `dep_delay`.

We will start with an examination of correlations between `dep_delay`
and other Quant predictors. (We will restrict ourselves to the top 5,
based on correlation scores.)

We will use a single quantitative predictor for our Linear Regression
Model at first. Based on the examination of the *residuals* we will add
another quantitative predictor. We will follow this process through up
to a point where the gains in model accuracy are good enough to justify
the additional model complexity.

::: callout-note
This approach is the exact opposite of the earlier tutorial on multiple
linear regression, where we started with a **maximal model** and trimmed
it down based on an assessment of `r.squared`.
:::

## {{< iconify flat-color-icons:workflow >}} Workflow: EDA

The `nycflights13` package contains 5 data frames:

-   airlines: Names of Airlines (`carrier`, `name`)
-   airports: Metadata about Airports(`faa`, `name`, `lon`, `lat`,
    `alt`, `tz`, `dst`(daylight savings zone), `tzone`(IANA timezone))
-   flights: Flights data (`year,month,day`, `dep_time`, `arr_time`,
    `sched_dep_time`, `sched_arr_time`, `dep_delay`, `arr_delay`,
    `carrier` , `origin`, `dest`, `flight`, `tailnum`, `air_time`,
    `dist`, `hour minute` (departure time), `time_hour` (POSIXct
    scheduled date hour at origin)
-   planes: Plane metadata (`tailnum`, `year` (of manufacture), `type`,
    `manufacturer`, `model`, `engines`(number), `engine`(type), `seats`,
    `speed`)
-   weather: Hourly met data at JFK/EWR/LGA (`origin`,
    `year, month, day, hour`, `temp, dewp`, `humid`,
    `wind_dir, wind_speed, wind_gust`, `precip`, `pressure`, `visib`,
    `time_hour` (POSIXct).

The weather data is logged on an hourly basis. Hence we ought to
calculate **average dep_delay** on an hourly basis and use that measure
as our target variable. (We will figure out how to deal with
**arr_delay** as we go along)

```{r}
#| label: hourly summary of delays
flights_hour <- flights %>% 
  relocate(year, month, day, hour, minute, origin) %>% 
  group_by(year, month, day, hour, origin, carrier) %>%
  summarise(across(.cols = contains("delay"), 
                    .f = ~ mean(.x, na.rm = TRUE),
                    .names = "mean_{.col}"
                    ),
             .groups = "drop")
flights_hour

```

So we have average delays, at all airports, for all airline/carriers, by
the hour.

## {{< iconify flat-color-icons:workflow >}} Workflow: Adding Weather data

We now join this summary data frame with the `weather` data: We will use
the common variables `year, month, day, hour, origin` to get an
effective join:

```{r}
#| label: joining weather data
# Joining by `year, month, day, hour, origin` auto-magically
# Note the Console message! Ta Da!
flights_hour_weather <- 
  flights_hour %>% 
  left_join(weather) %>% 
  relocate(year, month, day, hour, time_hour)
flights_hour_weather

```

## {{< iconify flat-color-icons:workflow >}} Workflow: Correlations

```{r}
#| label: corr-test plots

all_corrs <- 
  flights_hour_weather %>% 
  select(where(is.numeric)) %>% 
  
  # leave off mean_dep_delay and year to get all the remaining ones
  select(- mean_dep_delay, -year) %>% 
  
  
  # perform a cor.test for all variables against mean_dep_delay
  purrr::map(.x = .,
             .f = \(x) cor.test(x, flights_hour_weather$mean_dep_delay)) %>%
  
  # tidy up the cor.test outputs into a tidy data frame
  map_dfr(broom::tidy, .id = "predictor") 

all_corrs

all_corrs %>% 
  gf_point(estimate ~ reorder(predictor, estimate)) %>% 
  gf_errorbar(conf.high + conf.low ~ reorder(predictor, estimate),
              color = ~ -log10(p.value),
              width = 0.2) %>% 
  gf_labs(x = NULL, y = "Correlation with Mean Hourly Departure Delays") %>% 
  gf_theme(theme = theme_minimal) %>% 
  gf_refine(scale_color_gradient("significance",
                                 low = "grey", high = "red"),
            theme(axis.text.x = element_text(angle = 30, hjust = 1)))

```

We now start with setting up simple Linear Regressions with **no**
predictors, only an intercept. We then fit separate Linear Models using
each predictor **individually**. Then based on the the improvement in
`r.squared` offered by each predictor, we progressively add it to the
model, until we are "satisfied" with the quality of the model ( using
`rsquared` and other means).

Let us now do this.

## {{< iconify flat-color-icons:workflow >}} Workflow: Minimal Multiple Regression Model

```{r}
lm_min <- lm(data = flights_hour_weather, mean_dep_delay ~ 1)
summary(lm_min)
lm_min %>% broom::tidy()
lm_min %>% broom::glance()

```

OK, so the intercept is highly significant, the `t-statistic` is also
high, but the intercept contributes *nothing* to the `r.squared`!!

## {{< iconify flat-color-icons:workflow >}} Workflow: Individual Model Addition

We will now set up individual models for each predictor and look at the
`p.value` and `r.squared` offered by each separate model:

```{r}
#| label: Round1-All individual models at once

names <- names(flights_hour_weather %>%
  select(where(is.numeric), 
         -c(mean_dep_delay, year)))
names

n_vars <- length(names)

flights_model_set <- tibble(all_vars = list(names),
                            keep_vars = seq(1, n_vars),
                            data = list(flights_hour_weather))
flights_model_set # 12 rows

# Unleash purrr in a series of mutates
flights_model_set <- flights_model_set %>%
  
# list of predictor variables for each model
  mutate(mod_vars =
           pmap(
             .l = list(all_vars, keep_vars, data),
             .f = \(all_vars, keep_vars, data) all_vars[keep_vars]
           )) %>%
  
# build formulae with these for linear regression
  mutate(formula = map(.x = mod_vars,
                       .f = \(mod_vars) as.formula(paste(
                         "mean_dep_delay ~", paste(mod_vars, collapse = "+")
                       )))) %>%
  
# use the formulae to build multiple linear models
  mutate(models =
           pmap(
             .l = list(data, formula),
             .f = \(data, formula) lm(formula, data = data)
           ))
# Check everything after the operation
flights_model_set

# Tidy up the models using broom to expose their metrics
flights_model_set <- 
  flights_model_set %>% 
  mutate(tidy_models =
           map(
             .x = models,
             .f = \(x) broom::glance(x,
                                     conf.int = TRUE,
                                     conf.lvel = 0.95)
           ),
         predictor_name = names[keep_vars]) %>% 

  # Remove unwanted columns, keep model and predictor count
  select(keep_vars,predictor_name, tidy_models) %>%
  unnest(tidy_models)


# Plot r.squared vs predictor count
flights_model_set %>% 
  gf_point(1 - r.squared ~ reorder(predictor_name, r.squared)) %>%
  gf_line(ylab = "Loss of R.Squared",
          xlab = "No. params in the Linear Model") %>%
  gf_theme(my_theme()) %>% 
  gf_refine(theme(axis.text.x = element_text(angle = 30, hjust = 1)))

```

```{r}
# Which is the winning Predictor?
winner <- flights_model_set %>% 
  arrange(desc(r.squared)) %>% 
  select(predictor_name) %>% 
  head(1) %>% as.character()
winner

```

So we can add `r winner` as a predictor to our model.

```{r}
# Here is the Round 1 Model
lm_round1 <- update(lm_min, ~. + mean_arr_delay)
lm_round1 %>% broom::tidy()
lm_round1 %>% broom::glance()

```

## {{< iconify flat-color-icons:workflow >}} Workflow: Round 2

We will set up a **round-2** model using `hour` as the predictor, and
then proceed to add each of the other predictors as an `update` to the
model.

```{r}
#| label: Round 2

# Preliminaries
names <- names(flights_hour_weather %>%
  select(where(is.numeric), -c(mean_dep_delay, mean_arr_delay, year, winner)))
names

n_vars <- length(names)
n_vars
# names <- names %>% str_remove(winner)
# names
# n_vars <- n_vars-1


# Round 2 Iteration
flights_model_set <- tibble(all_vars = list(names),
                            keep_vars = seq(1, n_vars),
                            data = list(flights_hour_weather))
flights_model_set 

# Unleash purrr in a series of mutates
flights_model_set <- flights_model_set %>%
  
# list of predictor variables for each model
  mutate(mod_vars =
           pmap(
             .l = list(all_vars, keep_vars, data),
             .f = \(all_vars, keep_vars, data) all_vars[keep_vars]
           )) %>%
  
# build formulae with these for linear regression
  mutate(formula = map(.x = mod_vars,
                       .f = \(mod_vars) as.formula(paste(
                         "mean_dep_delay ~ hour +", paste(mod_vars, collapse = "+")
                       )))) %>%
  
# use the formulae to build multiple linear models
  mutate(models =
           pmap(
             .l = list(data, formula),
             .f = \(data, formula) lm(formula, data = data)
           ))
# Check everything after the operation
flights_model_set

# Tidy up the models using broom to expose their metrics
flights_model_set <- 
  flights_model_set %>% 
  mutate(tidy_models =
           map(
             .x = models,
             .f = \(x) broom::glance(x,
                                     conf.int = TRUE,
                                     conf.lvel = 0.95)
           ),
         predictor_name = names[keep_vars]) %>% 

  # Remove unwanted columns, keep model and predictor count
  select(keep_vars,predictor_name, tidy_models) %>%
  unnest(tidy_models)
flights_model_set

# Plot r.squared vs predictor count
flights_model_set %>% 
  gf_point(1 - r.squared ~ reorder(predictor_name, r.squared)) %>%
  gf_line(ylab = "Loss of R.Squared",
          xlab = "No. params in the Linear Model") %>%
  gf_theme(my_theme()) %>% 
  gf_refine(theme(axis.text.x = element_text(angle = 30, hjust = 1)))


```

## References

1.  https://ethanwicker.com/2021-01-11-multiple-linear-regression-002/
